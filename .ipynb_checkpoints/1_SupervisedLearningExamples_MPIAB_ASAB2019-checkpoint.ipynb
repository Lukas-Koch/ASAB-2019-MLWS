{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from keras.engine import Layer\n",
    "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from keras.layers import Input, Dense, Dropout, TimeDistributed, Bidirectional, Flatten\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers import Conv1D, Dense, AveragePooling1D, Flatten, Concatenate, MaxPooling1D ,ConvLSTM2D\n",
    "from keras.layers import Input, Lambda, Reshape, Activation, Add, UpSampling1D\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import GlobalAveragePooling2D, AveragePooling1D\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing import image\n",
    "from IPython.display import Image\n",
    "import glob\n",
    "import keras \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os.path\n",
    "from tqdm import tqdm\n",
    "from itertools import cycle\n",
    "from keras.utils import to_categorical\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ngwena-ian/miniconda3/envs/models/lib/python3.6/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  data = yaml.load(f.read()) or {}\n"
     ]
    }
   ],
   "source": [
    "import mdn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ngwena-ian/Documents/Git/ASAB-2019-MLWS'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = 'data/ocellatus_labels.csv'\n",
    "video_frame_dir = 'data/ocellatus_video_frames'\n",
    "inception_features = 'data/ocellatus_features.npy'  # precomputed for time\n",
    "LSTM_features_file = 'data/occelatus_LSTM_features.npy'\n",
    "LSTM_labels_file = 'data/occelatus_LSTM_labels.npy'\n",
    "DCNN_features_file = 'data/occelatus_DCNN_features.npy'\n",
    "DCNN_labels_file = 'data/occelatus_DCNN_labels.npy'\n",
    "tracked_features1 = np.loadtxt('data/ocellatus_fish1_features.csv', skiprows=1, delimiter=',')\n",
    "tracked_features2 = np.loadtxt('data/ocellatus_fish2_features.csv', skiprows=1, delimiter=',')\n",
    "tracked_features = np.hstack([tracked_features1, tracked_features2])\n",
    "video_frames = glob.glob('/'.join([video_frame_dir, '*.jpg']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 32\n",
    "seq_stps = 4\n",
    "batch_size = 64\n",
    "validation_split = 0.2\n",
    "n_epochs = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlotLosses(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.i = 0\n",
    "        self.x = []\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "        self.accs = []\n",
    "        self.val_accs = []\n",
    "        self.fig = plt.figure()\n",
    "        \n",
    "        self.logs = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        \n",
    "        self.logs.append(logs)\n",
    "        self.x.append(self.i)\n",
    "        self.accs.append(logs.get('acc'))\n",
    "        self.val_accs.append(logs.get('val_acc'))\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.val_losses.append(logs.get('val_loss'))\n",
    "        self.i += 1\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        plt.figure(figsize=(15,15))\n",
    "        plt.subplot(211)\n",
    "        plt.plot(self.x, self.losses, label=\"loss\")\n",
    "        plt.plot(self.x, self.val_losses, label=\"val_loss\")\n",
    "        plt.legend()\n",
    "        plt.subplot(212)\n",
    "        plt.plot(self.x, self.accs, label=\"acc\")\n",
    "        plt.plot(self.x, self.val_accs, label=\"val_acc\")\n",
    "        plt.legend()\n",
    "        plt.show();\n",
    "        \n",
    "plot_losses = PlotLosses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  deaing with uneven sample sizes\n",
    "def evenly_subsample_features(labels, features, idx, counts, seq_len, seq_stps, n_features):\n",
    "    c = cycle([i for i in np.unique(idx)])\n",
    "    n_examples = int(np.min(counts)-seq_len)\n",
    "    if seq_stps == 0:\n",
    "        X = np.empty((n_examples*len(np.unique(idx)), seq_len, n_features))\n",
    "        Y = np.empty((n_examples*len(np.unique(idx)), seq_len, labels.shape[1]))\n",
    "        for j in range(n_examples*len(np.unique(idx))):\n",
    "            i = next(c)\n",
    "            try:\n",
    "                ix = np.random.choice(np.where(idx==i)[0])\n",
    "                X[j, :, :] = features[ix-int(seq_len/2):\n",
    "                                      ix+int(seq_len/2)]\n",
    "                Y[j, :, :] = labels[ix-int(seq_len/2):\n",
    "                                    ix+int(seq_len/2)]\n",
    "            except ValueError:\n",
    "                ix = np.random.choice(np.where(idx==i)[0])\n",
    "                X[j, :, :] = features[ix-int(seq_len/2):\n",
    "                                      ix+int(seq_len/2)]\n",
    "                Y[j, :, :] = labels[ix-int(seq_len/2):\n",
    "                                    ix+int(seq_len/2)]\n",
    "    else:\n",
    "        X = np.empty((n_examples*len(np.unique(idx)),\n",
    "                      seq_stps,\n",
    "                      int(seq_len/seq_stps),\n",
    "                      n_features))\n",
    "        \n",
    "        Y = np.empty((n_examples*len(np.unique(idx)), labels.shape[1]))\n",
    "        for j in range(n_examples*len(np.unique(idx))):\n",
    "            i = next(c)\n",
    "            try:\n",
    "                ix = np.random.choice(np.where(idx==i)[0])\n",
    "                X[j, :, :] = features[ix-int(seq_len/2):\n",
    "                                      ix+int(seq_len/2)].reshape((seq_stps,\n",
    "                                              int(seq_len/seq_stps),\n",
    "                                              n_features))\n",
    "                Y[j, :] = labels[ix]\n",
    "            except ValueError:\n",
    "                ix = np.random.choice(np.where(idx==i)[0])\n",
    "                X[j, :, :] = features[ix-int(seq_len/2):\n",
    "                                      ix+int(seq_len/2)].reshape((seq_stps,\n",
    "                                              int(seq_len/seq_stps),\n",
    "                                              n_features))\n",
    "                Y[j, :] = labels[ix]\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40620, 4) (40620, 32)\n"
     ]
    }
   ],
   "source": [
    "labels = np.loadtxt(annotations, skiprows=1, delimiter=',')\n",
    "labels = (labels > 0.5).astype(np.int_)  # make labels onehot\n",
    "_, idx, counts = np.unique(labels, axis=0, return_inverse=True, return_counts=True)\n",
    "labels = to_categorical(idx)\n",
    "print(labels.shape, tracked_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 1.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]] [  920  8131   732 30837]\n"
     ]
    }
   ],
   "source": [
    "# be aware of the biases of your data\n",
    "# these can completely undermine your training\n",
    "_, idx, counts = np.unique(labels, axis=0, return_inverse=True, return_counts=True)\n",
    "print(_, counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2800, 32, 32) (2800, 32, 4)\n"
     ]
    }
   ],
   "source": [
    "X, Y = evenly_subsample_features(labels, tracked_features, idx, counts,seq_stps=1, seq_len=seq_len, n_features=tracked_features.shape[1])\n",
    "print(X.shape, Y.shape)\n",
    "np.save(DCNN_features_file, X)\n",
    "np.save(DCNN_labels_file, Y)\n",
    "del X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pool_1D(inputs, filters, kernel_size=3):\n",
    "    conv = Conv1D(filters, (kernel_size), padding='same')(inputs)\n",
    "    conv = Activation('relu')(conv)\n",
    "    conv = Dropout(0.1)(conv)\n",
    "    conv = AveragePooling1D()(conv)\n",
    "    return conv\n",
    "\n",
    "def upsample_1D(inputs, residual, filters, kernel_size=3):\n",
    "    conv = Conv1D(filters, (kernel_size), padding='same')(inputs)\n",
    "    residual = Conv1D(filters, (1))(residual)\n",
    "    conv = Add()([conv,residual])\n",
    "    conv = Activation('relu')(conv)\n",
    "    conv = UpSampling1D()(conv)\n",
    "    return conv\n",
    "\n",
    "def build_1DCNN_model(input_shape, filter_size=32, kernel_size=3, n_pooling_upsampling_steps=1, n_classes=4):\n",
    "    input_layer = Input(shape=input_shape, name='input')\n",
    "    x = pool_1D(input_layer, filter_size)\n",
    "    res1 = x\n",
    "    outputs = []\n",
    "    \n",
    "    for idx in range(n_pooling_upsampling_steps):\n",
    "        x = pool_1D(x, filter_size*(idx+1))\n",
    "        outputs.append(x)\n",
    "        \n",
    "    for idx in range(n_pooling_upsampling_steps):\n",
    "        x = upsample_1D(x, outputs[-(idx+1)], filter_size*(n_pooling_upsampling_steps-idx))\n",
    "\n",
    "    \n",
    "    for idx in range(n_pooling_upsampling_steps):\n",
    "        x = pool_1D(x, filter_size*(idx+1))\n",
    "        outputs.append(x)\n",
    "        \n",
    "    for idx in range(n_pooling_upsampling_steps):\n",
    "        x = upsample_1D(x, outputs[-(idx+1)], filter_size*(n_pooling_upsampling_steps-idx))\n",
    "    \n",
    "    for idx in range(n_pooling_upsampling_steps):\n",
    "        x = pool_1D(x, filter_size*(idx+1))\n",
    "        outputs.append(x)\n",
    "        \n",
    "    for idx in range(n_pooling_upsampling_steps):\n",
    "        x = upsample_1D(x, outputs[-(idx+1)], filter_size*(n_pooling_upsampling_steps-idx))\n",
    "\n",
    "    x = upsample_1D(x, res1,  filter_size)\n",
    "    x = Conv1D(n_classes, (kernel_size), padding='same')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    model = Model(input_layer, x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_dcnn = np.load(DCNN_features_file)\n",
    "y_train = np.load(DCNN_labels_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              (None, 28, 2048)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_70 (Conv1D)              (None, 28, 32)       196640      input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_151 (Activation)     (None, 28, 32)       0           conv1d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_38 (Dropout)            (None, 28, 32)       0           activation_151[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling1d_34 (AveragePo (None, 14, 32)       0           dropout_38[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_71 (Conv1D)              (None, 14, 32)       3104        average_pooling1d_34[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_152 (Activation)     (None, 14, 32)       0           conv1d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_39 (Dropout)            (None, 14, 32)       0           activation_152[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling1d_35 (AveragePo (None, 7, 32)        0           dropout_39[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_72 (Conv1D)              (None, 7, 32)        3104        average_pooling1d_35[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_73 (Conv1D)              (None, 7, 32)        1056        average_pooling1d_35[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 7, 32)        0           conv1d_72[0][0]                  \n",
      "                                                                 conv1d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_153 (Activation)     (None, 7, 32)        0           add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_14 (UpSampling1D) (None, 14, 32)       0           activation_153[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_74 (Conv1D)              (None, 14, 32)       3104        up_sampling1d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_154 (Activation)     (None, 14, 32)       0           conv1d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_40 (Dropout)            (None, 14, 32)       0           activation_154[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling1d_36 (AveragePo (None, 7, 32)        0           dropout_40[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_75 (Conv1D)              (None, 7, 32)        3104        average_pooling1d_36[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_76 (Conv1D)              (None, 7, 32)        1056        average_pooling1d_36[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 7, 32)        0           conv1d_75[0][0]                  \n",
      "                                                                 conv1d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_155 (Activation)     (None, 7, 32)        0           add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_15 (UpSampling1D) (None, 14, 32)       0           activation_155[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_77 (Conv1D)              (None, 14, 32)       3104        up_sampling1d_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_156 (Activation)     (None, 14, 32)       0           conv1d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_41 (Dropout)            (None, 14, 32)       0           activation_156[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling1d_37 (AveragePo (None, 7, 32)        0           dropout_41[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_78 (Conv1D)              (None, 7, 32)        3104        average_pooling1d_37[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_79 (Conv1D)              (None, 7, 32)        1056        average_pooling1d_37[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, 7, 32)        0           conv1d_78[0][0]                  \n",
      "                                                                 conv1d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_157 (Activation)     (None, 7, 32)        0           add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_16 (UpSampling1D) (None, 14, 32)       0           activation_157[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_80 (Conv1D)              (None, 14, 32)       3104        up_sampling1d_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_81 (Conv1D)              (None, 14, 32)       1056        average_pooling1d_34[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, 14, 32)       0           conv1d_80[0][0]                  \n",
      "                                                                 conv1d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_158 (Activation)     (None, 14, 32)       0           add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_17 (UpSampling1D) (None, 28, 32)       0           activation_158[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_82 (Conv1D)              (None, 28, 4)        388         up_sampling1d_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_159 (Activation)     (None, 28, 4)        0           conv1d_82[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 222,980\n",
      "Trainable params: 222,980\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dcnn_model = build_1DCNN_model(input_shape=(X_train_lstm.shape[1], X_train_lstm.shape[2]), n_pooling_upsampling_steps=1, n_classes=y_train.shape[2])\n",
    "optimizer = Adam(lr=1e-5)\n",
    "dcnn_model.compile(loss='mse', optimizer=optimizer, metrics=['acc']) \n",
    "dcnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2252 samples, validate on 564 samples\n",
      "Epoch 1/5000\n",
      "2252/2252 [==============================] - 1s 650us/step - loss: 0.2267 - acc: 0.2446 - val_loss: 0.2262 - val_acc: 0.2501\n",
      "Epoch 2/5000\n",
      "2252/2252 [==============================] - 1s 583us/step - loss: 0.2267 - acc: 0.2450 - val_loss: 0.2262 - val_acc: 0.2486\n",
      "Epoch 3/5000\n",
      "2252/2252 [==============================] - 1s 592us/step - loss: 0.2265 - acc: 0.2455 - val_loss: 0.2259 - val_acc: 0.2480\n",
      "Epoch 4/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.2265 - acc: 0.2445 - val_loss: 0.2259 - val_acc: 0.2502\n",
      "Epoch 5/5000\n",
      "2252/2252 [==============================] - 1s 582us/step - loss: 0.2264 - acc: 0.2461 - val_loss: 0.2257 - val_acc: 0.2537\n",
      "Epoch 6/5000\n",
      "2252/2252 [==============================] - 1s 596us/step - loss: 0.2263 - acc: 0.2453 - val_loss: 0.2258 - val_acc: 0.2532\n",
      "Epoch 7/5000\n",
      "2252/2252 [==============================] - 1s 573us/step - loss: 0.2261 - acc: 0.2492 - val_loss: 0.2256 - val_acc: 0.2549\n",
      "Epoch 8/5000\n",
      "2252/2252 [==============================] - 1s 585us/step - loss: 0.2262 - acc: 0.2480 - val_loss: 0.2257 - val_acc: 0.2527\n",
      "Epoch 9/5000\n",
      "2252/2252 [==============================] - 1s 595us/step - loss: 0.2259 - acc: 0.2509 - val_loss: 0.2254 - val_acc: 0.2547\n",
      "Epoch 10/5000\n",
      "2252/2252 [==============================] - 1s 594us/step - loss: 0.2258 - acc: 0.2484 - val_loss: 0.2253 - val_acc: 0.2563\n",
      "Epoch 11/5000\n",
      "2252/2252 [==============================] - 1s 600us/step - loss: 0.2258 - acc: 0.2492 - val_loss: 0.2251 - val_acc: 0.2569\n",
      "Epoch 12/5000\n",
      "2252/2252 [==============================] - 1s 606us/step - loss: 0.2256 - acc: 0.2513 - val_loss: 0.2252 - val_acc: 0.2576\n",
      "Epoch 13/5000\n",
      "2252/2252 [==============================] - 1s 583us/step - loss: 0.2254 - acc: 0.2522 - val_loss: 0.2250 - val_acc: 0.2587\n",
      "Epoch 14/5000\n",
      "2252/2252 [==============================] - 1s 577us/step - loss: 0.2252 - acc: 0.2528 - val_loss: 0.2248 - val_acc: 0.2592\n",
      "Epoch 15/5000\n",
      "2252/2252 [==============================] - 1s 599us/step - loss: 0.2251 - acc: 0.2528 - val_loss: 0.2248 - val_acc: 0.2615\n",
      "Epoch 16/5000\n",
      "2252/2252 [==============================] - 1s 578us/step - loss: 0.2252 - acc: 0.2545 - val_loss: 0.2247 - val_acc: 0.2618\n",
      "Epoch 17/5000\n",
      "2252/2252 [==============================] - 1s 586us/step - loss: 0.2249 - acc: 0.2554 - val_loss: 0.2244 - val_acc: 0.2610\n",
      "Epoch 18/5000\n",
      "2252/2252 [==============================] - 1s 597us/step - loss: 0.2248 - acc: 0.2552 - val_loss: 0.2243 - val_acc: 0.2649\n",
      "Epoch 19/5000\n",
      "2252/2252 [==============================] - 1s 591us/step - loss: 0.2247 - acc: 0.2569 - val_loss: 0.2244 - val_acc: 0.2653\n",
      "Epoch 20/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.2245 - acc: 0.2592 - val_loss: 0.2241 - val_acc: 0.2654\n",
      "Epoch 21/5000\n",
      "2252/2252 [==============================] - 1s 583us/step - loss: 0.2241 - acc: 0.2592 - val_loss: 0.2240 - val_acc: 0.2603\n",
      "Epoch 22/5000\n",
      "2252/2252 [==============================] - 1s 589us/step - loss: 0.2241 - acc: 0.2576 - val_loss: 0.2236 - val_acc: 0.2649\n",
      "Epoch 23/5000\n",
      "2252/2252 [==============================] - 1s 589us/step - loss: 0.2240 - acc: 0.2611 - val_loss: 0.2234 - val_acc: 0.2693\n",
      "Epoch 24/5000\n",
      "2252/2252 [==============================] - 1s 601us/step - loss: 0.2236 - acc: 0.2626 - val_loss: 0.2232 - val_acc: 0.2693\n",
      "Epoch 25/5000\n",
      "2252/2252 [==============================] - 1s 590us/step - loss: 0.2235 - acc: 0.2634 - val_loss: 0.2231 - val_acc: 0.2645\n",
      "Epoch 26/5000\n",
      "2252/2252 [==============================] - 1s 585us/step - loss: 0.2234 - acc: 0.2637 - val_loss: 0.2228 - val_acc: 0.2743\n",
      "Epoch 27/5000\n",
      "2252/2252 [==============================] - 1s 598us/step - loss: 0.2232 - acc: 0.2647 - val_loss: 0.2230 - val_acc: 0.2808\n",
      "Epoch 28/5000\n",
      "2252/2252 [==============================] - 1s 597us/step - loss: 0.2227 - acc: 0.2698 - val_loss: 0.2224 - val_acc: 0.2690\n",
      "Epoch 29/5000\n",
      "2252/2252 [==============================] - 1s 599us/step - loss: 0.2224 - acc: 0.2667 - val_loss: 0.2224 - val_acc: 0.2833\n",
      "Epoch 30/5000\n",
      "2252/2252 [==============================] - 1s 592us/step - loss: 0.2222 - acc: 0.2710 - val_loss: 0.2216 - val_acc: 0.2771\n",
      "Epoch 31/5000\n",
      "2252/2252 [==============================] - 1s 595us/step - loss: 0.2218 - acc: 0.2735 - val_loss: 0.2215 - val_acc: 0.2743\n",
      "Epoch 32/5000\n",
      "2252/2252 [==============================] - 1s 594us/step - loss: 0.2217 - acc: 0.2707 - val_loss: 0.2213 - val_acc: 0.2890\n",
      "Epoch 33/5000\n",
      "2252/2252 [==============================] - 1s 596us/step - loss: 0.2209 - acc: 0.2765 - val_loss: 0.2206 - val_acc: 0.2848\n",
      "Epoch 34/5000\n",
      "2252/2252 [==============================] - 1s 594us/step - loss: 0.2207 - acc: 0.2763 - val_loss: 0.2202 - val_acc: 0.2900\n",
      "Epoch 35/5000\n",
      "2252/2252 [==============================] - 1s 594us/step - loss: 0.2198 - acc: 0.2791 - val_loss: 0.2193 - val_acc: 0.2888\n",
      "Epoch 36/5000\n",
      "2252/2252 [==============================] - 1s 603us/step - loss: 0.2173 - acc: 0.2790 - val_loss: 0.2150 - val_acc: 0.2882\n",
      "Epoch 37/5000\n",
      "2252/2252 [==============================] - 1s 592us/step - loss: 0.2151 - acc: 0.2834 - val_loss: 0.2143 - val_acc: 0.2919\n",
      "Epoch 38/5000\n",
      "2252/2252 [==============================] - 1s 590us/step - loss: 0.2144 - acc: 0.2850 - val_loss: 0.2131 - val_acc: 0.2943\n",
      "Epoch 39/5000\n",
      "2252/2252 [==============================] - 1s 594us/step - loss: 0.2134 - acc: 0.2890 - val_loss: 0.2125 - val_acc: 0.3034\n",
      "Epoch 40/5000\n",
      "2252/2252 [==============================] - 1s 599us/step - loss: 0.2126 - acc: 0.2941 - val_loss: 0.2127 - val_acc: 0.2857\n",
      "Epoch 41/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.2125 - acc: 0.2933 - val_loss: 0.2108 - val_acc: 0.3057\n",
      "Epoch 42/5000\n",
      "2252/2252 [==============================] - 1s 596us/step - loss: 0.2086 - acc: 0.3042 - val_loss: 0.1838 - val_acc: 0.3938\n",
      "Epoch 43/5000\n",
      "2252/2252 [==============================] - 1s 596us/step - loss: 0.1876 - acc: 0.3915 - val_loss: 0.1798 - val_acc: 0.4317\n",
      "Epoch 44/5000\n",
      "2252/2252 [==============================] - 1s 600us/step - loss: 0.1820 - acc: 0.4169 - val_loss: 0.1764 - val_acc: 0.4477\n",
      "Epoch 45/5000\n",
      "2252/2252 [==============================] - 1s 587us/step - loss: 0.1799 - acc: 0.4264 - val_loss: 0.1746 - val_acc: 0.4558\n",
      "Epoch 46/5000\n",
      "2252/2252 [==============================] - 1s 591us/step - loss: 0.1782 - acc: 0.4323 - val_loss: 0.1733 - val_acc: 0.4669\n",
      "Epoch 47/5000\n",
      "2252/2252 [==============================] - 1s 594us/step - loss: 0.1760 - acc: 0.4483 - val_loss: 0.1717 - val_acc: 0.4745\n",
      "Epoch 48/5000\n",
      "2252/2252 [==============================] - 1s 586us/step - loss: 0.1746 - acc: 0.4567 - val_loss: 0.1703 - val_acc: 0.4790\n",
      "Epoch 49/5000\n",
      "2252/2252 [==============================] - 1s 594us/step - loss: 0.1745 - acc: 0.4521 - val_loss: 0.1724 - val_acc: 0.4555\n",
      "Epoch 50/5000\n",
      "2252/2252 [==============================] - 1s 589us/step - loss: 0.1734 - acc: 0.4558 - val_loss: 0.1681 - val_acc: 0.4929\n",
      "Epoch 51/5000\n",
      "2252/2252 [==============================] - 1s 592us/step - loss: 0.1707 - acc: 0.4726 - val_loss: 0.1663 - val_acc: 0.5013\n",
      "Epoch 52/5000\n",
      "2252/2252 [==============================] - 1s 603us/step - loss: 0.1685 - acc: 0.4850 - val_loss: 0.1660 - val_acc: 0.4932\n",
      "Epoch 53/5000\n",
      "2252/2252 [==============================] - 1s 606us/step - loss: 0.1668 - acc: 0.4921 - val_loss: 0.1643 - val_acc: 0.5046\n",
      "Epoch 54/5000\n",
      "2252/2252 [==============================] - 1s 592us/step - loss: 0.1662 - acc: 0.4942 - val_loss: 0.1635 - val_acc: 0.5044\n",
      "Epoch 55/5000\n",
      "2252/2252 [==============================] - 1s 590us/step - loss: 0.1643 - acc: 0.5013 - val_loss: 0.1600 - val_acc: 0.5261\n",
      "Epoch 56/5000\n",
      "2252/2252 [==============================] - 1s 600us/step - loss: 0.1625 - acc: 0.5111 - val_loss: 0.1581 - val_acc: 0.5284\n",
      "Epoch 57/5000\n",
      "2252/2252 [==============================] - 1s 581us/step - loss: 0.1612 - acc: 0.5152 - val_loss: 0.1566 - val_acc: 0.5344\n",
      "Epoch 58/5000\n",
      "2252/2252 [==============================] - 1s 588us/step - loss: 0.1592 - acc: 0.5211 - val_loss: 0.1551 - val_acc: 0.5423\n",
      "Epoch 59/5000\n",
      "2252/2252 [==============================] - 1s 595us/step - loss: 0.1573 - acc: 0.5295 - val_loss: 0.1540 - val_acc: 0.5400\n",
      "Epoch 60/5000\n",
      "2252/2252 [==============================] - 1s 591us/step - loss: 0.1559 - acc: 0.5337 - val_loss: 0.1520 - val_acc: 0.5459\n",
      "Epoch 61/5000\n",
      "2252/2252 [==============================] - 1s 595us/step - loss: 0.1552 - acc: 0.5373 - val_loss: 0.1515 - val_acc: 0.5463\n",
      "Epoch 62/5000\n",
      "2252/2252 [==============================] - 1s 602us/step - loss: 0.1529 - acc: 0.5438 - val_loss: 0.1486 - val_acc: 0.5569\n",
      "Epoch 63/5000\n",
      "2252/2252 [==============================] - 1s 592us/step - loss: 0.1522 - acc: 0.5447 - val_loss: 0.1469 - val_acc: 0.5619\n",
      "Epoch 64/5000\n",
      "2252/2252 [==============================] - 1s 588us/step - loss: 0.1502 - acc: 0.5534 - val_loss: 0.1462 - val_acc: 0.5624\n",
      "Epoch 65/5000\n",
      "2252/2252 [==============================] - 1s 591us/step - loss: 0.1492 - acc: 0.5552 - val_loss: 0.1443 - val_acc: 0.5673\n",
      "Epoch 66/5000\n",
      "2252/2252 [==============================] - 1s 602us/step - loss: 0.1478 - acc: 0.5605 - val_loss: 0.1462 - val_acc: 0.5602\n",
      "Epoch 67/5000\n",
      "2252/2252 [==============================] - 1s 600us/step - loss: 0.1492 - acc: 0.5534 - val_loss: 0.1487 - val_acc: 0.5624\n",
      "Epoch 68/5000\n",
      "2252/2252 [==============================] - 1s 590us/step - loss: 0.1459 - acc: 0.5644 - val_loss: 0.1438 - val_acc: 0.5652\n",
      "Epoch 69/5000\n",
      "2252/2252 [==============================] - 1s 597us/step - loss: 0.1448 - acc: 0.5679 - val_loss: 0.1427 - val_acc: 0.5683\n",
      "Epoch 70/5000\n",
      "2252/2252 [==============================] - 1s 597us/step - loss: 0.1441 - acc: 0.5708 - val_loss: 0.1407 - val_acc: 0.5797\n",
      "Epoch 71/5000\n",
      "2252/2252 [==============================] - 1s 589us/step - loss: 0.1434 - acc: 0.5740 - val_loss: 0.1400 - val_acc: 0.5821\n",
      "Epoch 72/5000\n",
      "2252/2252 [==============================] - 1s 591us/step - loss: 0.1424 - acc: 0.5771 - val_loss: 0.1380 - val_acc: 0.5825\n",
      "Epoch 73/5000\n",
      "2252/2252 [==============================] - 1s 587us/step - loss: 0.1415 - acc: 0.5774 - val_loss: 0.1375 - val_acc: 0.5840\n",
      "Epoch 74/5000\n",
      "2252/2252 [==============================] - 1s 594us/step - loss: 0.1405 - acc: 0.5829 - val_loss: 0.1390 - val_acc: 0.5862\n",
      "Epoch 75/5000\n",
      "2252/2252 [==============================] - 1s 598us/step - loss: 0.1409 - acc: 0.5805 - val_loss: 0.1362 - val_acc: 0.5891\n",
      "Epoch 76/5000\n",
      "2252/2252 [==============================] - 1s 590us/step - loss: 0.1386 - acc: 0.5843 - val_loss: 0.1354 - val_acc: 0.5896\n",
      "Epoch 77/5000\n",
      "2252/2252 [==============================] - 1s 589us/step - loss: 0.1381 - acc: 0.5887 - val_loss: 0.1351 - val_acc: 0.5918\n",
      "Epoch 78/5000\n",
      "2252/2252 [==============================] - 1s 570us/step - loss: 0.1378 - acc: 0.5878 - val_loss: 0.1343 - val_acc: 0.5932\n",
      "Epoch 79/5000\n",
      "2252/2252 [==============================] - 1s 599us/step - loss: 0.1379 - acc: 0.5877 - val_loss: 0.1338 - val_acc: 0.5951\n",
      "Epoch 80/5000\n",
      "2252/2252 [==============================] - 1s 583us/step - loss: 0.1369 - acc: 0.5899 - val_loss: 0.1376 - val_acc: 0.5921\n",
      "Epoch 81/5000\n",
      "2252/2252 [==============================] - 1s 584us/step - loss: 0.1364 - acc: 0.5934 - val_loss: 0.1322 - val_acc: 0.5987\n",
      "Epoch 82/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.1346 - acc: 0.5961 - val_loss: 0.1322 - val_acc: 0.5980\n",
      "Epoch 83/5000\n",
      "2252/2252 [==============================] - 1s 586us/step - loss: 0.1342 - acc: 0.5974 - val_loss: 0.1316 - val_acc: 0.5990\n",
      "Epoch 84/5000\n",
      "2252/2252 [==============================] - 1s 591us/step - loss: 0.1342 - acc: 0.5962 - val_loss: 0.1313 - val_acc: 0.6010\n",
      "Epoch 85/5000\n",
      "2252/2252 [==============================] - 1s 598us/step - loss: 0.1338 - acc: 0.5981 - val_loss: 0.1317 - val_acc: 0.5959\n",
      "Epoch 86/5000\n",
      "2252/2252 [==============================] - 1s 585us/step - loss: 0.1327 - acc: 0.6000 - val_loss: 0.1308 - val_acc: 0.6006\n",
      "Epoch 87/5000\n",
      "2252/2252 [==============================] - 1s 591us/step - loss: 0.1328 - acc: 0.6001 - val_loss: 0.1298 - val_acc: 0.6043\n",
      "Epoch 88/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.1323 - acc: 0.6024 - val_loss: 0.1294 - val_acc: 0.6058\n",
      "Epoch 89/5000\n",
      "2252/2252 [==============================] - 1s 592us/step - loss: 0.1317 - acc: 0.6043 - val_loss: 0.1289 - val_acc: 0.6063\n",
      "Epoch 90/5000\n",
      "2252/2252 [==============================] - 1s 605us/step - loss: 0.1309 - acc: 0.6059 - val_loss: 0.1289 - val_acc: 0.6049\n",
      "Epoch 91/5000\n",
      "2252/2252 [==============================] - 1s 592us/step - loss: 0.1311 - acc: 0.6053 - val_loss: 0.1282 - val_acc: 0.6087\n",
      "Epoch 92/5000\n",
      "2252/2252 [==============================] - 1s 600us/step - loss: 0.1311 - acc: 0.6063 - val_loss: 0.1282 - val_acc: 0.6095\n",
      "Epoch 93/5000\n",
      "2252/2252 [==============================] - 1s 595us/step - loss: 0.1293 - acc: 0.6100 - val_loss: 0.1276 - val_acc: 0.6100\n",
      "Epoch 94/5000\n",
      "2252/2252 [==============================] - 1s 583us/step - loss: 0.1309 - acc: 0.6055 - val_loss: 0.1270 - val_acc: 0.6097\n",
      "Epoch 95/5000\n",
      "2252/2252 [==============================] - 1s 595us/step - loss: 0.1282 - acc: 0.6128 - val_loss: 0.1280 - val_acc: 0.6037\n",
      "Epoch 96/5000\n",
      "2252/2252 [==============================] - 1s 598us/step - loss: 0.1281 - acc: 0.6116 - val_loss: 0.1313 - val_acc: 0.6037\n",
      "Epoch 97/5000\n",
      "2252/2252 [==============================] - 1s 587us/step - loss: 0.1276 - acc: 0.6142 - val_loss: 0.1260 - val_acc: 0.6129\n",
      "Epoch 98/5000\n",
      "2252/2252 [==============================] - 1s 580us/step - loss: 0.1276 - acc: 0.6142 - val_loss: 0.1268 - val_acc: 0.6114\n",
      "Epoch 99/5000\n",
      "2252/2252 [==============================] - 1s 599us/step - loss: 0.1266 - acc: 0.6170 - val_loss: 0.1249 - val_acc: 0.6146\n",
      "Epoch 100/5000\n",
      "2252/2252 [==============================] - 1s 602us/step - loss: 0.1258 - acc: 0.6153 - val_loss: 0.1247 - val_acc: 0.6172\n",
      "Epoch 101/5000\n",
      "2252/2252 [==============================] - 1s 573us/step - loss: 0.1260 - acc: 0.6171 - val_loss: 0.1240 - val_acc: 0.6175\n",
      "Epoch 102/5000\n",
      "2252/2252 [==============================] - 1s 591us/step - loss: 0.1263 - acc: 0.6159 - val_loss: 0.1234 - val_acc: 0.6179\n",
      "Epoch 103/5000\n",
      "2252/2252 [==============================] - 1s 583us/step - loss: 0.1247 - acc: 0.6220 - val_loss: 0.1229 - val_acc: 0.6203\n",
      "Epoch 104/5000\n",
      "2252/2252 [==============================] - 1s 587us/step - loss: 0.1237 - acc: 0.6232 - val_loss: 0.1230 - val_acc: 0.6169\n",
      "Epoch 105/5000\n",
      "2252/2252 [==============================] - 1s 588us/step - loss: 0.1240 - acc: 0.6221 - val_loss: 0.1263 - val_acc: 0.6136\n",
      "Epoch 106/5000\n",
      "2252/2252 [==============================] - 1s 579us/step - loss: 0.1243 - acc: 0.6200 - val_loss: 0.1222 - val_acc: 0.6223\n",
      "Epoch 107/5000\n",
      "2252/2252 [==============================] - 1s 587us/step - loss: 0.1226 - acc: 0.6241 - val_loss: 0.1214 - val_acc: 0.6264\n",
      "Epoch 108/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.1222 - acc: 0.6292 - val_loss: 0.1208 - val_acc: 0.6262\n",
      "Epoch 109/5000\n",
      "2252/2252 [==============================] - 1s 588us/step - loss: 0.1210 - acc: 0.6315 - val_loss: 0.1214 - val_acc: 0.6249\n",
      "Epoch 110/5000\n",
      "2252/2252 [==============================] - 1s 595us/step - loss: 0.1204 - acc: 0.6314 - val_loss: 0.1199 - val_acc: 0.6285\n",
      "Epoch 111/5000\n",
      "2252/2252 [==============================] - 1s 588us/step - loss: 0.1200 - acc: 0.6332 - val_loss: 0.1192 - val_acc: 0.6304\n",
      "Epoch 112/5000\n",
      "2252/2252 [==============================] - 1s 587us/step - loss: 0.1202 - acc: 0.6302 - val_loss: 0.1196 - val_acc: 0.6304\n",
      "Epoch 113/5000\n",
      "2252/2252 [==============================] - 1s 583us/step - loss: 0.1204 - acc: 0.6332 - val_loss: 0.1184 - val_acc: 0.6322\n",
      "Epoch 114/5000\n",
      "2252/2252 [==============================] - 1s 569us/step - loss: 0.1194 - acc: 0.6344 - val_loss: 0.1185 - val_acc: 0.6346\n",
      "Epoch 115/5000\n",
      "2252/2252 [==============================] - 1s 594us/step - loss: 0.1195 - acc: 0.6330 - val_loss: 0.1175 - val_acc: 0.6381\n",
      "Epoch 116/5000\n",
      "2252/2252 [==============================] - 1s 602us/step - loss: 0.1180 - acc: 0.6394 - val_loss: 0.1172 - val_acc: 0.6365\n",
      "Epoch 117/5000\n",
      "2252/2252 [==============================] - 1s 595us/step - loss: 0.1188 - acc: 0.6351 - val_loss: 0.1164 - val_acc: 0.6422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118/5000\n",
      "2252/2252 [==============================] - 1s 590us/step - loss: 0.1167 - acc: 0.6440 - val_loss: 0.1164 - val_acc: 0.6408\n",
      "Epoch 119/5000\n",
      "2252/2252 [==============================] - 1s 575us/step - loss: 0.1159 - acc: 0.6453 - val_loss: 0.1175 - val_acc: 0.6367\n",
      "Epoch 120/5000\n",
      "2252/2252 [==============================] - 1s 579us/step - loss: 0.1166 - acc: 0.6426 - val_loss: 0.1198 - val_acc: 0.6313\n",
      "Epoch 121/5000\n",
      "2252/2252 [==============================] - 1s 596us/step - loss: 0.1155 - acc: 0.6458 - val_loss: 0.1148 - val_acc: 0.6403\n",
      "Epoch 122/5000\n",
      "2252/2252 [==============================] - 1s 598us/step - loss: 0.1145 - acc: 0.6487 - val_loss: 0.1159 - val_acc: 0.6330\n",
      "Epoch 123/5000\n",
      "2252/2252 [==============================] - 1s 586us/step - loss: 0.1142 - acc: 0.6484 - val_loss: 0.1139 - val_acc: 0.6449\n",
      "Epoch 124/5000\n",
      "2252/2252 [==============================] - 1s 600us/step - loss: 0.1134 - acc: 0.6504 - val_loss: 0.1177 - val_acc: 0.6361\n",
      "Epoch 125/5000\n",
      "2252/2252 [==============================] - 1s 583us/step - loss: 0.1130 - acc: 0.6564 - val_loss: 0.1129 - val_acc: 0.6487\n",
      "Epoch 126/5000\n",
      "2252/2252 [==============================] - 1s 595us/step - loss: 0.1128 - acc: 0.6553 - val_loss: 0.1140 - val_acc: 0.6491\n",
      "Epoch 127/5000\n",
      "2252/2252 [==============================] - 1s 589us/step - loss: 0.1130 - acc: 0.6544 - val_loss: 0.1123 - val_acc: 0.6472\n",
      "Epoch 128/5000\n",
      "2252/2252 [==============================] - 1s 589us/step - loss: 0.1120 - acc: 0.6551 - val_loss: 0.1143 - val_acc: 0.6465\n",
      "Epoch 129/5000\n",
      "2252/2252 [==============================] - 1s 589us/step - loss: 0.1115 - acc: 0.6548 - val_loss: 0.1129 - val_acc: 0.6492\n",
      "Epoch 130/5000\n",
      "2252/2252 [==============================] - 1s 592us/step - loss: 0.1108 - acc: 0.6566 - val_loss: 0.1117 - val_acc: 0.6512\n",
      "Epoch 131/5000\n",
      "2252/2252 [==============================] - 1s 597us/step - loss: 0.1111 - acc: 0.6583 - val_loss: 0.1147 - val_acc: 0.6442\n",
      "Epoch 132/5000\n",
      "2252/2252 [==============================] - 1s 591us/step - loss: 0.1110 - acc: 0.6556 - val_loss: 0.1123 - val_acc: 0.6510\n",
      "Epoch 133/5000\n",
      "2252/2252 [==============================] - 1s 586us/step - loss: 0.1096 - acc: 0.6614 - val_loss: 0.1102 - val_acc: 0.6515\n",
      "Epoch 134/5000\n",
      "2252/2252 [==============================] - 1s 596us/step - loss: 0.1101 - acc: 0.6584 - val_loss: 0.1102 - val_acc: 0.6544\n",
      "Epoch 135/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.1115 - acc: 0.6564 - val_loss: 0.1139 - val_acc: 0.6476\n",
      "Epoch 136/5000\n",
      "2252/2252 [==============================] - 1s 596us/step - loss: 0.1086 - acc: 0.6617 - val_loss: 0.1093 - val_acc: 0.6545\n",
      "Epoch 137/5000\n",
      "2252/2252 [==============================] - 1s 583us/step - loss: 0.1085 - acc: 0.6623 - val_loss: 0.1157 - val_acc: 0.6414\n",
      "Epoch 138/5000\n",
      "2252/2252 [==============================] - 1s 588us/step - loss: 0.1078 - acc: 0.6679 - val_loss: 0.1093 - val_acc: 0.6502\n",
      "Epoch 139/5000\n",
      "2252/2252 [==============================] - 1s 598us/step - loss: 0.1087 - acc: 0.6634 - val_loss: 0.1086 - val_acc: 0.6553\n",
      "Epoch 140/5000\n",
      "2252/2252 [==============================] - 1s 602us/step - loss: 0.1066 - acc: 0.6702 - val_loss: 0.1118 - val_acc: 0.6520\n",
      "Epoch 141/5000\n",
      "2252/2252 [==============================] - 1s 587us/step - loss: 0.1068 - acc: 0.6691 - val_loss: 0.1086 - val_acc: 0.6568\n",
      "Epoch 142/5000\n",
      "2252/2252 [==============================] - 1s 581us/step - loss: 0.1060 - acc: 0.6718 - val_loss: 0.1100 - val_acc: 0.6570\n",
      "Epoch 143/5000\n",
      "2252/2252 [==============================] - 1s 591us/step - loss: 0.1060 - acc: 0.6686 - val_loss: 0.1072 - val_acc: 0.6569\n",
      "Epoch 144/5000\n",
      "2252/2252 [==============================] - 1s 575us/step - loss: 0.1058 - acc: 0.6692 - val_loss: 0.1070 - val_acc: 0.6567\n",
      "Epoch 145/5000\n",
      "2252/2252 [==============================] - 1s 591us/step - loss: 0.1052 - acc: 0.6747 - val_loss: 0.1119 - val_acc: 0.6509\n",
      "Epoch 146/5000\n",
      "2252/2252 [==============================] - 1s 588us/step - loss: 0.1058 - acc: 0.6718 - val_loss: 0.1062 - val_acc: 0.6620\n",
      "Epoch 147/5000\n",
      "2252/2252 [==============================] - 1s 587us/step - loss: 0.1048 - acc: 0.6729 - val_loss: 0.1060 - val_acc: 0.6619\n",
      "Epoch 148/5000\n",
      "2252/2252 [==============================] - 1s 597us/step - loss: 0.1043 - acc: 0.6727 - val_loss: 0.1061 - val_acc: 0.6577\n",
      "Epoch 149/5000\n",
      "2252/2252 [==============================] - 1s 586us/step - loss: 0.1047 - acc: 0.6733 - val_loss: 0.1065 - val_acc: 0.6615\n",
      "Epoch 150/5000\n",
      "2252/2252 [==============================] - 1s 583us/step - loss: 0.1037 - acc: 0.6755 - val_loss: 0.1066 - val_acc: 0.6616\n",
      "Epoch 151/5000\n",
      "2252/2252 [==============================] - 1s 587us/step - loss: 0.1030 - acc: 0.6775 - val_loss: 0.1090 - val_acc: 0.6565\n",
      "Epoch 152/5000\n",
      "2252/2252 [==============================] - 1s 590us/step - loss: 0.1042 - acc: 0.6721 - val_loss: 0.1068 - val_acc: 0.6611\n",
      "Epoch 153/5000\n",
      "2252/2252 [==============================] - 1s 596us/step - loss: 0.1024 - acc: 0.6776 - val_loss: 0.1050 - val_acc: 0.6634\n",
      "Epoch 154/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.1032 - acc: 0.6738 - val_loss: 0.1040 - val_acc: 0.6648\n",
      "Epoch 155/5000\n",
      "2252/2252 [==============================] - 1s 590us/step - loss: 0.1014 - acc: 0.6796 - val_loss: 0.1078 - val_acc: 0.6515\n",
      "Epoch 156/5000\n",
      "2252/2252 [==============================] - 1s 589us/step - loss: 0.1036 - acc: 0.6762 - val_loss: 0.1036 - val_acc: 0.6674\n",
      "Epoch 157/5000\n",
      "2252/2252 [==============================] - 1s 582us/step - loss: 0.1013 - acc: 0.6826 - val_loss: 0.1034 - val_acc: 0.6692\n",
      "Epoch 158/5000\n",
      "2252/2252 [==============================] - 1s 599us/step - loss: 0.1018 - acc: 0.6797 - val_loss: 0.1056 - val_acc: 0.6632\n",
      "Epoch 159/5000\n",
      "2252/2252 [==============================] - 1s 598us/step - loss: 0.1011 - acc: 0.6817 - val_loss: 0.1035 - val_acc: 0.6661\n",
      "Epoch 160/5000\n",
      "2252/2252 [==============================] - 1s 589us/step - loss: 0.1003 - acc: 0.6848 - val_loss: 0.1060 - val_acc: 0.6631\n",
      "Epoch 161/5000\n",
      "2252/2252 [==============================] - 1s 586us/step - loss: 0.0999 - acc: 0.6863 - val_loss: 0.1027 - val_acc: 0.6667\n",
      "Epoch 162/5000\n",
      "2252/2252 [==============================] - 1s 596us/step - loss: 0.1010 - acc: 0.6807 - val_loss: 0.1026 - val_acc: 0.6667\n",
      "Epoch 163/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.0998 - acc: 0.6878 - val_loss: 0.1023 - val_acc: 0.6698\n",
      "Epoch 164/5000\n",
      "2252/2252 [==============================] - 1s 599us/step - loss: 0.1003 - acc: 0.6853 - val_loss: 0.1038 - val_acc: 0.6671\n",
      "Epoch 165/5000\n",
      "2252/2252 [==============================] - 1s 601us/step - loss: 0.1001 - acc: 0.6840 - val_loss: 0.1018 - val_acc: 0.6721\n",
      "Epoch 166/5000\n",
      "2252/2252 [==============================] - 1s 597us/step - loss: 0.0998 - acc: 0.6858 - val_loss: 0.1031 - val_acc: 0.6689\n",
      "Epoch 167/5000\n",
      "2252/2252 [==============================] - 1s 591us/step - loss: 0.0991 - acc: 0.6885 - val_loss: 0.1039 - val_acc: 0.6670\n",
      "Epoch 168/5000\n",
      "2252/2252 [==============================] - 1s 589us/step - loss: 0.0990 - acc: 0.6872 - val_loss: 0.1051 - val_acc: 0.6651\n",
      "Epoch 169/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.0989 - acc: 0.6869 - val_loss: 0.1015 - val_acc: 0.6711\n",
      "Epoch 170/5000\n",
      "2252/2252 [==============================] - 1s 604us/step - loss: 0.0989 - acc: 0.6881 - val_loss: 0.1011 - val_acc: 0.6727\n",
      "Epoch 171/5000\n",
      "2252/2252 [==============================] - 1s 604us/step - loss: 0.0981 - acc: 0.6928 - val_loss: 0.1017 - val_acc: 0.6726\n",
      "Epoch 172/5000\n",
      "2252/2252 [==============================] - 1s 600us/step - loss: 0.0986 - acc: 0.6881 - val_loss: 0.1010 - val_acc: 0.6731\n",
      "Epoch 173/5000\n",
      "2252/2252 [==============================] - 1s 592us/step - loss: 0.0974 - acc: 0.6922 - val_loss: 0.1015 - val_acc: 0.6719\n",
      "Epoch 174/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.0967 - acc: 0.6968 - val_loss: 0.1010 - val_acc: 0.6734\n",
      "Epoch 175/5000\n",
      "2252/2252 [==============================] - 1s 596us/step - loss: 0.0981 - acc: 0.6912 - val_loss: 0.1043 - val_acc: 0.6670\n",
      "Epoch 176/5000\n",
      "2252/2252 [==============================] - 1s 590us/step - loss: 0.0972 - acc: 0.6924 - val_loss: 0.1000 - val_acc: 0.6772\n",
      "Epoch 177/5000\n",
      "2252/2252 [==============================] - 1s 595us/step - loss: 0.0966 - acc: 0.6926 - val_loss: 0.1011 - val_acc: 0.6736\n",
      "Epoch 178/5000\n",
      "2252/2252 [==============================] - 1s 601us/step - loss: 0.0970 - acc: 0.6925 - val_loss: 0.0996 - val_acc: 0.6774\n",
      "Epoch 179/5000\n",
      "2252/2252 [==============================] - 1s 592us/step - loss: 0.0975 - acc: 0.6938 - val_loss: 0.0998 - val_acc: 0.6774\n",
      "Epoch 180/5000\n",
      "2252/2252 [==============================] - 1s 597us/step - loss: 0.0964 - acc: 0.6936 - val_loss: 0.0995 - val_acc: 0.6736\n",
      "Epoch 181/5000\n",
      "2252/2252 [==============================] - 1s 585us/step - loss: 0.0958 - acc: 0.7014 - val_loss: 0.0997 - val_acc: 0.6760\n",
      "Epoch 182/5000\n",
      "2252/2252 [==============================] - 1s 589us/step - loss: 0.0956 - acc: 0.6954 - val_loss: 0.1011 - val_acc: 0.6715\n",
      "Epoch 183/5000\n",
      "2252/2252 [==============================] - 1s 596us/step - loss: 0.0970 - acc: 0.6931 - val_loss: 0.0988 - val_acc: 0.6807\n",
      "Epoch 184/5000\n",
      "2252/2252 [==============================] - 1s 590us/step - loss: 0.0957 - acc: 0.6975 - val_loss: 0.0998 - val_acc: 0.6765\n",
      "Epoch 185/5000\n",
      "2252/2252 [==============================] - 1s 585us/step - loss: 0.0956 - acc: 0.6962 - val_loss: 0.0994 - val_acc: 0.6769\n",
      "Epoch 186/5000\n",
      "2252/2252 [==============================] - 1s 590us/step - loss: 0.0956 - acc: 0.6973 - val_loss: 0.0988 - val_acc: 0.6807\n",
      "Epoch 187/5000\n",
      "2252/2252 [==============================] - 1s 576us/step - loss: 0.0950 - acc: 0.6972 - val_loss: 0.0982 - val_acc: 0.6816\n",
      "Epoch 188/5000\n",
      "2252/2252 [==============================] - 1s 604us/step - loss: 0.0950 - acc: 0.6984 - val_loss: 0.0996 - val_acc: 0.6752\n",
      "Epoch 189/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.0958 - acc: 0.6947 - val_loss: 0.1022 - val_acc: 0.6720\n",
      "Epoch 190/5000\n",
      "2252/2252 [==============================] - 1s 590us/step - loss: 0.0942 - acc: 0.6999 - val_loss: 0.0977 - val_acc: 0.6830\n",
      "Epoch 191/5000\n",
      "2252/2252 [==============================] - 1s 588us/step - loss: 0.0949 - acc: 0.6980 - val_loss: 0.1001 - val_acc: 0.6758\n",
      "Epoch 192/5000\n",
      "2252/2252 [==============================] - 1s 592us/step - loss: 0.0940 - acc: 0.7035 - val_loss: 0.0977 - val_acc: 0.6830\n",
      "Epoch 193/5000\n",
      "2252/2252 [==============================] - 1s 592us/step - loss: 0.0939 - acc: 0.7029 - val_loss: 0.0990 - val_acc: 0.6779\n",
      "Epoch 194/5000\n",
      "2252/2252 [==============================] - 1s 590us/step - loss: 0.0937 - acc: 0.7011 - val_loss: 0.0973 - val_acc: 0.6840\n",
      "Epoch 195/5000\n",
      "2252/2252 [==============================] - 1s 592us/step - loss: 0.0938 - acc: 0.7040 - val_loss: 0.1038 - val_acc: 0.6678\n",
      "Epoch 196/5000\n",
      "2252/2252 [==============================] - 1s 584us/step - loss: 0.0949 - acc: 0.6969 - val_loss: 0.0976 - val_acc: 0.6847\n",
      "Epoch 197/5000\n",
      "2252/2252 [==============================] - 1s 600us/step - loss: 0.0936 - acc: 0.7022 - val_loss: 0.0976 - val_acc: 0.6841\n",
      "Epoch 198/5000\n",
      "2252/2252 [==============================] - 1s 598us/step - loss: 0.0936 - acc: 0.7014 - val_loss: 0.0969 - val_acc: 0.6879\n",
      "Epoch 199/5000\n",
      "2252/2252 [==============================] - 1s 595us/step - loss: 0.0934 - acc: 0.7034 - val_loss: 0.0971 - val_acc: 0.6859\n",
      "Epoch 200/5000\n",
      "2252/2252 [==============================] - 1s 597us/step - loss: 0.0928 - acc: 0.7030 - val_loss: 0.0971 - val_acc: 0.6841\n",
      "Epoch 201/5000\n",
      "2252/2252 [==============================] - 1s 576us/step - loss: 0.0930 - acc: 0.7035 - val_loss: 0.0995 - val_acc: 0.6768\n",
      "Epoch 202/5000\n",
      "2252/2252 [==============================] - 1s 587us/step - loss: 0.0930 - acc: 0.7048 - val_loss: 0.0963 - val_acc: 0.6888\n",
      "Epoch 203/5000\n",
      "2252/2252 [==============================] - 1s 596us/step - loss: 0.0921 - acc: 0.7046 - val_loss: 0.0965 - val_acc: 0.6890\n",
      "Epoch 204/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.0927 - acc: 0.7031 - val_loss: 0.0959 - val_acc: 0.6900\n",
      "Epoch 205/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.0916 - acc: 0.7092 - val_loss: 0.0968 - val_acc: 0.6876\n",
      "Epoch 206/5000\n",
      "2252/2252 [==============================] - 1s 588us/step - loss: 0.0919 - acc: 0.7089 - val_loss: 0.0994 - val_acc: 0.6795\n",
      "Epoch 207/5000\n",
      "2252/2252 [==============================] - 1s 587us/step - loss: 0.0917 - acc: 0.7058 - val_loss: 0.0975 - val_acc: 0.6850\n",
      "Epoch 208/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.0924 - acc: 0.7068 - val_loss: 0.0963 - val_acc: 0.6877\n",
      "Epoch 209/5000\n",
      "2252/2252 [==============================] - 1s 601us/step - loss: 0.0918 - acc: 0.7096 - val_loss: 0.0979 - val_acc: 0.6833\n",
      "Epoch 210/5000\n",
      "2252/2252 [==============================] - 1s 589us/step - loss: 0.0915 - acc: 0.7097 - val_loss: 0.1022 - val_acc: 0.6736\n",
      "Epoch 211/5000\n",
      "2252/2252 [==============================] - 1s 602us/step - loss: 0.0921 - acc: 0.7054 - val_loss: 0.0958 - val_acc: 0.6884\n",
      "Epoch 212/5000\n",
      "2252/2252 [==============================] - 1s 598us/step - loss: 0.0920 - acc: 0.7088 - val_loss: 0.0970 - val_acc: 0.6887\n",
      "Epoch 213/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.0919 - acc: 0.7059 - val_loss: 0.1020 - val_acc: 0.6750\n",
      "Epoch 214/5000\n",
      "2252/2252 [==============================] - 1s 590us/step - loss: 0.0917 - acc: 0.7083 - val_loss: 0.0977 - val_acc: 0.6831\n",
      "Epoch 215/5000\n",
      "2252/2252 [==============================] - 1s 601us/step - loss: 0.0915 - acc: 0.7080 - val_loss: 0.0974 - val_acc: 0.6852\n",
      "Epoch 216/5000\n",
      "2252/2252 [==============================] - 1s 586us/step - loss: 0.0912 - acc: 0.7096 - val_loss: 0.0954 - val_acc: 0.6927\n",
      "Epoch 217/5000\n",
      "2252/2252 [==============================] - 1s 604us/step - loss: 0.0913 - acc: 0.7109 - val_loss: 0.0964 - val_acc: 0.6815\n",
      "Epoch 218/5000\n",
      "2252/2252 [==============================] - 1s 589us/step - loss: 0.0903 - acc: 0.7172 - val_loss: 0.0956 - val_acc: 0.6893\n",
      "Epoch 219/5000\n",
      "2252/2252 [==============================] - 1s 597us/step - loss: 0.0909 - acc: 0.7091 - val_loss: 0.0959 - val_acc: 0.6903\n",
      "Epoch 220/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.0901 - acc: 0.7112 - val_loss: 0.0951 - val_acc: 0.6936\n",
      "Epoch 221/5000\n",
      "2252/2252 [==============================] - 1s 595us/step - loss: 0.0903 - acc: 0.7153 - val_loss: 0.0963 - val_acc: 0.6836\n",
      "Epoch 222/5000\n",
      "2252/2252 [==============================] - 1s 607us/step - loss: 0.0902 - acc: 0.7125 - val_loss: 0.0947 - val_acc: 0.6939\n",
      "Epoch 223/5000\n",
      "2252/2252 [==============================] - 1s 599us/step - loss: 0.0918 - acc: 0.7059 - val_loss: 0.0955 - val_acc: 0.6924\n",
      "Epoch 224/5000\n",
      "2252/2252 [==============================] - 1s 576us/step - loss: 0.0900 - acc: 0.7134 - val_loss: 0.0946 - val_acc: 0.6931\n",
      "Epoch 225/5000\n",
      "2252/2252 [==============================] - 1s 596us/step - loss: 0.0907 - acc: 0.7119 - val_loss: 0.0945 - val_acc: 0.6955\n",
      "Epoch 226/5000\n",
      "2252/2252 [==============================] - 1s 588us/step - loss: 0.0894 - acc: 0.7154 - val_loss: 0.0954 - val_acc: 0.6935\n",
      "Epoch 227/5000\n",
      "2252/2252 [==============================] - 1s 571us/step - loss: 0.0899 - acc: 0.7171 - val_loss: 0.0947 - val_acc: 0.6963\n",
      "Epoch 228/5000\n",
      "2252/2252 [==============================] - 1s 587us/step - loss: 0.0902 - acc: 0.7134 - val_loss: 0.0944 - val_acc: 0.6952\n",
      "Epoch 229/5000\n",
      "2252/2252 [==============================] - 1s 604us/step - loss: 0.0895 - acc: 0.7148 - val_loss: 0.0945 - val_acc: 0.6954\n",
      "Epoch 230/5000\n",
      "2252/2252 [==============================] - 1s 592us/step - loss: 0.0899 - acc: 0.7167 - val_loss: 0.0965 - val_acc: 0.6902\n",
      "Epoch 231/5000\n",
      "2252/2252 [==============================] - 1s 586us/step - loss: 0.0894 - acc: 0.7169 - val_loss: 0.0951 - val_acc: 0.6947\n",
      "Epoch 232/5000\n",
      "2252/2252 [==============================] - 1s 598us/step - loss: 0.0887 - acc: 0.7188 - val_loss: 0.0952 - val_acc: 0.6941\n",
      "Epoch 233/5000\n",
      "2252/2252 [==============================] - 1s 590us/step - loss: 0.0896 - acc: 0.7166 - val_loss: 0.0943 - val_acc: 0.6978\n",
      "Epoch 234/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2252/2252 [==============================] - 1s 595us/step - loss: 0.0882 - acc: 0.7195 - val_loss: 0.0945 - val_acc: 0.6976\n",
      "Epoch 235/5000\n",
      "2252/2252 [==============================] - 1s 585us/step - loss: 0.0889 - acc: 0.7175 - val_loss: 0.0961 - val_acc: 0.6914\n",
      "Epoch 236/5000\n",
      "2252/2252 [==============================] - 1s 598us/step - loss: 0.0884 - acc: 0.7226 - val_loss: 0.0942 - val_acc: 0.6963\n",
      "Epoch 237/5000\n",
      "2252/2252 [==============================] - 1s 576us/step - loss: 0.0891 - acc: 0.7181 - val_loss: 0.0949 - val_acc: 0.6965\n",
      "Epoch 238/5000\n",
      "2252/2252 [==============================] - 1s 587us/step - loss: 0.0892 - acc: 0.7169 - val_loss: 0.0937 - val_acc: 0.6984\n",
      "Epoch 239/5000\n",
      "2252/2252 [==============================] - 1s 586us/step - loss: 0.0881 - acc: 0.7220 - val_loss: 0.0945 - val_acc: 0.6969\n",
      "Epoch 240/5000\n",
      "2252/2252 [==============================] - 1s 603us/step - loss: 0.0879 - acc: 0.7214 - val_loss: 0.0936 - val_acc: 0.6995\n",
      "Epoch 241/5000\n",
      "2252/2252 [==============================] - 1s 596us/step - loss: 0.0886 - acc: 0.7180 - val_loss: 0.0938 - val_acc: 0.6950\n",
      "Epoch 242/5000\n",
      "2252/2252 [==============================] - 1s 589us/step - loss: 0.0884 - acc: 0.7200 - val_loss: 0.0939 - val_acc: 0.6986\n",
      "Epoch 243/5000\n",
      "2252/2252 [==============================] - 1s 574us/step - loss: 0.0886 - acc: 0.7168 - val_loss: 0.0945 - val_acc: 0.6974\n",
      "Epoch 244/5000\n",
      "2252/2252 [==============================] - 1s 600us/step - loss: 0.0886 - acc: 0.7210 - val_loss: 0.0956 - val_acc: 0.6934\n",
      "Epoch 245/5000\n",
      "2252/2252 [==============================] - 1s 585us/step - loss: 0.0882 - acc: 0.7225 - val_loss: 0.0962 - val_acc: 0.6936\n",
      "Epoch 246/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.0878 - acc: 0.7250 - val_loss: 0.0934 - val_acc: 0.6961\n",
      "Epoch 247/5000\n",
      "2252/2252 [==============================] - 1s 598us/step - loss: 0.0870 - acc: 0.7284 - val_loss: 0.0956 - val_acc: 0.6955\n",
      "Epoch 248/5000\n",
      "2252/2252 [==============================] - 1s 602us/step - loss: 0.0880 - acc: 0.7245 - val_loss: 0.0932 - val_acc: 0.6995\n",
      "Epoch 249/5000\n",
      "2252/2252 [==============================] - 1s 597us/step - loss: 0.0878 - acc: 0.7247 - val_loss: 0.0933 - val_acc: 0.6976\n",
      "Epoch 250/5000\n",
      "2252/2252 [==============================] - 1s 589us/step - loss: 0.0872 - acc: 0.7263 - val_loss: 0.0934 - val_acc: 0.7008\n",
      "Epoch 251/5000\n",
      "2252/2252 [==============================] - 1s 603us/step - loss: 0.0872 - acc: 0.7277 - val_loss: 0.0934 - val_acc: 0.6985\n",
      "Epoch 252/5000\n",
      "2252/2252 [==============================] - 1s 600us/step - loss: 0.0877 - acc: 0.7274 - val_loss: 0.0930 - val_acc: 0.6995\n",
      "Epoch 253/5000\n",
      "2252/2252 [==============================] - 1s 585us/step - loss: 0.0876 - acc: 0.7220 - val_loss: 0.0932 - val_acc: 0.7005\n",
      "Epoch 254/5000\n",
      "2252/2252 [==============================] - 1s 579us/step - loss: 0.0873 - acc: 0.7251 - val_loss: 0.0934 - val_acc: 0.6992\n",
      "Epoch 255/5000\n",
      "2252/2252 [==============================] - 1s 590us/step - loss: 0.0874 - acc: 0.7266 - val_loss: 0.0956 - val_acc: 0.6983\n",
      "Epoch 256/5000\n",
      "2252/2252 [==============================] - 1s 591us/step - loss: 0.0868 - acc: 0.7284 - val_loss: 0.0993 - val_acc: 0.6859\n",
      "Epoch 257/5000\n",
      "2252/2252 [==============================] - 1s 600us/step - loss: 0.0873 - acc: 0.7284 - val_loss: 0.0934 - val_acc: 0.6997\n",
      "Epoch 258/5000\n",
      "2252/2252 [==============================] - 1s 591us/step - loss: 0.0860 - acc: 0.7301 - val_loss: 0.0933 - val_acc: 0.7016\n",
      "Epoch 259/5000\n",
      "2252/2252 [==============================] - 1s 594us/step - loss: 0.0862 - acc: 0.7313 - val_loss: 0.0934 - val_acc: 0.7004\n",
      "Epoch 260/5000\n",
      "2252/2252 [==============================] - 1s 584us/step - loss: 0.0867 - acc: 0.7295 - val_loss: 0.0979 - val_acc: 0.6762\n",
      "Epoch 261/5000\n",
      "2252/2252 [==============================] - 1s 588us/step - loss: 0.0866 - acc: 0.7275 - val_loss: 0.0944 - val_acc: 0.6996\n",
      "Epoch 262/5000\n",
      "2252/2252 [==============================] - 1s 596us/step - loss: 0.0864 - acc: 0.7305 - val_loss: 0.0968 - val_acc: 0.6955\n",
      "Epoch 263/5000\n",
      "2252/2252 [==============================] - 1s 599us/step - loss: 0.0874 - acc: 0.7242 - val_loss: 0.0936 - val_acc: 0.7016\n",
      "Epoch 264/5000\n",
      "2252/2252 [==============================] - 1s 599us/step - loss: 0.0863 - acc: 0.7300 - val_loss: 0.0932 - val_acc: 0.6973\n",
      "Epoch 265/5000\n",
      "2252/2252 [==============================] - 1s 594us/step - loss: 0.0870 - acc: 0.7268 - val_loss: 0.0945 - val_acc: 0.7023\n",
      "Epoch 266/5000\n",
      "2252/2252 [==============================] - 1s 586us/step - loss: 0.0865 - acc: 0.7286 - val_loss: 0.0947 - val_acc: 0.6994\n",
      "Epoch 267/5000\n",
      "2252/2252 [==============================] - 1s 601us/step - loss: 0.0871 - acc: 0.7268 - val_loss: 0.0927 - val_acc: 0.6985\n",
      "Epoch 268/5000\n",
      "2252/2252 [==============================] - 1s 587us/step - loss: 0.0863 - acc: 0.7304 - val_loss: 0.0937 - val_acc: 0.7024\n",
      "Epoch 269/5000\n",
      "2252/2252 [==============================] - 1s 583us/step - loss: 0.0851 - acc: 0.7350 - val_loss: 0.0943 - val_acc: 0.7004\n",
      "Epoch 270/5000\n",
      "2252/2252 [==============================] - 1s 583us/step - loss: 0.0856 - acc: 0.7359 - val_loss: 0.0926 - val_acc: 0.7043\n",
      "Epoch 271/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.0852 - acc: 0.7368 - val_loss: 0.0939 - val_acc: 0.7014\n",
      "Epoch 272/5000\n",
      "2252/2252 [==============================] - 1s 598us/step - loss: 0.0848 - acc: 0.7388 - val_loss: 0.0927 - val_acc: 0.7026\n",
      "Epoch 273/5000\n",
      "2252/2252 [==============================] - 1s 592us/step - loss: 0.0855 - acc: 0.7354 - val_loss: 0.0922 - val_acc: 0.7040\n",
      "Epoch 274/5000\n",
      "2252/2252 [==============================] - 1s 591us/step - loss: 0.0846 - acc: 0.7393 - val_loss: 0.0927 - val_acc: 0.7028\n",
      "Epoch 275/5000\n",
      "2252/2252 [==============================] - 1s 598us/step - loss: 0.0855 - acc: 0.7330 - val_loss: 0.0990 - val_acc: 0.6861\n",
      "Epoch 276/5000\n",
      "2252/2252 [==============================] - 1s 595us/step - loss: 0.0852 - acc: 0.7374 - val_loss: 0.0924 - val_acc: 0.7013\n",
      "Epoch 277/5000\n",
      "2252/2252 [==============================] - 1s 603us/step - loss: 0.0852 - acc: 0.7368 - val_loss: 0.0928 - val_acc: 0.7061\n",
      "Epoch 278/5000\n",
      "2252/2252 [==============================] - 1s 601us/step - loss: 0.0848 - acc: 0.7367 - val_loss: 0.0920 - val_acc: 0.7086\n",
      "Epoch 279/5000\n",
      "2252/2252 [==============================] - 1s 601us/step - loss: 0.0844 - acc: 0.7378 - val_loss: 0.0929 - val_acc: 0.7062\n",
      "Epoch 280/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.0846 - acc: 0.7379 - val_loss: 0.0965 - val_acc: 0.6961\n",
      "Epoch 281/5000\n",
      "2252/2252 [==============================] - 1s 600us/step - loss: 0.0854 - acc: 0.7366 - val_loss: 0.0926 - val_acc: 0.7072\n",
      "Epoch 282/5000\n",
      "2252/2252 [==============================] - 1s 584us/step - loss: 0.0847 - acc: 0.7385 - val_loss: 0.0925 - val_acc: 0.7081\n",
      "Epoch 283/5000\n",
      "2252/2252 [==============================] - 1s 587us/step - loss: 0.0846 - acc: 0.7387 - val_loss: 0.0938 - val_acc: 0.7052\n",
      "Epoch 284/5000\n",
      "2252/2252 [==============================] - 1s 592us/step - loss: 0.0850 - acc: 0.7389 - val_loss: 0.0923 - val_acc: 0.7016\n",
      "Epoch 285/5000\n",
      "2252/2252 [==============================] - 1s 591us/step - loss: 0.0848 - acc: 0.7396 - val_loss: 0.0927 - val_acc: 0.7017\n",
      "Epoch 286/5000\n",
      "2252/2252 [==============================] - 1s 596us/step - loss: 0.0846 - acc: 0.7417 - val_loss: 0.0919 - val_acc: 0.7059\n",
      "Epoch 287/5000\n",
      "2252/2252 [==============================] - 1s 590us/step - loss: 0.0840 - acc: 0.7430 - val_loss: 0.0920 - val_acc: 0.7089\n",
      "Epoch 288/5000\n",
      "2252/2252 [==============================] - 1s 602us/step - loss: 0.0836 - acc: 0.7466 - val_loss: 0.0922 - val_acc: 0.7030\n",
      "Epoch 289/5000\n",
      "2252/2252 [==============================] - 1s 601us/step - loss: 0.0847 - acc: 0.7367 - val_loss: 0.0922 - val_acc: 0.7071\n",
      "Epoch 290/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.0839 - acc: 0.7428 - val_loss: 0.0919 - val_acc: 0.7054\n",
      "Epoch 291/5000\n",
      "2252/2252 [==============================] - 1s 588us/step - loss: 0.0835 - acc: 0.7453 - val_loss: 0.0918 - val_acc: 0.7082\n",
      "Epoch 292/5000\n",
      "2252/2252 [==============================] - 1s 599us/step - loss: 0.0835 - acc: 0.7455 - val_loss: 0.0944 - val_acc: 0.6921\n",
      "Epoch 293/5000\n",
      "2252/2252 [==============================] - 1s 594us/step - loss: 0.0842 - acc: 0.7437 - val_loss: 0.0916 - val_acc: 0.7071\n",
      "Epoch 294/5000\n",
      "2252/2252 [==============================] - 1s 580us/step - loss: 0.0835 - acc: 0.7447 - val_loss: 0.0916 - val_acc: 0.7110\n",
      "Epoch 295/5000\n",
      "2252/2252 [==============================] - 1s 577us/step - loss: 0.0829 - acc: 0.7475 - val_loss: 0.0940 - val_acc: 0.7056\n",
      "Epoch 296/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.0834 - acc: 0.7459 - val_loss: 0.0917 - val_acc: 0.7086\n",
      "Epoch 297/5000\n",
      "2252/2252 [==============================] - 1s 592us/step - loss: 0.0840 - acc: 0.7457 - val_loss: 0.0918 - val_acc: 0.7116\n",
      "Epoch 298/5000\n",
      "2252/2252 [==============================] - 1s 590us/step - loss: 0.0832 - acc: 0.7475 - val_loss: 0.0932 - val_acc: 0.7079\n",
      "Epoch 299/5000\n",
      "2252/2252 [==============================] - 1s 587us/step - loss: 0.0823 - acc: 0.7533 - val_loss: 0.0914 - val_acc: 0.7116\n",
      "Epoch 300/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.0821 - acc: 0.7524 - val_loss: 0.0922 - val_acc: 0.7116\n",
      "Epoch 301/5000\n",
      "2252/2252 [==============================] - 1s 606us/step - loss: 0.0820 - acc: 0.7531 - val_loss: 0.0919 - val_acc: 0.7116\n",
      "Epoch 302/5000\n",
      "2252/2252 [==============================] - 1s 592us/step - loss: 0.0833 - acc: 0.7463 - val_loss: 0.0922 - val_acc: 0.7125\n",
      "Epoch 303/5000\n",
      "2252/2252 [==============================] - 1s 582us/step - loss: 0.0816 - acc: 0.7540 - val_loss: 0.0922 - val_acc: 0.7131\n",
      "Epoch 304/5000\n",
      "2252/2252 [==============================] - 1s 596us/step - loss: 0.0818 - acc: 0.7552 - val_loss: 0.0914 - val_acc: 0.7133\n",
      "Epoch 305/5000\n",
      "2252/2252 [==============================] - 1s 603us/step - loss: 0.0818 - acc: 0.7539 - val_loss: 0.0914 - val_acc: 0.7090\n",
      "Epoch 306/5000\n",
      "2252/2252 [==============================] - 1s 592us/step - loss: 0.0822 - acc: 0.7520 - val_loss: 0.0941 - val_acc: 0.7080\n",
      "Epoch 307/5000\n",
      "2252/2252 [==============================] - 1s 598us/step - loss: 0.0816 - acc: 0.7524 - val_loss: 0.0915 - val_acc: 0.7075\n",
      "Epoch 308/5000\n",
      "2252/2252 [==============================] - 1s 588us/step - loss: 0.0816 - acc: 0.7564 - val_loss: 0.0916 - val_acc: 0.7138\n",
      "Epoch 309/5000\n",
      "2252/2252 [==============================] - 1s 588us/step - loss: 0.0818 - acc: 0.7541 - val_loss: 0.0940 - val_acc: 0.7082\n",
      "Epoch 310/5000\n",
      "2252/2252 [==============================] - 1s 590us/step - loss: 0.0825 - acc: 0.7477 - val_loss: 0.0938 - val_acc: 0.7073\n",
      "Epoch 311/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.0815 - acc: 0.7575 - val_loss: 0.0911 - val_acc: 0.7147\n",
      "Epoch 312/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.0810 - acc: 0.7577 - val_loss: 0.0914 - val_acc: 0.7166\n",
      "Epoch 313/5000\n",
      "2252/2252 [==============================] - 1s 592us/step - loss: 0.0804 - acc: 0.7606 - val_loss: 0.0910 - val_acc: 0.7146\n",
      "Epoch 314/5000\n",
      "2252/2252 [==============================] - 1s 594us/step - loss: 0.0805 - acc: 0.7617 - val_loss: 0.0910 - val_acc: 0.7126\n",
      "Epoch 315/5000\n",
      "2252/2252 [==============================] - 1s 606us/step - loss: 0.0815 - acc: 0.7560 - val_loss: 0.0919 - val_acc: 0.7124\n",
      "Epoch 316/5000\n",
      "2252/2252 [==============================] - 1s 588us/step - loss: 0.0807 - acc: 0.7607 - val_loss: 0.0910 - val_acc: 0.7166\n",
      "Epoch 317/5000\n",
      "2252/2252 [==============================] - 1s 598us/step - loss: 0.0819 - acc: 0.7534 - val_loss: 0.0932 - val_acc: 0.7075\n",
      "Epoch 318/5000\n",
      "2252/2252 [==============================] - 1s 587us/step - loss: 0.0808 - acc: 0.7616 - val_loss: 0.0939 - val_acc: 0.7092\n",
      "Epoch 319/5000\n",
      "2252/2252 [==============================] - 1s 590us/step - loss: 0.0808 - acc: 0.7585 - val_loss: 0.0921 - val_acc: 0.7116\n",
      "Epoch 320/5000\n",
      "2252/2252 [==============================] - 1s 595us/step - loss: 0.0805 - acc: 0.7588 - val_loss: 0.0908 - val_acc: 0.7144\n",
      "Epoch 321/5000\n",
      "2252/2252 [==============================] - 1s 584us/step - loss: 0.0805 - acc: 0.7581 - val_loss: 0.0904 - val_acc: 0.7168\n",
      "Epoch 322/5000\n",
      "2252/2252 [==============================] - 1s 589us/step - loss: 0.0809 - acc: 0.7565 - val_loss: 0.0912 - val_acc: 0.7118\n",
      "Epoch 323/5000\n",
      "2252/2252 [==============================] - 1s 581us/step - loss: 0.0811 - acc: 0.7579 - val_loss: 0.0913 - val_acc: 0.7162\n",
      "Epoch 324/5000\n",
      "2252/2252 [==============================] - 1s 591us/step - loss: 0.0800 - acc: 0.7635 - val_loss: 0.0909 - val_acc: 0.7130\n",
      "Epoch 325/5000\n",
      "2252/2252 [==============================] - 1s 589us/step - loss: 0.0800 - acc: 0.7665 - val_loss: 0.0914 - val_acc: 0.7178\n",
      "Epoch 326/5000\n",
      "2252/2252 [==============================] - 1s 584us/step - loss: 0.0797 - acc: 0.7658 - val_loss: 0.0926 - val_acc: 0.7157\n",
      "Epoch 327/5000\n",
      "2252/2252 [==============================] - 1s 587us/step - loss: 0.0799 - acc: 0.7624 - val_loss: 0.0900 - val_acc: 0.7181\n",
      "Epoch 328/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.0797 - acc: 0.7642 - val_loss: 0.0901 - val_acc: 0.7175\n",
      "Epoch 329/5000\n",
      "2252/2252 [==============================] - 1s 587us/step - loss: 0.0795 - acc: 0.7682 - val_loss: 0.0904 - val_acc: 0.7190\n",
      "Epoch 330/5000\n",
      "2252/2252 [==============================] - 1s 599us/step - loss: 0.0795 - acc: 0.7665 - val_loss: 0.0901 - val_acc: 0.7182\n",
      "Epoch 331/5000\n",
      "2252/2252 [==============================] - 1s 590us/step - loss: 0.0792 - acc: 0.7646 - val_loss: 0.0910 - val_acc: 0.7181\n",
      "Epoch 332/5000\n",
      "2252/2252 [==============================] - 1s 590us/step - loss: 0.0790 - acc: 0.7692 - val_loss: 0.0914 - val_acc: 0.7097\n",
      "Epoch 333/5000\n",
      "2252/2252 [==============================] - 1s 604us/step - loss: 0.0794 - acc: 0.7623 - val_loss: 0.0948 - val_acc: 0.7056\n",
      "Epoch 334/5000\n",
      "2252/2252 [==============================] - 1s 599us/step - loss: 0.0794 - acc: 0.7673 - val_loss: 0.0943 - val_acc: 0.7059\n",
      "Epoch 335/5000\n",
      "2252/2252 [==============================] - 1s 589us/step - loss: 0.0783 - acc: 0.7736 - val_loss: 0.0923 - val_acc: 0.7168\n",
      "Epoch 336/5000\n",
      "2252/2252 [==============================] - 1s 592us/step - loss: 0.0783 - acc: 0.7679 - val_loss: 0.0904 - val_acc: 0.7206\n",
      "Epoch 337/5000\n",
      "2252/2252 [==============================] - 1s 586us/step - loss: 0.0787 - acc: 0.7703 - val_loss: 0.0905 - val_acc: 0.7205\n",
      "Epoch 338/5000\n",
      "2252/2252 [==============================] - 1s 588us/step - loss: 0.0783 - acc: 0.7708 - val_loss: 0.0906 - val_acc: 0.7151\n",
      "Epoch 339/5000\n",
      "2252/2252 [==============================] - 1s 578us/step - loss: 0.0782 - acc: 0.7719 - val_loss: 0.0946 - val_acc: 0.7086\n",
      "Epoch 340/5000\n",
      "2252/2252 [==============================] - 1s 594us/step - loss: 0.0781 - acc: 0.7714 - val_loss: 0.0921 - val_acc: 0.7168\n",
      "Epoch 341/5000\n",
      "2252/2252 [==============================] - 1s 598us/step - loss: 0.0775 - acc: 0.7736 - val_loss: 0.0901 - val_acc: 0.7195\n",
      "Epoch 342/5000\n",
      "2252/2252 [==============================] - 1s 583us/step - loss: 0.0785 - acc: 0.7674 - val_loss: 0.0904 - val_acc: 0.7215\n",
      "Epoch 343/5000\n",
      "2252/2252 [==============================] - 1s 594us/step - loss: 0.0802 - acc: 0.7609 - val_loss: 0.0915 - val_acc: 0.7180\n",
      "Epoch 344/5000\n",
      "2252/2252 [==============================] - 1s 588us/step - loss: 0.0778 - acc: 0.7756 - val_loss: 0.0894 - val_acc: 0.7227\n",
      "Epoch 345/5000\n",
      "2252/2252 [==============================] - 1s 600us/step - loss: 0.0780 - acc: 0.7718 - val_loss: 0.0896 - val_acc: 0.7195\n",
      "Epoch 346/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.0793 - acc: 0.7646 - val_loss: 0.0912 - val_acc: 0.7164\n",
      "Epoch 347/5000\n",
      "2252/2252 [==============================] - 1s 592us/step - loss: 0.0782 - acc: 0.7713 - val_loss: 0.0905 - val_acc: 0.7175\n",
      "Epoch 348/5000\n",
      "2252/2252 [==============================] - 1s 571us/step - loss: 0.0778 - acc: 0.7709 - val_loss: 0.0897 - val_acc: 0.7235\n",
      "Epoch 349/5000\n",
      "2252/2252 [==============================] - 1s 597us/step - loss: 0.0770 - acc: 0.7753 - val_loss: 0.0924 - val_acc: 0.7167\n",
      "Epoch 350/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2252/2252 [==============================] - 1s 591us/step - loss: 0.0801 - acc: 0.7642 - val_loss: 0.0935 - val_acc: 0.7117\n",
      "Epoch 351/5000\n",
      "2252/2252 [==============================] - 1s 602us/step - loss: 0.0793 - acc: 0.7637 - val_loss: 0.0917 - val_acc: 0.7153\n",
      "Epoch 352/5000\n",
      "2252/2252 [==============================] - 1s 595us/step - loss: 0.0783 - acc: 0.7686 - val_loss: 0.0899 - val_acc: 0.7202\n",
      "Epoch 353/5000\n",
      "2252/2252 [==============================] - 1s 603us/step - loss: 0.0767 - acc: 0.7792 - val_loss: 0.0902 - val_acc: 0.7223\n",
      "Epoch 354/5000\n",
      "2252/2252 [==============================] - 1s 598us/step - loss: 0.0766 - acc: 0.7771 - val_loss: 0.0893 - val_acc: 0.7242\n",
      "Epoch 355/5000\n",
      "2252/2252 [==============================] - 1s 599us/step - loss: 0.0751 - acc: 0.7839 - val_loss: 0.0955 - val_acc: 0.7057\n",
      "Epoch 356/5000\n",
      "2252/2252 [==============================] - 1s 599us/step - loss: 0.0758 - acc: 0.7819 - val_loss: 0.0891 - val_acc: 0.7246\n",
      "Epoch 357/5000\n",
      "2252/2252 [==============================] - 1s 592us/step - loss: 0.0756 - acc: 0.7845 - val_loss: 0.0909 - val_acc: 0.7199\n",
      "Epoch 358/5000\n",
      "2252/2252 [==============================] - 1s 588us/step - loss: 0.0755 - acc: 0.7837 - val_loss: 0.0894 - val_acc: 0.7248\n",
      "Epoch 359/5000\n",
      "2252/2252 [==============================] - 1s 580us/step - loss: 0.0753 - acc: 0.7839 - val_loss: 0.0902 - val_acc: 0.7246\n",
      "Epoch 360/5000\n",
      "2252/2252 [==============================] - 1s 584us/step - loss: 0.0751 - acc: 0.7817 - val_loss: 0.0914 - val_acc: 0.7162\n",
      "Epoch 361/5000\n",
      "2252/2252 [==============================] - 1s 594us/step - loss: 0.0760 - acc: 0.7786 - val_loss: 0.0890 - val_acc: 0.7259\n",
      "Epoch 362/5000\n",
      "2252/2252 [==============================] - 1s 595us/step - loss: 0.0753 - acc: 0.7837 - val_loss: 0.0891 - val_acc: 0.7248\n",
      "Epoch 363/5000\n",
      "2252/2252 [==============================] - 1s 573us/step - loss: 0.0764 - acc: 0.7783 - val_loss: 0.0909 - val_acc: 0.7204\n",
      "Epoch 364/5000\n",
      "2252/2252 [==============================] - 1s 585us/step - loss: 0.0743 - acc: 0.7871 - val_loss: 0.0896 - val_acc: 0.7247\n",
      "Epoch 365/5000\n",
      "2252/2252 [==============================] - 1s 590us/step - loss: 0.0743 - acc: 0.7889 - val_loss: 0.0886 - val_acc: 0.7274\n",
      "Epoch 366/5000\n",
      "2252/2252 [==============================] - 1s 600us/step - loss: 0.0759 - acc: 0.7807 - val_loss: 0.0898 - val_acc: 0.7206\n",
      "Epoch 367/5000\n",
      "2252/2252 [==============================] - 1s 597us/step - loss: 0.0768 - acc: 0.7766 - val_loss: 0.0904 - val_acc: 0.7230\n",
      "Epoch 368/5000\n",
      "2252/2252 [==============================] - 1s 587us/step - loss: 0.0757 - acc: 0.7822 - val_loss: 0.0954 - val_acc: 0.7071\n",
      "Epoch 369/5000\n",
      "2252/2252 [==============================] - 1s 588us/step - loss: 0.0737 - acc: 0.7914 - val_loss: 0.0896 - val_acc: 0.7235\n",
      "Epoch 370/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.0750 - acc: 0.7851 - val_loss: 0.0905 - val_acc: 0.7221\n",
      "Epoch 371/5000\n",
      "2252/2252 [==============================] - 1s 592us/step - loss: 0.0746 - acc: 0.7867 - val_loss: 0.0883 - val_acc: 0.7312\n",
      "Epoch 372/5000\n",
      "2252/2252 [==============================] - 1s 598us/step - loss: 0.0737 - acc: 0.7876 - val_loss: 0.0891 - val_acc: 0.7254\n",
      "Epoch 373/5000\n",
      "2252/2252 [==============================] - 1s 594us/step - loss: 0.0742 - acc: 0.7880 - val_loss: 0.0891 - val_acc: 0.7275\n",
      "Epoch 374/5000\n",
      "2252/2252 [==============================] - 1s 592us/step - loss: 0.0725 - acc: 0.7929 - val_loss: 0.0891 - val_acc: 0.7268\n",
      "Epoch 375/5000\n",
      "2252/2252 [==============================] - 1s 605us/step - loss: 0.0730 - acc: 0.7909 - val_loss: 0.0880 - val_acc: 0.7302\n",
      "Epoch 376/5000\n",
      "2252/2252 [==============================] - 1s 588us/step - loss: 0.0732 - acc: 0.7895 - val_loss: 0.0899 - val_acc: 0.7252\n",
      "Epoch 377/5000\n",
      "2252/2252 [==============================] - 1s 596us/step - loss: 0.0729 - acc: 0.7925 - val_loss: 0.0888 - val_acc: 0.7263\n",
      "Epoch 378/5000\n",
      "2252/2252 [==============================] - 1s 599us/step - loss: 0.0730 - acc: 0.7907 - val_loss: 0.0885 - val_acc: 0.7282\n",
      "Epoch 379/5000\n",
      "2252/2252 [==============================] - 1s 591us/step - loss: 0.0734 - acc: 0.7903 - val_loss: 0.0884 - val_acc: 0.7315\n",
      "Epoch 380/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.0732 - acc: 0.7895 - val_loss: 0.0886 - val_acc: 0.7252\n",
      "Epoch 381/5000\n",
      "2252/2252 [==============================] - 1s 590us/step - loss: 0.0725 - acc: 0.7922 - val_loss: 0.0882 - val_acc: 0.7299\n",
      "Epoch 382/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.0741 - acc: 0.7860 - val_loss: 0.0879 - val_acc: 0.7298\n",
      "Epoch 383/5000\n",
      "2252/2252 [==============================] - 1s 604us/step - loss: 0.0717 - acc: 0.7998 - val_loss: 0.0874 - val_acc: 0.7330\n",
      "Epoch 384/5000\n",
      "2252/2252 [==============================] - 1s 607us/step - loss: 0.0725 - acc: 0.7907 - val_loss: 0.0881 - val_acc: 0.7326\n",
      "Epoch 385/5000\n",
      "2252/2252 [==============================] - 1s 608us/step - loss: 0.0722 - acc: 0.7954 - val_loss: 0.0879 - val_acc: 0.7314\n",
      "Epoch 386/5000\n",
      "2252/2252 [==============================] - 1s 592us/step - loss: 0.0717 - acc: 0.7986 - val_loss: 0.0884 - val_acc: 0.7307\n",
      "Epoch 387/5000\n",
      "2252/2252 [==============================] - 1s 590us/step - loss: 0.0732 - acc: 0.7879 - val_loss: 0.0895 - val_acc: 0.7268\n",
      "Epoch 388/5000\n",
      "2252/2252 [==============================] - 1s 597us/step - loss: 0.0738 - acc: 0.7884 - val_loss: 0.0910 - val_acc: 0.7216\n",
      "Epoch 389/5000\n",
      "2252/2252 [==============================] - 1s 591us/step - loss: 0.0719 - acc: 0.7966 - val_loss: 0.0881 - val_acc: 0.7311\n",
      "Epoch 390/5000\n",
      "2252/2252 [==============================] - 1s 579us/step - loss: 0.0728 - acc: 0.7927 - val_loss: 0.0881 - val_acc: 0.7324\n",
      "Epoch 391/5000\n",
      "2252/2252 [==============================] - 1s 580us/step - loss: 0.0714 - acc: 0.7974 - val_loss: 0.0881 - val_acc: 0.7316\n",
      "Epoch 392/5000\n",
      "2252/2252 [==============================] - 1s 596us/step - loss: 0.0709 - acc: 0.7980 - val_loss: 0.0876 - val_acc: 0.7359\n",
      "Epoch 393/5000\n",
      "2252/2252 [==============================] - 1s 605us/step - loss: 0.0707 - acc: 0.8001 - val_loss: 0.0878 - val_acc: 0.7326\n",
      "Epoch 394/5000\n",
      "2252/2252 [==============================] - 1s 599us/step - loss: 0.0707 - acc: 0.8002 - val_loss: 0.0873 - val_acc: 0.7366\n",
      "Epoch 395/5000\n",
      "2252/2252 [==============================] - 1s 597us/step - loss: 0.0697 - acc: 0.8064 - val_loss: 0.0875 - val_acc: 0.7345\n",
      "Epoch 396/5000\n",
      "2252/2252 [==============================] - 1s 606us/step - loss: 0.0715 - acc: 0.7955 - val_loss: 0.0894 - val_acc: 0.7275\n",
      "Epoch 397/5000\n",
      "2252/2252 [==============================] - 1s 598us/step - loss: 0.0715 - acc: 0.7961 - val_loss: 0.0877 - val_acc: 0.7333\n",
      "Epoch 398/5000\n",
      "2252/2252 [==============================] - 1s 599us/step - loss: 0.0703 - acc: 0.8013 - val_loss: 0.0890 - val_acc: 0.7311\n",
      "Epoch 399/5000\n",
      "2252/2252 [==============================] - 1s 591us/step - loss: 0.0703 - acc: 0.8019 - val_loss: 0.0865 - val_acc: 0.7391\n",
      "Epoch 400/5000\n",
      "2252/2252 [==============================] - 1s 586us/step - loss: 0.0703 - acc: 0.8013 - val_loss: 0.0875 - val_acc: 0.7360\n",
      "Epoch 401/5000\n",
      "2252/2252 [==============================] - 1s 591us/step - loss: 0.0703 - acc: 0.8019 - val_loss: 0.0871 - val_acc: 0.7333\n",
      "Epoch 402/5000\n",
      "2252/2252 [==============================] - 1s 603us/step - loss: 0.0705 - acc: 0.7996 - val_loss: 0.0876 - val_acc: 0.7362\n",
      "Epoch 403/5000\n",
      "2252/2252 [==============================] - 1s 587us/step - loss: 0.0705 - acc: 0.7986 - val_loss: 0.0865 - val_acc: 0.7405\n",
      "Epoch 404/5000\n",
      "2252/2252 [==============================] - 1s 595us/step - loss: 0.0689 - acc: 0.8075 - val_loss: 0.0886 - val_acc: 0.7314\n",
      "Epoch 405/5000\n",
      "2252/2252 [==============================] - 1s 589us/step - loss: 0.0698 - acc: 0.8012 - val_loss: 0.0871 - val_acc: 0.7387\n",
      "Epoch 406/5000\n",
      "2252/2252 [==============================] - 1s 592us/step - loss: 0.0701 - acc: 0.8011 - val_loss: 0.0882 - val_acc: 0.7319\n",
      "Epoch 407/5000\n",
      "2252/2252 [==============================] - 1s 586us/step - loss: 0.0688 - acc: 0.8066 - val_loss: 0.0863 - val_acc: 0.7394\n",
      "Epoch 408/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.0689 - acc: 0.8066 - val_loss: 0.0866 - val_acc: 0.7380\n",
      "Epoch 409/5000\n",
      "2252/2252 [==============================] - 1s 597us/step - loss: 0.0687 - acc: 0.8077 - val_loss: 0.0867 - val_acc: 0.7374\n",
      "Epoch 410/5000\n",
      "2252/2252 [==============================] - 1s 587us/step - loss: 0.0705 - acc: 0.8006 - val_loss: 0.0870 - val_acc: 0.7379\n",
      "Epoch 411/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.0681 - acc: 0.8098 - val_loss: 0.0875 - val_acc: 0.7350\n",
      "Epoch 412/5000\n",
      "2252/2252 [==============================] - 1s 586us/step - loss: 0.0694 - acc: 0.8009 - val_loss: 0.0869 - val_acc: 0.7378\n",
      "Epoch 413/5000\n",
      "2252/2252 [==============================] - 1s 603us/step - loss: 0.0688 - acc: 0.8053 - val_loss: 0.0872 - val_acc: 0.7363\n",
      "Epoch 414/5000\n",
      "2252/2252 [==============================] - 1s 605us/step - loss: 0.0679 - acc: 0.8111 - val_loss: 0.0862 - val_acc: 0.7418\n",
      "Epoch 415/5000\n",
      "2252/2252 [==============================] - 1s 591us/step - loss: 0.0687 - acc: 0.8063 - val_loss: 0.0872 - val_acc: 0.7377\n",
      "Epoch 416/5000\n",
      "2252/2252 [==============================] - 1s 599us/step - loss: 0.0672 - acc: 0.8139 - val_loss: 0.0887 - val_acc: 0.7314\n",
      "Epoch 417/5000\n",
      "2252/2252 [==============================] - 1s 591us/step - loss: 0.0687 - acc: 0.8050 - val_loss: 0.0864 - val_acc: 0.7411\n",
      "Epoch 418/5000\n",
      "2252/2252 [==============================] - 1s 600us/step - loss: 0.0677 - acc: 0.8097 - val_loss: 0.0892 - val_acc: 0.7303\n",
      "Epoch 419/5000\n",
      "2252/2252 [==============================] - 1s 584us/step - loss: 0.0701 - acc: 0.8000 - val_loss: 0.0867 - val_acc: 0.7363\n",
      "Epoch 420/5000\n",
      "2252/2252 [==============================] - 1s 591us/step - loss: 0.0668 - acc: 0.8136 - val_loss: 0.0864 - val_acc: 0.7392\n",
      "Epoch 421/5000\n",
      "2252/2252 [==============================] - 1s 590us/step - loss: 0.0669 - acc: 0.8151 - val_loss: 0.0931 - val_acc: 0.7187\n",
      "Epoch 422/5000\n",
      "2252/2252 [==============================] - 1s 590us/step - loss: 0.0672 - acc: 0.8106 - val_loss: 0.0861 - val_acc: 0.7424\n",
      "Epoch 423/5000\n",
      "2252/2252 [==============================] - 1s 584us/step - loss: 0.0661 - acc: 0.8171 - val_loss: 0.0916 - val_acc: 0.7232\n",
      "Epoch 424/5000\n",
      "2252/2252 [==============================] - 1s 588us/step - loss: 0.0675 - acc: 0.8118 - val_loss: 0.0859 - val_acc: 0.7448\n",
      "Epoch 425/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.0660 - acc: 0.8162 - val_loss: 0.0879 - val_acc: 0.7370\n",
      "Epoch 426/5000\n",
      "2252/2252 [==============================] - 1s 585us/step - loss: 0.0672 - acc: 0.8117 - val_loss: 0.0858 - val_acc: 0.7439\n",
      "Epoch 427/5000\n",
      "2252/2252 [==============================] - 1s 598us/step - loss: 0.0675 - acc: 0.8108 - val_loss: 0.0944 - val_acc: 0.7187\n",
      "Epoch 428/5000\n",
      "2252/2252 [==============================] - 1s 605us/step - loss: 0.0703 - acc: 0.7983 - val_loss: 0.0861 - val_acc: 0.7402\n",
      "Epoch 429/5000\n",
      "2252/2252 [==============================] - 1s 590us/step - loss: 0.0656 - acc: 0.8182 - val_loss: 0.0858 - val_acc: 0.7437\n",
      "Epoch 430/5000\n",
      "2252/2252 [==============================] - 1s 590us/step - loss: 0.0667 - acc: 0.8141 - val_loss: 0.0882 - val_acc: 0.7338\n",
      "Epoch 431/5000\n",
      "2252/2252 [==============================] - 1s 586us/step - loss: 0.0652 - acc: 0.8197 - val_loss: 0.0866 - val_acc: 0.7417\n",
      "Epoch 432/5000\n",
      "2252/2252 [==============================] - 1s 587us/step - loss: 0.0668 - acc: 0.8132 - val_loss: 0.0876 - val_acc: 0.7349\n",
      "Epoch 433/5000\n",
      "2252/2252 [==============================] - 1s 590us/step - loss: 0.0681 - acc: 0.8092 - val_loss: 0.0904 - val_acc: 0.7294\n",
      "Epoch 434/5000\n",
      "2252/2252 [==============================] - 1s 590us/step - loss: 0.0673 - acc: 0.8100 - val_loss: 0.0873 - val_acc: 0.7378\n",
      "Epoch 435/5000\n",
      "2252/2252 [==============================] - 1s 596us/step - loss: 0.0659 - acc: 0.8171 - val_loss: 0.0860 - val_acc: 0.7424\n",
      "Epoch 436/5000\n",
      "2252/2252 [==============================] - 1s 594us/step - loss: 0.0659 - acc: 0.8158 - val_loss: 0.0869 - val_acc: 0.7383\n",
      "Epoch 437/5000\n",
      "2252/2252 [==============================] - 1s 594us/step - loss: 0.0655 - acc: 0.8182 - val_loss: 0.0912 - val_acc: 0.7278\n",
      "Epoch 438/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.0665 - acc: 0.8133 - val_loss: 0.0914 - val_acc: 0.7254\n",
      "Epoch 439/5000\n",
      "2252/2252 [==============================] - 1s 592us/step - loss: 0.0659 - acc: 0.8158 - val_loss: 0.0859 - val_acc: 0.7458\n",
      "Epoch 440/5000\n",
      "2252/2252 [==============================] - 1s 596us/step - loss: 0.0654 - acc: 0.8187 - val_loss: 0.0889 - val_acc: 0.7313\n",
      "Epoch 441/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.0652 - acc: 0.8213 - val_loss: 0.0855 - val_acc: 0.7483\n",
      "Epoch 442/5000\n",
      "2252/2252 [==============================] - 1s 598us/step - loss: 0.0661 - acc: 0.8141 - val_loss: 0.0853 - val_acc: 0.7457\n",
      "Epoch 443/5000\n",
      "2252/2252 [==============================] - 1s 596us/step - loss: 0.0650 - acc: 0.8187 - val_loss: 0.0860 - val_acc: 0.7434\n",
      "Epoch 444/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.0657 - acc: 0.8174 - val_loss: 0.0879 - val_acc: 0.7386\n",
      "Epoch 445/5000\n",
      "2252/2252 [==============================] - 1s 601us/step - loss: 0.0654 - acc: 0.8159 - val_loss: 0.0868 - val_acc: 0.7442\n",
      "Epoch 446/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.0692 - acc: 0.8025 - val_loss: 0.0919 - val_acc: 0.7275\n",
      "Epoch 447/5000\n",
      "2252/2252 [==============================] - 1s 590us/step - loss: 0.0647 - acc: 0.8176 - val_loss: 0.0854 - val_acc: 0.7477\n",
      "Epoch 448/5000\n",
      "2252/2252 [==============================] - 1s 589us/step - loss: 0.0645 - acc: 0.8201 - val_loss: 0.0895 - val_acc: 0.7318\n",
      "Epoch 449/5000\n",
      "2252/2252 [==============================] - 1s 594us/step - loss: 0.0646 - acc: 0.8181 - val_loss: 0.0860 - val_acc: 0.7430\n",
      "Epoch 450/5000\n",
      "2252/2252 [==============================] - 1s 599us/step - loss: 0.0640 - acc: 0.8215 - val_loss: 0.0857 - val_acc: 0.7448\n",
      "Epoch 451/5000\n",
      "2252/2252 [==============================] - 1s 594us/step - loss: 0.0639 - acc: 0.8233 - val_loss: 0.0850 - val_acc: 0.7462\n",
      "Epoch 452/5000\n",
      "2252/2252 [==============================] - 1s 598us/step - loss: 0.0656 - acc: 0.8181 - val_loss: 0.0847 - val_acc: 0.7487\n",
      "Epoch 453/5000\n",
      "2252/2252 [==============================] - 1s 605us/step - loss: 0.0640 - acc: 0.8197 - val_loss: 0.0845 - val_acc: 0.7480\n",
      "Epoch 454/5000\n",
      "2252/2252 [==============================] - 1s 592us/step - loss: 0.0639 - acc: 0.8209 - val_loss: 0.0854 - val_acc: 0.7482\n",
      "Epoch 455/5000\n",
      "2252/2252 [==============================] - 1s 588us/step - loss: 0.0647 - acc: 0.8195 - val_loss: 0.0846 - val_acc: 0.7499\n",
      "Epoch 456/5000\n",
      "2252/2252 [==============================] - 1s 599us/step - loss: 0.0656 - acc: 0.8163 - val_loss: 0.0862 - val_acc: 0.7437\n",
      "Epoch 457/5000\n",
      "2252/2252 [==============================] - 1s 602us/step - loss: 0.0634 - acc: 0.8217 - val_loss: 0.0854 - val_acc: 0.7471\n",
      "Epoch 458/5000\n",
      "2252/2252 [==============================] - 1s 583us/step - loss: 0.0633 - acc: 0.8245 - val_loss: 0.0906 - val_acc: 0.7306\n",
      "Epoch 459/5000\n",
      "2252/2252 [==============================] - 1s 592us/step - loss: 0.0648 - acc: 0.8192 - val_loss: 0.0894 - val_acc: 0.7325\n",
      "Epoch 460/5000\n",
      "2252/2252 [==============================] - 1s 591us/step - loss: 0.0632 - acc: 0.8251 - val_loss: 0.0853 - val_acc: 0.7462\n",
      "Epoch 461/5000\n",
      "2252/2252 [==============================] - 1s 589us/step - loss: 0.0645 - acc: 0.8162 - val_loss: 0.0850 - val_acc: 0.7465\n",
      "Epoch 462/5000\n",
      "2252/2252 [==============================] - 1s 592us/step - loss: 0.0650 - acc: 0.8153 - val_loss: 0.0873 - val_acc: 0.7404\n",
      "Epoch 463/5000\n",
      "2252/2252 [==============================] - 1s 594us/step - loss: 0.0633 - acc: 0.8228 - val_loss: 0.0853 - val_acc: 0.7450\n",
      "Epoch 464/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.0643 - acc: 0.8204 - val_loss: 0.0847 - val_acc: 0.7501\n",
      "Epoch 465/5000\n",
      "2252/2252 [==============================] - 1s 569us/step - loss: 0.0642 - acc: 0.8206 - val_loss: 0.0846 - val_acc: 0.7482\n",
      "Epoch 466/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2252/2252 [==============================] - 1s 589us/step - loss: 0.0628 - acc: 0.8275 - val_loss: 0.0846 - val_acc: 0.7489\n",
      "Epoch 467/5000\n",
      "2252/2252 [==============================] - 1s 592us/step - loss: 0.0624 - acc: 0.8283 - val_loss: 0.0861 - val_acc: 0.7453\n",
      "Epoch 468/5000\n",
      "2252/2252 [==============================] - 1s 600us/step - loss: 0.0639 - acc: 0.8222 - val_loss: 0.0849 - val_acc: 0.7494\n",
      "Epoch 469/5000\n",
      "2252/2252 [==============================] - 1s 576us/step - loss: 0.0618 - acc: 0.8285 - val_loss: 0.0863 - val_acc: 0.7438\n",
      "Epoch 470/5000\n",
      "2252/2252 [==============================] - 1s 580us/step - loss: 0.0621 - acc: 0.8289 - val_loss: 0.0854 - val_acc: 0.7470\n",
      "Epoch 471/5000\n",
      "2252/2252 [==============================] - 1s 597us/step - loss: 0.0632 - acc: 0.8231 - val_loss: 0.0856 - val_acc: 0.7467\n",
      "Epoch 472/5000\n",
      "2252/2252 [==============================] - 1s 591us/step - loss: 0.0620 - acc: 0.8288 - val_loss: 0.0845 - val_acc: 0.7504\n",
      "Epoch 473/5000\n",
      "2252/2252 [==============================] - 1s 588us/step - loss: 0.0619 - acc: 0.8307 - val_loss: 0.0917 - val_acc: 0.7289\n",
      "Epoch 474/5000\n",
      "2252/2252 [==============================] - 1s 598us/step - loss: 0.0626 - acc: 0.8254 - val_loss: 0.0848 - val_acc: 0.7507\n",
      "Epoch 475/5000\n",
      "2252/2252 [==============================] - 1s 584us/step - loss: 0.0617 - acc: 0.8301 - val_loss: 0.0852 - val_acc: 0.7469\n",
      "Epoch 476/5000\n",
      "2252/2252 [==============================] - 1s 585us/step - loss: 0.0614 - acc: 0.8317 - val_loss: 0.0906 - val_acc: 0.7325\n",
      "Epoch 477/5000\n",
      "2252/2252 [==============================] - 1s 586us/step - loss: 0.0629 - acc: 0.8248 - val_loss: 0.0847 - val_acc: 0.7499\n",
      "Epoch 478/5000\n",
      "2252/2252 [==============================] - 1s 598us/step - loss: 0.0627 - acc: 0.8264 - val_loss: 0.0872 - val_acc: 0.7418\n",
      "Epoch 479/5000\n",
      "2252/2252 [==============================] - 1s 589us/step - loss: 0.0635 - acc: 0.8219 - val_loss: 0.0864 - val_acc: 0.7449\n",
      "Epoch 480/5000\n",
      "2252/2252 [==============================] - 1s 594us/step - loss: 0.0607 - acc: 0.8334 - val_loss: 0.0849 - val_acc: 0.7492\n",
      "Epoch 481/5000\n",
      "2252/2252 [==============================] - 1s 594us/step - loss: 0.0615 - acc: 0.8303 - val_loss: 0.0842 - val_acc: 0.7525\n",
      "Epoch 482/5000\n",
      "2252/2252 [==============================] - 1s 594us/step - loss: 0.0618 - acc: 0.8305 - val_loss: 0.0849 - val_acc: 0.7497\n",
      "Epoch 483/5000\n",
      "2252/2252 [==============================] - 1s 597us/step - loss: 0.0627 - acc: 0.8254 - val_loss: 0.0895 - val_acc: 0.7361\n",
      "Epoch 484/5000\n",
      "2252/2252 [==============================] - 1s 591us/step - loss: 0.0614 - acc: 0.8307 - val_loss: 0.0863 - val_acc: 0.7463\n",
      "Epoch 485/5000\n",
      "2252/2252 [==============================] - 1s 596us/step - loss: 0.0614 - acc: 0.8319 - val_loss: 0.0842 - val_acc: 0.7510\n",
      "Epoch 486/5000\n",
      "2252/2252 [==============================] - 1s 590us/step - loss: 0.0625 - acc: 0.8246 - val_loss: 0.0850 - val_acc: 0.7480\n",
      "Epoch 487/5000\n",
      "2252/2252 [==============================] - 1s 595us/step - loss: 0.0613 - acc: 0.8302 - val_loss: 0.0852 - val_acc: 0.7482\n",
      "Epoch 488/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.0608 - acc: 0.8317 - val_loss: 0.0844 - val_acc: 0.7501\n",
      "Epoch 489/5000\n",
      "2252/2252 [==============================] - 1s 594us/step - loss: 0.0607 - acc: 0.8314 - val_loss: 0.0852 - val_acc: 0.7490\n",
      "Epoch 490/5000\n",
      "2252/2252 [==============================] - 1s 590us/step - loss: 0.0618 - acc: 0.8276 - val_loss: 0.0878 - val_acc: 0.7420\n",
      "Epoch 491/5000\n",
      "2252/2252 [==============================] - 1s 583us/step - loss: 0.0617 - acc: 0.8283 - val_loss: 0.0835 - val_acc: 0.7541\n",
      "Epoch 492/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.0608 - acc: 0.8314 - val_loss: 0.0858 - val_acc: 0.7466\n",
      "Epoch 493/5000\n",
      "2252/2252 [==============================] - 1s 594us/step - loss: 0.0610 - acc: 0.8288 - val_loss: 0.0863 - val_acc: 0.7461\n",
      "Epoch 494/5000\n",
      "2252/2252 [==============================] - 1s 584us/step - loss: 0.0606 - acc: 0.8313 - val_loss: 0.0842 - val_acc: 0.7519\n",
      "Epoch 495/5000\n",
      "2252/2252 [==============================] - 1s 598us/step - loss: 0.0611 - acc: 0.8298 - val_loss: 0.0892 - val_acc: 0.7377\n",
      "Epoch 496/5000\n",
      "2252/2252 [==============================] - 1s 592us/step - loss: 0.0596 - acc: 0.8359 - val_loss: 0.0867 - val_acc: 0.7447\n",
      "Epoch 497/5000\n",
      "2252/2252 [==============================] - 1s 587us/step - loss: 0.0596 - acc: 0.8361 - val_loss: 0.0844 - val_acc: 0.7532\n",
      "Epoch 498/5000\n",
      "2252/2252 [==============================] - 1s 598us/step - loss: 0.0614 - acc: 0.8285 - val_loss: 0.0850 - val_acc: 0.7510\n",
      "Epoch 499/5000\n",
      "2252/2252 [==============================] - 1s 589us/step - loss: 0.0609 - acc: 0.8311 - val_loss: 0.0841 - val_acc: 0.7509\n",
      "Epoch 500/5000\n",
      "2252/2252 [==============================] - 1s 605us/step - loss: 0.0601 - acc: 0.8345 - val_loss: 0.0866 - val_acc: 0.7453\n",
      "Epoch 501/5000\n",
      "2252/2252 [==============================] - 1s 594us/step - loss: 0.0593 - acc: 0.8366 - val_loss: 0.0855 - val_acc: 0.7493\n",
      "Epoch 502/5000\n",
      "2252/2252 [==============================] - 1s 602us/step - loss: 0.0598 - acc: 0.8347 - val_loss: 0.0841 - val_acc: 0.7494\n",
      "Epoch 503/5000\n",
      "2252/2252 [==============================] - 1s 584us/step - loss: 0.0600 - acc: 0.8331 - val_loss: 0.0881 - val_acc: 0.7414\n",
      "Epoch 504/5000\n",
      "2252/2252 [==============================] - 1s 592us/step - loss: 0.0618 - acc: 0.8270 - val_loss: 0.0845 - val_acc: 0.7498\n",
      "Epoch 505/5000\n",
      "2252/2252 [==============================] - 1s 591us/step - loss: 0.0602 - acc: 0.8343 - val_loss: 0.0847 - val_acc: 0.7515\n",
      "Epoch 506/5000\n",
      "2252/2252 [==============================] - 1s 587us/step - loss: 0.0588 - acc: 0.8383 - val_loss: 0.0871 - val_acc: 0.7442\n",
      "Epoch 507/5000\n",
      "2252/2252 [==============================] - 1s 586us/step - loss: 0.0585 - acc: 0.8378 - val_loss: 0.0853 - val_acc: 0.7484\n",
      "Epoch 508/5000\n",
      "2252/2252 [==============================] - 1s 586us/step - loss: 0.0597 - acc: 0.8349 - val_loss: 0.0856 - val_acc: 0.7485\n",
      "Epoch 509/5000\n",
      "2252/2252 [==============================] - 1s 588us/step - loss: 0.0594 - acc: 0.8351 - val_loss: 0.0863 - val_acc: 0.7473\n",
      "Epoch 510/5000\n",
      "2252/2252 [==============================] - 1s 585us/step - loss: 0.0605 - acc: 0.8324 - val_loss: 0.0844 - val_acc: 0.7509\n",
      "Epoch 511/5000\n",
      "2252/2252 [==============================] - 1s 589us/step - loss: 0.0586 - acc: 0.8380 - val_loss: 0.0846 - val_acc: 0.7490\n",
      "Epoch 512/5000\n",
      "2252/2252 [==============================] - 1s 589us/step - loss: 0.0601 - acc: 0.8339 - val_loss: 0.0857 - val_acc: 0.7478\n",
      "Epoch 513/5000\n",
      "2252/2252 [==============================] - 1s 588us/step - loss: 0.0606 - acc: 0.8312 - val_loss: 0.0838 - val_acc: 0.7543\n",
      "Epoch 514/5000\n",
      "2252/2252 [==============================] - 1s 585us/step - loss: 0.0602 - acc: 0.8324 - val_loss: 0.0840 - val_acc: 0.7516\n",
      "Epoch 515/5000\n",
      "2252/2252 [==============================] - 1s 586us/step - loss: 0.0592 - acc: 0.8363 - val_loss: 0.0879 - val_acc: 0.7430\n",
      "Epoch 516/5000\n",
      "2252/2252 [==============================] - 1s 597us/step - loss: 0.0589 - acc: 0.8377 - val_loss: 0.0879 - val_acc: 0.7428\n",
      "Epoch 517/5000\n",
      "2252/2252 [==============================] - 1s 583us/step - loss: 0.0588 - acc: 0.8378 - val_loss: 0.0995 - val_acc: 0.7094\n",
      "Epoch 518/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.0617 - acc: 0.8250 - val_loss: 0.0855 - val_acc: 0.7473\n",
      "Epoch 519/5000\n",
      "2252/2252 [==============================] - 1s 598us/step - loss: 0.0587 - acc: 0.8380 - val_loss: 0.0841 - val_acc: 0.7525\n",
      "Epoch 520/5000\n",
      "2252/2252 [==============================] - 1s 586us/step - loss: 0.0590 - acc: 0.8377 - val_loss: 0.0855 - val_acc: 0.7469\n",
      "Epoch 521/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.0577 - acc: 0.8430 - val_loss: 0.0857 - val_acc: 0.7485\n",
      "Epoch 522/5000\n",
      "2252/2252 [==============================] - 1s 590us/step - loss: 0.0584 - acc: 0.8389 - val_loss: 0.0921 - val_acc: 0.7326\n",
      "Epoch 523/5000\n",
      "2252/2252 [==============================] - 1s 589us/step - loss: 0.0589 - acc: 0.8385 - val_loss: 0.1021 - val_acc: 0.7042\n",
      "Epoch 524/5000\n",
      "2252/2252 [==============================] - 1s 583us/step - loss: 0.0608 - acc: 0.8307 - val_loss: 0.0963 - val_acc: 0.7222\n",
      "Epoch 525/5000\n",
      "2252/2252 [==============================] - 1s 584us/step - loss: 0.0601 - acc: 0.8326 - val_loss: 0.0852 - val_acc: 0.7504\n",
      "Epoch 526/5000\n",
      "2252/2252 [==============================] - 1s 587us/step - loss: 0.0569 - acc: 0.8464 - val_loss: 0.0848 - val_acc: 0.7487\n",
      "Epoch 527/5000\n",
      "2252/2252 [==============================] - 1s 587us/step - loss: 0.0580 - acc: 0.8395 - val_loss: 0.0856 - val_acc: 0.7482\n",
      "Epoch 528/5000\n",
      "2252/2252 [==============================] - 1s 602us/step - loss: 0.0582 - acc: 0.8419 - val_loss: 0.0891 - val_acc: 0.7415\n",
      "Epoch 529/5000\n",
      "2252/2252 [==============================] - 1s 595us/step - loss: 0.0582 - acc: 0.8403 - val_loss: 0.0900 - val_acc: 0.7362\n",
      "Epoch 530/5000\n",
      "2252/2252 [==============================] - 1s 588us/step - loss: 0.0583 - acc: 0.8396 - val_loss: 0.0832 - val_acc: 0.7567\n",
      "Epoch 531/5000\n",
      "2252/2252 [==============================] - 1s 597us/step - loss: 0.0569 - acc: 0.8447 - val_loss: 0.0835 - val_acc: 0.7532\n",
      "Epoch 532/5000\n",
      "2252/2252 [==============================] - 1s 590us/step - loss: 0.0605 - acc: 0.8314 - val_loss: 0.0883 - val_acc: 0.7411\n",
      "Epoch 533/5000\n",
      "2252/2252 [==============================] - 1s 592us/step - loss: 0.0583 - acc: 0.8401 - val_loss: 0.0920 - val_acc: 0.7342\n",
      "Epoch 534/5000\n",
      "2252/2252 [==============================] - 1s 600us/step - loss: 0.0569 - acc: 0.8436 - val_loss: 0.0841 - val_acc: 0.7507\n",
      "Epoch 535/5000\n",
      "2252/2252 [==============================] - 1s 599us/step - loss: 0.0574 - acc: 0.8420 - val_loss: 0.0841 - val_acc: 0.7523\n",
      "Epoch 536/5000\n",
      "2252/2252 [==============================] - 1s 586us/step - loss: 0.0575 - acc: 0.8404 - val_loss: 0.0833 - val_acc: 0.7561\n",
      "Epoch 537/5000\n",
      "2252/2252 [==============================] - 1s 580us/step - loss: 0.0573 - acc: 0.8437 - val_loss: 0.0905 - val_acc: 0.7373\n",
      "Epoch 538/5000\n",
      "2252/2252 [==============================] - 1s 578us/step - loss: 0.0568 - acc: 0.8439 - val_loss: 0.0881 - val_acc: 0.7428\n",
      "Epoch 539/5000\n",
      "2252/2252 [==============================] - 1s 590us/step - loss: 0.0570 - acc: 0.8428 - val_loss: 0.0846 - val_acc: 0.7518\n",
      "Epoch 540/5000\n",
      "2252/2252 [==============================] - 1s 591us/step - loss: 0.0574 - acc: 0.8430 - val_loss: 0.0830 - val_acc: 0.7582\n",
      "Epoch 541/5000\n",
      "2252/2252 [==============================] - 1s 595us/step - loss: 0.0578 - acc: 0.8423 - val_loss: 0.0833 - val_acc: 0.7540\n",
      "Epoch 542/5000\n",
      "2252/2252 [==============================] - 1s 585us/step - loss: 0.0567 - acc: 0.8432 - val_loss: 0.0841 - val_acc: 0.7535\n",
      "Epoch 543/5000\n",
      "2252/2252 [==============================] - 1s 594us/step - loss: 0.0583 - acc: 0.8379 - val_loss: 0.0837 - val_acc: 0.7551\n",
      "Epoch 544/5000\n",
      "2252/2252 [==============================] - 1s 590us/step - loss: 0.0569 - acc: 0.8422 - val_loss: 0.0867 - val_acc: 0.7472\n",
      "Epoch 545/5000\n",
      "2252/2252 [==============================] - 1s 599us/step - loss: 0.0578 - acc: 0.8410 - val_loss: 0.0843 - val_acc: 0.7513\n",
      "Epoch 546/5000\n",
      "2252/2252 [==============================] - 1s 590us/step - loss: 0.0584 - acc: 0.8388 - val_loss: 0.0835 - val_acc: 0.7539\n",
      "Epoch 547/5000\n",
      "2252/2252 [==============================] - 1s 592us/step - loss: 0.0568 - acc: 0.8439 - val_loss: 0.0843 - val_acc: 0.7531\n",
      "Epoch 548/5000\n",
      "2252/2252 [==============================] - 1s 600us/step - loss: 0.0579 - acc: 0.8404 - val_loss: 0.0853 - val_acc: 0.7511\n",
      "Epoch 549/5000\n",
      "2252/2252 [==============================] - 1s 591us/step - loss: 0.0580 - acc: 0.8393 - val_loss: 0.0827 - val_acc: 0.7566\n",
      "Epoch 550/5000\n",
      "2252/2252 [==============================] - 1s 601us/step - loss: 0.0571 - acc: 0.8424 - val_loss: 0.0844 - val_acc: 0.7517\n",
      "Epoch 551/5000\n",
      "2252/2252 [==============================] - 1s 583us/step - loss: 0.0560 - acc: 0.8465 - val_loss: 0.0835 - val_acc: 0.7556\n",
      "Epoch 552/5000\n",
      "2252/2252 [==============================] - 1s 596us/step - loss: 0.0554 - acc: 0.8493 - val_loss: 0.0840 - val_acc: 0.7558\n",
      "Epoch 553/5000\n",
      "2252/2252 [==============================] - 1s 587us/step - loss: 0.0564 - acc: 0.8447 - val_loss: 0.0874 - val_acc: 0.7453\n",
      "Epoch 554/5000\n",
      "2252/2252 [==============================] - 1s 592us/step - loss: 0.0556 - acc: 0.8461 - val_loss: 0.0851 - val_acc: 0.7539\n",
      "Epoch 555/5000\n",
      "2252/2252 [==============================] - 1s 591us/step - loss: 0.0575 - acc: 0.8416 - val_loss: 0.0859 - val_acc: 0.7489\n",
      "Epoch 556/5000\n",
      "2252/2252 [==============================] - 1s 584us/step - loss: 0.0563 - acc: 0.8457 - val_loss: 0.0842 - val_acc: 0.7539\n",
      "Epoch 557/5000\n",
      "2252/2252 [==============================] - 1s 600us/step - loss: 0.0554 - acc: 0.8475 - val_loss: 0.0828 - val_acc: 0.7576\n",
      "Epoch 558/5000\n",
      "2252/2252 [==============================] - 1s 585us/step - loss: 0.0555 - acc: 0.8486 - val_loss: 0.0847 - val_acc: 0.7530\n",
      "Epoch 559/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.0560 - acc: 0.8455 - val_loss: 0.0831 - val_acc: 0.7592\n",
      "Epoch 560/5000\n",
      "2252/2252 [==============================] - 1s 595us/step - loss: 0.0562 - acc: 0.8453 - val_loss: 0.0895 - val_acc: 0.7422\n",
      "Epoch 561/5000\n",
      "2252/2252 [==============================] - 1s 598us/step - loss: 0.0585 - acc: 0.8394 - val_loss: 0.0877 - val_acc: 0.7451\n",
      "Epoch 562/5000\n",
      "2252/2252 [==============================] - 1s 589us/step - loss: 0.0563 - acc: 0.8453 - val_loss: 0.0843 - val_acc: 0.7523\n",
      "Epoch 563/5000\n",
      "2252/2252 [==============================] - 1s 590us/step - loss: 0.0563 - acc: 0.8453 - val_loss: 0.0855 - val_acc: 0.7494\n",
      "Epoch 564/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.0561 - acc: 0.8465 - val_loss: 0.0869 - val_acc: 0.7483\n",
      "Epoch 565/5000\n",
      "2252/2252 [==============================] - 1s 590us/step - loss: 0.0564 - acc: 0.8459 - val_loss: 0.0858 - val_acc: 0.7496\n",
      "Epoch 566/5000\n",
      "2252/2252 [==============================] - 1s 590us/step - loss: 0.0561 - acc: 0.8448 - val_loss: 0.0826 - val_acc: 0.7600\n",
      "Epoch 567/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.0552 - acc: 0.8488 - val_loss: 0.0852 - val_acc: 0.7514\n",
      "Epoch 568/5000\n",
      "2252/2252 [==============================] - 1s 581us/step - loss: 0.0545 - acc: 0.8516 - val_loss: 0.0846 - val_acc: 0.7551\n",
      "Epoch 569/5000\n",
      "2252/2252 [==============================] - 1s 598us/step - loss: 0.0552 - acc: 0.8491 - val_loss: 0.0843 - val_acc: 0.7534\n",
      "Epoch 570/5000\n",
      "2252/2252 [==============================] - 1s 584us/step - loss: 0.0557 - acc: 0.8480 - val_loss: 0.0872 - val_acc: 0.7482\n",
      "Epoch 571/5000\n",
      "2252/2252 [==============================] - 1s 596us/step - loss: 0.0555 - acc: 0.8494 - val_loss: 0.0846 - val_acc: 0.7532\n",
      "Epoch 572/5000\n",
      "2252/2252 [==============================] - 1s 585us/step - loss: 0.0537 - acc: 0.8535 - val_loss: 0.0830 - val_acc: 0.7573\n",
      "Epoch 573/5000\n",
      "2252/2252 [==============================] - 1s 591us/step - loss: 0.0551 - acc: 0.8488 - val_loss: 0.0843 - val_acc: 0.7543\n",
      "Epoch 574/5000\n",
      "2252/2252 [==============================] - 1s 587us/step - loss: 0.0554 - acc: 0.8486 - val_loss: 0.0859 - val_acc: 0.7526\n",
      "Epoch 575/5000\n",
      "2252/2252 [==============================] - 1s 595us/step - loss: 0.0553 - acc: 0.8490 - val_loss: 0.0835 - val_acc: 0.7594\n",
      "Epoch 576/5000\n",
      "2252/2252 [==============================] - 1s 595us/step - loss: 0.0545 - acc: 0.8522 - val_loss: 0.0837 - val_acc: 0.7553\n",
      "Epoch 577/5000\n",
      "2252/2252 [==============================] - 1s 597us/step - loss: 0.0557 - acc: 0.8474 - val_loss: 0.0834 - val_acc: 0.7583\n",
      "Epoch 578/5000\n",
      "2252/2252 [==============================] - 1s 584us/step - loss: 0.0547 - acc: 0.8520 - val_loss: 0.0849 - val_acc: 0.7544\n",
      "Epoch 579/5000\n",
      "2252/2252 [==============================] - 1s 588us/step - loss: 0.0548 - acc: 0.8507 - val_loss: 0.0835 - val_acc: 0.7579\n",
      "Epoch 580/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.0555 - acc: 0.8472 - val_loss: 0.0883 - val_acc: 0.7461\n",
      "Epoch 581/5000\n",
      "2252/2252 [==============================] - 1s 595us/step - loss: 0.0551 - acc: 0.8495 - val_loss: 0.0829 - val_acc: 0.7603\n",
      "Epoch 582/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2252/2252 [==============================] - 1s 589us/step - loss: 0.0539 - acc: 0.8529 - val_loss: 0.0835 - val_acc: 0.7576\n",
      "Epoch 583/5000\n",
      "2252/2252 [==============================] - 1s 591us/step - loss: 0.0552 - acc: 0.8483 - val_loss: 0.0861 - val_acc: 0.7513\n",
      "Epoch 584/5000\n",
      "2252/2252 [==============================] - 1s 591us/step - loss: 0.0531 - acc: 0.8573 - val_loss: 0.0843 - val_acc: 0.7568\n",
      "Epoch 585/5000\n",
      "2252/2252 [==============================] - 1s 584us/step - loss: 0.0544 - acc: 0.8523 - val_loss: 0.0853 - val_acc: 0.7532\n",
      "Epoch 586/5000\n",
      "2252/2252 [==============================] - 1s 600us/step - loss: 0.0534 - acc: 0.8552 - val_loss: 0.0828 - val_acc: 0.7580\n",
      "Epoch 587/5000\n",
      "2252/2252 [==============================] - 1s 594us/step - loss: 0.0549 - acc: 0.8500 - val_loss: 0.0872 - val_acc: 0.7496\n",
      "Epoch 588/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.0535 - acc: 0.8544 - val_loss: 0.0885 - val_acc: 0.7472\n",
      "Epoch 589/5000\n",
      "2252/2252 [==============================] - 1s 600us/step - loss: 0.0551 - acc: 0.8491 - val_loss: 0.0840 - val_acc: 0.7549\n",
      "Epoch 590/5000\n",
      "2252/2252 [==============================] - 1s 596us/step - loss: 0.0550 - acc: 0.8481 - val_loss: 0.0833 - val_acc: 0.7579\n",
      "Epoch 591/5000\n",
      "2252/2252 [==============================] - 1s 583us/step - loss: 0.0535 - acc: 0.8549 - val_loss: 0.0827 - val_acc: 0.7591\n",
      "Epoch 592/5000\n",
      "2252/2252 [==============================] - 1s 598us/step - loss: 0.0548 - acc: 0.8493 - val_loss: 0.0831 - val_acc: 0.7588\n",
      "Epoch 593/5000\n",
      "2252/2252 [==============================] - 1s 595us/step - loss: 0.0555 - acc: 0.8469 - val_loss: 0.0829 - val_acc: 0.7592\n",
      "Epoch 594/5000\n",
      "2252/2252 [==============================] - 1s 595us/step - loss: 0.0544 - acc: 0.8529 - val_loss: 0.0877 - val_acc: 0.7467\n",
      "Epoch 595/5000\n",
      "2252/2252 [==============================] - 1s 588us/step - loss: 0.0559 - acc: 0.8451 - val_loss: 0.0840 - val_acc: 0.7575\n",
      "Epoch 596/5000\n",
      "2252/2252 [==============================] - 1s 600us/step - loss: 0.0540 - acc: 0.8528 - val_loss: 0.0833 - val_acc: 0.7565\n",
      "Epoch 597/5000\n",
      "2252/2252 [==============================] - 1s 585us/step - loss: 0.0523 - acc: 0.8570 - val_loss: 0.0857 - val_acc: 0.7514\n",
      "Epoch 598/5000\n",
      "2252/2252 [==============================] - 1s 613us/step - loss: 0.0537 - acc: 0.8512 - val_loss: 0.0851 - val_acc: 0.7534\n",
      "Epoch 599/5000\n",
      "2252/2252 [==============================] - 1s 590us/step - loss: 0.0540 - acc: 0.8510 - val_loss: 0.0867 - val_acc: 0.7487\n",
      "Epoch 600/5000\n",
      "2252/2252 [==============================] - 1s 588us/step - loss: 0.0537 - acc: 0.8541 - val_loss: 0.0855 - val_acc: 0.7542\n",
      "Epoch 601/5000\n",
      "2252/2252 [==============================] - 1s 583us/step - loss: 0.0539 - acc: 0.8526 - val_loss: 0.0849 - val_acc: 0.7535\n",
      "Epoch 602/5000\n",
      "2252/2252 [==============================] - 1s 579us/step - loss: 0.0528 - acc: 0.8548 - val_loss: 0.0832 - val_acc: 0.7589\n",
      "Epoch 603/5000\n",
      "2252/2252 [==============================] - 1s 587us/step - loss: 0.0563 - acc: 0.8447 - val_loss: 0.0927 - val_acc: 0.7380\n",
      "Epoch 604/5000\n",
      "2252/2252 [==============================] - 1s 602us/step - loss: 0.0529 - acc: 0.8569 - val_loss: 0.0839 - val_acc: 0.7575\n",
      "Epoch 605/5000\n",
      "2252/2252 [==============================] - 1s 588us/step - loss: 0.0547 - acc: 0.8495 - val_loss: 0.0820 - val_acc: 0.7619\n",
      "Epoch 606/5000\n",
      "2252/2252 [==============================] - 1s 598us/step - loss: 0.0537 - acc: 0.8531 - val_loss: 0.0830 - val_acc: 0.7585\n",
      "Epoch 607/5000\n",
      "2252/2252 [==============================] - 1s 606us/step - loss: 0.0539 - acc: 0.8538 - val_loss: 0.0834 - val_acc: 0.7581\n",
      "Epoch 608/5000\n",
      "2252/2252 [==============================] - 1s 600us/step - loss: 0.0537 - acc: 0.8530 - val_loss: 0.0834 - val_acc: 0.7580\n",
      "Epoch 609/5000\n",
      "2252/2252 [==============================] - 1s 583us/step - loss: 0.0522 - acc: 0.8586 - val_loss: 0.0861 - val_acc: 0.7521\n",
      "Epoch 610/5000\n",
      "2252/2252 [==============================] - 1s 594us/step - loss: 0.0526 - acc: 0.8579 - val_loss: 0.0848 - val_acc: 0.7547\n",
      "Epoch 611/5000\n",
      "2252/2252 [==============================] - 1s 597us/step - loss: 0.0525 - acc: 0.8576 - val_loss: 0.0868 - val_acc: 0.7515\n",
      "Epoch 612/5000\n",
      "2252/2252 [==============================] - 1s 602us/step - loss: 0.0533 - acc: 0.8547 - val_loss: 0.0900 - val_acc: 0.7425\n",
      "Epoch 613/5000\n",
      "2252/2252 [==============================] - 1s 597us/step - loss: 0.0527 - acc: 0.8573 - val_loss: 0.0871 - val_acc: 0.7492\n",
      "Epoch 614/5000\n",
      "2252/2252 [==============================] - 1s 604us/step - loss: 0.0523 - acc: 0.8570 - val_loss: 0.0833 - val_acc: 0.7589\n",
      "Epoch 615/5000\n",
      "2252/2252 [==============================] - 1s 594us/step - loss: 0.0532 - acc: 0.8552 - val_loss: 0.0861 - val_acc: 0.7504\n",
      "Epoch 616/5000\n",
      "2252/2252 [==============================] - 1s 599us/step - loss: 0.0527 - acc: 0.8573 - val_loss: 0.0902 - val_acc: 0.7439\n",
      "Epoch 617/5000\n",
      "2252/2252 [==============================] - 1s 598us/step - loss: 0.0559 - acc: 0.8462 - val_loss: 0.0859 - val_acc: 0.7519\n",
      "Epoch 618/5000\n",
      "2252/2252 [==============================] - 1s 598us/step - loss: 0.0515 - acc: 0.8621 - val_loss: 0.0896 - val_acc: 0.7468\n",
      "Epoch 619/5000\n",
      "2252/2252 [==============================] - 1s 594us/step - loss: 0.0524 - acc: 0.8586 - val_loss: 0.0894 - val_acc: 0.7460\n",
      "Epoch 620/5000\n",
      "2252/2252 [==============================] - 1s 599us/step - loss: 0.0521 - acc: 0.8595 - val_loss: 0.0831 - val_acc: 0.7606\n",
      "Epoch 621/5000\n",
      "2252/2252 [==============================] - 1s 597us/step - loss: 0.0527 - acc: 0.8570 - val_loss: 0.0856 - val_acc: 0.7529\n",
      "Epoch 622/5000\n",
      "2252/2252 [==============================] - 1s 576us/step - loss: 0.0525 - acc: 0.8586 - val_loss: 0.0859 - val_acc: 0.7528\n",
      "Epoch 623/5000\n",
      "2252/2252 [==============================] - 1s 588us/step - loss: 0.0526 - acc: 0.8577 - val_loss: 0.0840 - val_acc: 0.7561\n",
      "Epoch 624/5000\n",
      "2252/2252 [==============================] - 1s 600us/step - loss: 0.0514 - acc: 0.8628 - val_loss: 0.0852 - val_acc: 0.7549\n",
      "Epoch 625/5000\n",
      "2252/2252 [==============================] - 1s 595us/step - loss: 0.0536 - acc: 0.8533 - val_loss: 0.0873 - val_acc: 0.7514\n",
      "Epoch 626/5000\n",
      "2252/2252 [==============================] - 1s 597us/step - loss: 0.0529 - acc: 0.8556 - val_loss: 0.0827 - val_acc: 0.7618\n",
      "Epoch 627/5000\n",
      "2252/2252 [==============================] - 1s 602us/step - loss: 0.0522 - acc: 0.8587 - val_loss: 0.0851 - val_acc: 0.7553\n",
      "Epoch 628/5000\n",
      "2252/2252 [==============================] - 1s 584us/step - loss: 0.0517 - acc: 0.8601 - val_loss: 0.0845 - val_acc: 0.7550\n",
      "Epoch 629/5000\n",
      "2252/2252 [==============================] - 1s 594us/step - loss: 0.0516 - acc: 0.8615 - val_loss: 0.0826 - val_acc: 0.7621\n",
      "Epoch 630/5000\n",
      "2252/2252 [==============================] - 1s 603us/step - loss: 0.0516 - acc: 0.8603 - val_loss: 0.0828 - val_acc: 0.7613\n",
      "Epoch 631/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.0519 - acc: 0.8604 - val_loss: 0.0847 - val_acc: 0.7555\n",
      "Epoch 632/5000\n",
      "2252/2252 [==============================] - 1s 581us/step - loss: 0.0525 - acc: 0.8590 - val_loss: 0.0826 - val_acc: 0.7611\n",
      "Epoch 633/5000\n",
      "2252/2252 [==============================] - 1s 594us/step - loss: 0.0519 - acc: 0.8593 - val_loss: 0.0861 - val_acc: 0.7513\n",
      "Epoch 634/5000\n",
      "2252/2252 [==============================] - 1s 597us/step - loss: 0.0512 - acc: 0.8612 - val_loss: 0.0873 - val_acc: 0.7501\n",
      "Epoch 635/5000\n",
      "2252/2252 [==============================] - 1s 601us/step - loss: 0.0526 - acc: 0.8571 - val_loss: 0.0823 - val_acc: 0.7639\n",
      "Epoch 636/5000\n",
      "2252/2252 [==============================] - 1s 598us/step - loss: 0.0536 - acc: 0.8538 - val_loss: 0.0839 - val_acc: 0.7547\n",
      "Epoch 637/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.0530 - acc: 0.8553 - val_loss: 0.0868 - val_acc: 0.7522\n",
      "Epoch 638/5000\n",
      "2252/2252 [==============================] - 1s 603us/step - loss: 0.0549 - acc: 0.8488 - val_loss: 0.0844 - val_acc: 0.7561\n",
      "Epoch 639/5000\n",
      "2252/2252 [==============================] - 1s 592us/step - loss: 0.0520 - acc: 0.8590 - val_loss: 0.0857 - val_acc: 0.7513\n",
      "Epoch 640/5000\n",
      "2252/2252 [==============================] - 1s 588us/step - loss: 0.0514 - acc: 0.8604 - val_loss: 0.0823 - val_acc: 0.7655\n",
      "Epoch 641/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.0512 - acc: 0.8613 - val_loss: 0.0861 - val_acc: 0.7541\n",
      "Epoch 642/5000\n",
      "2252/2252 [==============================] - 1s 596us/step - loss: 0.0520 - acc: 0.8585 - val_loss: 0.0831 - val_acc: 0.7617\n",
      "Epoch 643/5000\n",
      "2252/2252 [==============================] - 1s 586us/step - loss: 0.0510 - acc: 0.8627 - val_loss: 0.0855 - val_acc: 0.7525\n",
      "Epoch 644/5000\n",
      "2252/2252 [==============================] - 1s 594us/step - loss: 0.0508 - acc: 0.8636 - val_loss: 0.0830 - val_acc: 0.7614\n",
      "Epoch 645/5000\n",
      "2252/2252 [==============================] - 1s 602us/step - loss: 0.0510 - acc: 0.8624 - val_loss: 0.0824 - val_acc: 0.7633\n",
      "Epoch 646/5000\n",
      "2252/2252 [==============================] - 1s 591us/step - loss: 0.0516 - acc: 0.8600 - val_loss: 0.0840 - val_acc: 0.7600\n",
      "Epoch 647/5000\n",
      "2252/2252 [==============================] - 1s 600us/step - loss: 0.0509 - acc: 0.8618 - val_loss: 0.0842 - val_acc: 0.7598\n",
      "Epoch 648/5000\n",
      "2252/2252 [==============================] - 1s 592us/step - loss: 0.0530 - acc: 0.8550 - val_loss: 0.0971 - val_acc: 0.7277\n",
      "Epoch 649/5000\n",
      "2252/2252 [==============================] - 1s 601us/step - loss: 0.0528 - acc: 0.8560 - val_loss: 0.0831 - val_acc: 0.7626\n",
      "Epoch 650/5000\n",
      "2252/2252 [==============================] - 1s 592us/step - loss: 0.0502 - acc: 0.8644 - val_loss: 0.0867 - val_acc: 0.7521\n",
      "Epoch 651/5000\n",
      "2252/2252 [==============================] - 1s 592us/step - loss: 0.0507 - acc: 0.8639 - val_loss: 0.0848 - val_acc: 0.7575\n",
      "Epoch 652/5000\n",
      "2252/2252 [==============================] - 1s 590us/step - loss: 0.0508 - acc: 0.8618 - val_loss: 0.0855 - val_acc: 0.7553\n",
      "Epoch 653/5000\n",
      "2252/2252 [==============================] - 1s 594us/step - loss: 0.0499 - acc: 0.8656 - val_loss: 0.0847 - val_acc: 0.7568\n",
      "Epoch 654/5000\n",
      "2252/2252 [==============================] - 1s 602us/step - loss: 0.0509 - acc: 0.8603 - val_loss: 0.0842 - val_acc: 0.7573\n",
      "Epoch 655/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.0513 - acc: 0.8601 - val_loss: 0.0861 - val_acc: 0.7532\n",
      "Epoch 656/5000\n",
      "2252/2252 [==============================] - 1s 596us/step - loss: 0.0508 - acc: 0.8620 - val_loss: 0.0825 - val_acc: 0.7636\n",
      "Epoch 657/5000\n",
      "2252/2252 [==============================] - 1s 587us/step - loss: 0.0523 - acc: 0.8556 - val_loss: 0.0864 - val_acc: 0.7527\n",
      "Epoch 658/5000\n",
      "2252/2252 [==============================] - 1s 582us/step - loss: 0.0512 - acc: 0.8610 - val_loss: 0.0839 - val_acc: 0.7598\n",
      "Epoch 659/5000\n",
      "2252/2252 [==============================] - 1s 591us/step - loss: 0.0530 - acc: 0.8549 - val_loss: 0.0835 - val_acc: 0.7608\n",
      "Epoch 660/5000\n",
      "2252/2252 [==============================] - 1s 579us/step - loss: 0.0507 - acc: 0.8614 - val_loss: 0.0828 - val_acc: 0.7611\n",
      "Epoch 661/5000\n",
      "2252/2252 [==============================] - 1s 602us/step - loss: 0.0503 - acc: 0.8641 - val_loss: 0.0854 - val_acc: 0.7561\n",
      "Epoch 662/5000\n",
      "2252/2252 [==============================] - 1s 599us/step - loss: 0.0490 - acc: 0.8678 - val_loss: 0.0870 - val_acc: 0.7526\n",
      "Epoch 663/5000\n",
      "2252/2252 [==============================] - 1s 587us/step - loss: 0.0509 - acc: 0.8620 - val_loss: 0.0880 - val_acc: 0.7497\n",
      "Epoch 664/5000\n",
      "2252/2252 [==============================] - 1s 595us/step - loss: 0.0511 - acc: 0.8613 - val_loss: 0.0854 - val_acc: 0.7550\n",
      "Epoch 665/5000\n",
      "2252/2252 [==============================] - 1s 601us/step - loss: 0.0499 - acc: 0.8658 - val_loss: 0.0833 - val_acc: 0.7605\n",
      "Epoch 666/5000\n",
      "2252/2252 [==============================] - 1s 591us/step - loss: 0.0513 - acc: 0.8607 - val_loss: 0.0840 - val_acc: 0.7588\n",
      "Epoch 667/5000\n",
      "2252/2252 [==============================] - 1s 586us/step - loss: 0.0513 - acc: 0.8605 - val_loss: 0.0849 - val_acc: 0.7562\n",
      "Epoch 668/5000\n",
      "2252/2252 [==============================] - 1s 598us/step - loss: 0.0493 - acc: 0.8682 - val_loss: 0.0868 - val_acc: 0.7537\n",
      "Epoch 669/5000\n",
      "2252/2252 [==============================] - 1s 596us/step - loss: 0.0503 - acc: 0.8642 - val_loss: 0.0962 - val_acc: 0.7327\n",
      "Epoch 670/5000\n",
      "2252/2252 [==============================] - 1s 589us/step - loss: 0.0506 - acc: 0.8629 - val_loss: 0.0848 - val_acc: 0.7566\n",
      "Epoch 671/5000\n",
      "2252/2252 [==============================] - 1s 586us/step - loss: 0.0504 - acc: 0.8639 - val_loss: 0.0853 - val_acc: 0.7574\n",
      "Epoch 672/5000\n",
      "2252/2252 [==============================] - 1s 597us/step - loss: 0.0496 - acc: 0.8640 - val_loss: 0.0847 - val_acc: 0.7578\n",
      "Epoch 673/5000\n",
      "2252/2252 [==============================] - 1s 610us/step - loss: 0.0495 - acc: 0.8677 - val_loss: 0.0870 - val_acc: 0.7522\n",
      "Epoch 674/5000\n",
      "2252/2252 [==============================] - 1s 592us/step - loss: 0.0509 - acc: 0.8623 - val_loss: 0.0828 - val_acc: 0.7636\n",
      "Epoch 675/5000\n",
      "2252/2252 [==============================] - 1s 603us/step - loss: 0.0508 - acc: 0.8621 - val_loss: 0.0885 - val_acc: 0.7482\n",
      "Epoch 676/5000\n",
      "2252/2252 [==============================] - 1s 591us/step - loss: 0.0498 - acc: 0.8655 - val_loss: 0.0896 - val_acc: 0.7488\n",
      "Epoch 677/5000\n",
      "2252/2252 [==============================] - 1s 591us/step - loss: 0.0495 - acc: 0.8676 - val_loss: 0.0832 - val_acc: 0.7627\n",
      "Epoch 678/5000\n",
      "2252/2252 [==============================] - 1s 590us/step - loss: 0.0502 - acc: 0.8642 - val_loss: 0.0871 - val_acc: 0.7513\n",
      "Epoch 679/5000\n",
      "2252/2252 [==============================] - 1s 599us/step - loss: 0.0502 - acc: 0.8645 - val_loss: 0.0829 - val_acc: 0.7610\n",
      "Epoch 680/5000\n",
      "2252/2252 [==============================] - 1s 581us/step - loss: 0.0493 - acc: 0.8676 - val_loss: 0.0827 - val_acc: 0.7611\n",
      "Epoch 681/5000\n",
      "2252/2252 [==============================] - 1s 589us/step - loss: 0.0509 - acc: 0.8625 - val_loss: 0.0859 - val_acc: 0.7537\n",
      "Epoch 682/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.0500 - acc: 0.8643 - val_loss: 0.0924 - val_acc: 0.7409\n",
      "Epoch 683/5000\n",
      "2252/2252 [==============================] - 1s 585us/step - loss: 0.0490 - acc: 0.8687 - val_loss: 0.0876 - val_acc: 0.7528\n",
      "Epoch 684/5000\n",
      "2252/2252 [==============================] - 1s 599us/step - loss: 0.0497 - acc: 0.8653 - val_loss: 0.0865 - val_acc: 0.7552\n",
      "Epoch 685/5000\n",
      "2252/2252 [==============================] - 1s 591us/step - loss: 0.0488 - acc: 0.8689 - val_loss: 0.0857 - val_acc: 0.7555\n",
      "Epoch 686/5000\n",
      "2252/2252 [==============================] - 1s 589us/step - loss: 0.0490 - acc: 0.8678 - val_loss: 0.0820 - val_acc: 0.7653\n",
      "Epoch 687/5000\n",
      "2252/2252 [==============================] - 1s 595us/step - loss: 0.0516 - acc: 0.8608 - val_loss: 0.0826 - val_acc: 0.7651\n",
      "Epoch 688/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.0517 - acc: 0.8594 - val_loss: 0.0846 - val_acc: 0.7570\n",
      "Epoch 689/5000\n",
      "2252/2252 [==============================] - 1s 594us/step - loss: 0.0510 - acc: 0.8621 - val_loss: 0.0920 - val_acc: 0.7392\n",
      "Epoch 690/5000\n",
      "2252/2252 [==============================] - 1s 590us/step - loss: 0.0510 - acc: 0.8616 - val_loss: 0.0821 - val_acc: 0.7634\n",
      "Epoch 691/5000\n",
      "2252/2252 [==============================] - 1s 587us/step - loss: 0.0503 - acc: 0.8635 - val_loss: 0.0884 - val_acc: 0.7487\n",
      "Epoch 692/5000\n",
      "2252/2252 [==============================] - 1s 601us/step - loss: 0.0519 - acc: 0.8593 - val_loss: 0.0858 - val_acc: 0.7557\n",
      "Epoch 693/5000\n",
      "2252/2252 [==============================] - 1s 568us/step - loss: 0.0495 - acc: 0.8660 - val_loss: 0.0824 - val_acc: 0.7649\n",
      "Epoch 694/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.0482 - acc: 0.8711 - val_loss: 0.0915 - val_acc: 0.7400\n",
      "Epoch 695/5000\n",
      "2252/2252 [==============================] - 1s 591us/step - loss: 0.0521 - acc: 0.8587 - val_loss: 0.0857 - val_acc: 0.7577\n",
      "Epoch 696/5000\n",
      "2252/2252 [==============================] - 1s 583us/step - loss: 0.0492 - acc: 0.8685 - val_loss: 0.0853 - val_acc: 0.7565\n",
      "Epoch 697/5000\n",
      "2252/2252 [==============================] - 1s 582us/step - loss: 0.0488 - acc: 0.8683 - val_loss: 0.0879 - val_acc: 0.7513\n",
      "Epoch 698/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2252/2252 [==============================] - 1s 599us/step - loss: 0.0493 - acc: 0.8666 - val_loss: 0.0845 - val_acc: 0.7601\n",
      "Epoch 699/5000\n",
      "2252/2252 [==============================] - 1s 595us/step - loss: 0.0488 - acc: 0.8683 - val_loss: 0.0870 - val_acc: 0.7539\n",
      "Epoch 700/5000\n",
      "2252/2252 [==============================] - 1s 602us/step - loss: 0.0486 - acc: 0.8697 - val_loss: 0.0848 - val_acc: 0.7594\n",
      "Epoch 701/5000\n",
      "2252/2252 [==============================] - 1s 595us/step - loss: 0.0484 - acc: 0.8694 - val_loss: 0.0890 - val_acc: 0.7474\n",
      "Epoch 702/5000\n",
      "2252/2252 [==============================] - 1s 601us/step - loss: 0.0502 - acc: 0.8640 - val_loss: 0.0822 - val_acc: 0.7653\n",
      "Epoch 703/5000\n",
      "2252/2252 [==============================] - 1s 579us/step - loss: 0.0486 - acc: 0.8696 - val_loss: 0.0840 - val_acc: 0.7601\n",
      "Epoch 704/5000\n",
      "2252/2252 [==============================] - 1s 576us/step - loss: 0.0499 - acc: 0.8648 - val_loss: 0.0833 - val_acc: 0.7623\n",
      "Epoch 705/5000\n",
      "2252/2252 [==============================] - 1s 591us/step - loss: 0.0498 - acc: 0.8656 - val_loss: 0.0838 - val_acc: 0.7599\n",
      "Epoch 706/5000\n",
      "2252/2252 [==============================] - 1s 598us/step - loss: 0.0489 - acc: 0.8690 - val_loss: 0.0848 - val_acc: 0.7572\n",
      "Epoch 707/5000\n",
      "2252/2252 [==============================] - 1s 592us/step - loss: 0.0484 - acc: 0.8708 - val_loss: 0.0841 - val_acc: 0.7593\n",
      "Epoch 708/5000\n",
      "2252/2252 [==============================] - 1s 591us/step - loss: 0.0480 - acc: 0.8699 - val_loss: 0.0847 - val_acc: 0.7577\n",
      "Epoch 709/5000\n",
      "2252/2252 [==============================] - 1s 585us/step - loss: 0.0474 - acc: 0.8729 - val_loss: 0.0850 - val_acc: 0.7566\n",
      "Epoch 710/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.0488 - acc: 0.8673 - val_loss: 0.0836 - val_acc: 0.7629\n",
      "Epoch 711/5000\n",
      "2252/2252 [==============================] - 1s 587us/step - loss: 0.0490 - acc: 0.8681 - val_loss: 0.0858 - val_acc: 0.7561\n",
      "Epoch 712/5000\n",
      "2252/2252 [==============================] - 1s 583us/step - loss: 0.0482 - acc: 0.8701 - val_loss: 0.0845 - val_acc: 0.7592\n",
      "Epoch 713/5000\n",
      "2252/2252 [==============================] - 1s 595us/step - loss: 0.0477 - acc: 0.8724 - val_loss: 0.0825 - val_acc: 0.7643\n",
      "Epoch 714/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.0485 - acc: 0.8709 - val_loss: 0.0838 - val_acc: 0.7613\n",
      "Epoch 715/5000\n",
      "2252/2252 [==============================] - 1s 588us/step - loss: 0.0481 - acc: 0.8711 - val_loss: 0.0867 - val_acc: 0.7544\n",
      "Epoch 716/5000\n",
      "2252/2252 [==============================] - 1s 587us/step - loss: 0.0492 - acc: 0.8686 - val_loss: 0.0962 - val_acc: 0.7329\n",
      "Epoch 717/5000\n",
      "2252/2252 [==============================] - 1s 596us/step - loss: 0.0502 - acc: 0.8637 - val_loss: 0.0846 - val_acc: 0.7589\n",
      "Epoch 718/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.0485 - acc: 0.8688 - val_loss: 0.0845 - val_acc: 0.7581\n",
      "Epoch 719/5000\n",
      "2252/2252 [==============================] - 1s 591us/step - loss: 0.0477 - acc: 0.8734 - val_loss: 0.0840 - val_acc: 0.7625\n",
      "Epoch 720/5000\n",
      "2252/2252 [==============================] - 1s 588us/step - loss: 0.0488 - acc: 0.8688 - val_loss: 0.0902 - val_acc: 0.7473\n",
      "Epoch 721/5000\n",
      "2252/2252 [==============================] - 1s 592us/step - loss: 0.0507 - acc: 0.8626 - val_loss: 0.0874 - val_acc: 0.7535\n",
      "Epoch 722/5000\n",
      "2252/2252 [==============================] - 1s 590us/step - loss: 0.0488 - acc: 0.8699 - val_loss: 0.0902 - val_acc: 0.7454\n",
      "Epoch 723/5000\n",
      "2252/2252 [==============================] - 1s 585us/step - loss: 0.0477 - acc: 0.8720 - val_loss: 0.0884 - val_acc: 0.7514\n",
      "Epoch 724/5000\n",
      "2252/2252 [==============================] - 1s 588us/step - loss: 0.0486 - acc: 0.8708 - val_loss: 0.0877 - val_acc: 0.7537\n",
      "Epoch 725/5000\n",
      "2252/2252 [==============================] - 1s 601us/step - loss: 0.0490 - acc: 0.8678 - val_loss: 0.0898 - val_acc: 0.7512\n",
      "Epoch 726/5000\n",
      "2252/2252 [==============================] - 1s 596us/step - loss: 0.0477 - acc: 0.8729 - val_loss: 0.0846 - val_acc: 0.7589\n",
      "Epoch 727/5000\n",
      "2252/2252 [==============================] - 1s 597us/step - loss: 0.0466 - acc: 0.8748 - val_loss: 0.0849 - val_acc: 0.7585\n",
      "Epoch 728/5000\n",
      "2252/2252 [==============================] - 1s 597us/step - loss: 0.0470 - acc: 0.8745 - val_loss: 0.0927 - val_acc: 0.7389\n",
      "Epoch 729/5000\n",
      "2252/2252 [==============================] - 1s 592us/step - loss: 0.0488 - acc: 0.8677 - val_loss: 0.0836 - val_acc: 0.7615\n",
      "Epoch 730/5000\n",
      "2252/2252 [==============================] - 1s 592us/step - loss: 0.0485 - acc: 0.8690 - val_loss: 0.0838 - val_acc: 0.7615\n",
      "Epoch 731/5000\n",
      "2252/2252 [==============================] - 1s 592us/step - loss: 0.0480 - acc: 0.8728 - val_loss: 0.0866 - val_acc: 0.7563\n",
      "Epoch 732/5000\n",
      "2252/2252 [==============================] - 1s 589us/step - loss: 0.0475 - acc: 0.8715 - val_loss: 0.0872 - val_acc: 0.7537\n",
      "Epoch 733/5000\n",
      "2252/2252 [==============================] - 1s 583us/step - loss: 0.0467 - acc: 0.8748 - val_loss: 0.0843 - val_acc: 0.7581\n",
      "Epoch 734/5000\n",
      "2252/2252 [==============================] - 1s 576us/step - loss: 0.0474 - acc: 0.8736 - val_loss: 0.0841 - val_acc: 0.7591\n",
      "Epoch 735/5000\n",
      "2252/2252 [==============================] - 1s 584us/step - loss: 0.0470 - acc: 0.8748 - val_loss: 0.0840 - val_acc: 0.7591\n",
      "Epoch 736/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.0468 - acc: 0.8747 - val_loss: 0.0872 - val_acc: 0.7546\n",
      "Epoch 737/5000\n",
      "2252/2252 [==============================] - 1s 598us/step - loss: 0.0469 - acc: 0.8747 - val_loss: 0.0861 - val_acc: 0.7561\n",
      "Epoch 738/5000\n",
      "2252/2252 [==============================] - 1s 596us/step - loss: 0.0476 - acc: 0.8718 - val_loss: 0.0826 - val_acc: 0.7660\n",
      "Epoch 739/5000\n",
      "2252/2252 [==============================] - 1s 597us/step - loss: 0.0476 - acc: 0.8730 - val_loss: 0.0832 - val_acc: 0.7625\n",
      "Epoch 740/5000\n",
      "2252/2252 [==============================] - 1s 588us/step - loss: 0.0475 - acc: 0.8724 - val_loss: 0.0867 - val_acc: 0.7561\n",
      "Epoch 741/5000\n",
      "2252/2252 [==============================] - 1s 596us/step - loss: 0.0482 - acc: 0.8717 - val_loss: 0.0860 - val_acc: 0.7563\n",
      "Epoch 742/5000\n",
      "2252/2252 [==============================] - 1s 589us/step - loss: 0.0475 - acc: 0.8717 - val_loss: 0.0846 - val_acc: 0.7603\n",
      "Epoch 743/5000\n",
      "2252/2252 [==============================] - 1s 597us/step - loss: 0.0476 - acc: 0.8727 - val_loss: 0.0862 - val_acc: 0.7561\n",
      "Epoch 744/5000\n",
      "2252/2252 [==============================] - 1s 594us/step - loss: 0.0462 - acc: 0.8776 - val_loss: 0.0882 - val_acc: 0.7518\n",
      "Epoch 745/5000\n",
      "2252/2252 [==============================] - 1s 598us/step - loss: 0.0478 - acc: 0.8711 - val_loss: 0.0844 - val_acc: 0.7606\n",
      "Epoch 746/5000\n",
      "2252/2252 [==============================] - 1s 595us/step - loss: 0.0477 - acc: 0.8718 - val_loss: 0.0890 - val_acc: 0.7512\n",
      "Epoch 747/5000\n",
      "2252/2252 [==============================] - 1s 597us/step - loss: 0.0474 - acc: 0.8738 - val_loss: 0.0848 - val_acc: 0.7603\n",
      "Epoch 748/5000\n",
      "2252/2252 [==============================] - 1s 581us/step - loss: 0.0476 - acc: 0.8736 - val_loss: 0.0981 - val_acc: 0.7298\n",
      "Epoch 749/5000\n",
      "2252/2252 [==============================] - 1s 597us/step - loss: 0.0481 - acc: 0.8717 - val_loss: 0.0821 - val_acc: 0.7658\n",
      "Epoch 750/5000\n",
      "2252/2252 [==============================] - 1s 592us/step - loss: 0.0469 - acc: 0.8746 - val_loss: 0.0825 - val_acc: 0.7637\n",
      "Epoch 751/5000\n",
      "2252/2252 [==============================] - 1s 598us/step - loss: 0.0467 - acc: 0.8752 - val_loss: 0.0840 - val_acc: 0.7600\n",
      "Epoch 752/5000\n",
      "2252/2252 [==============================] - 1s 596us/step - loss: 0.0460 - acc: 0.8787 - val_loss: 0.0842 - val_acc: 0.7605\n",
      "Epoch 753/5000\n",
      "2252/2252 [==============================] - 1s 587us/step - loss: 0.0471 - acc: 0.8735 - val_loss: 0.0852 - val_acc: 0.7592\n",
      "Epoch 754/5000\n",
      "2252/2252 [==============================] - 1s 590us/step - loss: 0.0463 - acc: 0.8751 - val_loss: 0.0851 - val_acc: 0.7604\n",
      "Epoch 755/5000\n",
      "2252/2252 [==============================] - 1s 590us/step - loss: 0.0460 - acc: 0.8777 - val_loss: 0.0831 - val_acc: 0.7640\n",
      "Epoch 756/5000\n",
      "2252/2252 [==============================] - 1s 582us/step - loss: 0.0468 - acc: 0.8734 - val_loss: 0.0833 - val_acc: 0.7634\n",
      "Epoch 757/5000\n",
      "2252/2252 [==============================] - 1s 580us/step - loss: 0.0468 - acc: 0.8758 - val_loss: 0.0831 - val_acc: 0.7642\n",
      "Epoch 758/5000\n",
      "2252/2252 [==============================] - 1s 587us/step - loss: 0.0463 - acc: 0.8765 - val_loss: 0.0826 - val_acc: 0.7689\n",
      "Epoch 759/5000\n",
      "2252/2252 [==============================] - 1s 595us/step - loss: 0.0467 - acc: 0.8767 - val_loss: 0.0848 - val_acc: 0.7588\n",
      "Epoch 760/5000\n",
      "2252/2252 [==============================] - 1s 587us/step - loss: 0.0474 - acc: 0.8724 - val_loss: 0.0839 - val_acc: 0.7616\n",
      "Epoch 761/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.0470 - acc: 0.8741 - val_loss: 0.0879 - val_acc: 0.7539\n",
      "Epoch 762/5000\n",
      "2252/2252 [==============================] - 1s 598us/step - loss: 0.0464 - acc: 0.8764 - val_loss: 0.0854 - val_acc: 0.7587\n",
      "Epoch 763/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.0463 - acc: 0.8771 - val_loss: 0.0826 - val_acc: 0.7655\n",
      "Epoch 764/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.0455 - acc: 0.8794 - val_loss: 0.0822 - val_acc: 0.7681\n",
      "Epoch 765/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.0476 - acc: 0.8724 - val_loss: 0.0880 - val_acc: 0.7537\n",
      "Epoch 766/5000\n",
      "2252/2252 [==============================] - 1s 587us/step - loss: 0.0464 - acc: 0.8764 - val_loss: 0.0833 - val_acc: 0.7646\n",
      "Epoch 767/5000\n",
      "2252/2252 [==============================] - 1s 587us/step - loss: 0.0462 - acc: 0.8768 - val_loss: 0.0853 - val_acc: 0.7594\n",
      "Epoch 768/5000\n",
      "2252/2252 [==============================] - 1s 596us/step - loss: 0.0456 - acc: 0.8796 - val_loss: 0.0822 - val_acc: 0.7672\n",
      "Epoch 769/5000\n",
      "2252/2252 [==============================] - 1s 596us/step - loss: 0.0477 - acc: 0.8717 - val_loss: 0.0879 - val_acc: 0.7523\n",
      "Epoch 770/5000\n",
      "2252/2252 [==============================] - 1s 584us/step - loss: 0.0468 - acc: 0.8745 - val_loss: 0.0834 - val_acc: 0.7637\n",
      "Epoch 771/5000\n",
      "2252/2252 [==============================] - 1s 598us/step - loss: 0.0483 - acc: 0.8695 - val_loss: 0.0862 - val_acc: 0.7581\n",
      "Epoch 772/5000\n",
      "2252/2252 [==============================] - 1s 599us/step - loss: 0.0458 - acc: 0.8773 - val_loss: 0.0835 - val_acc: 0.7630\n",
      "Epoch 773/5000\n",
      "2252/2252 [==============================] - 1s 583us/step - loss: 0.0470 - acc: 0.8755 - val_loss: 0.0872 - val_acc: 0.7549\n",
      "Epoch 774/5000\n",
      "2252/2252 [==============================] - 1s 589us/step - loss: 0.0462 - acc: 0.8768 - val_loss: 0.0851 - val_acc: 0.7601\n",
      "Epoch 775/5000\n",
      "2252/2252 [==============================] - 1s 591us/step - loss: 0.0450 - acc: 0.8816 - val_loss: 0.0913 - val_acc: 0.7475\n",
      "Epoch 776/5000\n",
      "2252/2252 [==============================] - 1s 602us/step - loss: 0.0465 - acc: 0.8764 - val_loss: 0.0857 - val_acc: 0.7583\n",
      "Epoch 777/5000\n",
      "2252/2252 [==============================] - 1s 580us/step - loss: 0.0477 - acc: 0.8726 - val_loss: 0.0827 - val_acc: 0.7667\n",
      "Epoch 778/5000\n",
      "2252/2252 [==============================] - 1s 589us/step - loss: 0.0474 - acc: 0.8736 - val_loss: 0.0830 - val_acc: 0.7650\n",
      "Epoch 779/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.0461 - acc: 0.8779 - val_loss: 0.0860 - val_acc: 0.7562\n",
      "Epoch 780/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.0457 - acc: 0.8795 - val_loss: 0.0849 - val_acc: 0.7584\n",
      "Epoch 781/5000\n",
      "2252/2252 [==============================] - 1s 586us/step - loss: 0.0467 - acc: 0.8741 - val_loss: 0.0847 - val_acc: 0.7636\n",
      "Epoch 782/5000\n",
      "2252/2252 [==============================] - 1s 600us/step - loss: 0.0455 - acc: 0.8791 - val_loss: 0.0841 - val_acc: 0.7643\n",
      "Epoch 783/5000\n",
      "2252/2252 [==============================] - 1s 598us/step - loss: 0.0463 - acc: 0.8777 - val_loss: 0.0832 - val_acc: 0.7638\n",
      "Epoch 784/5000\n",
      "2252/2252 [==============================] - 1s 595us/step - loss: 0.0460 - acc: 0.8774 - val_loss: 0.0827 - val_acc: 0.7658\n",
      "Epoch 785/5000\n",
      "2252/2252 [==============================] - 1s 590us/step - loss: 0.0467 - acc: 0.8763 - val_loss: 0.0822 - val_acc: 0.7681\n",
      "Epoch 786/5000\n",
      "2252/2252 [==============================] - 1s 588us/step - loss: 0.0460 - acc: 0.8765 - val_loss: 0.0868 - val_acc: 0.7568\n",
      "Epoch 787/5000\n",
      "2252/2252 [==============================] - 1s 592us/step - loss: 0.0468 - acc: 0.8735 - val_loss: 0.0830 - val_acc: 0.7653\n",
      "Epoch 788/5000\n",
      "2252/2252 [==============================] - 1s 594us/step - loss: 0.0459 - acc: 0.8768 - val_loss: 0.0857 - val_acc: 0.7577\n",
      "Epoch 789/5000\n",
      "2252/2252 [==============================] - 1s 592us/step - loss: 0.0467 - acc: 0.8756 - val_loss: 0.0852 - val_acc: 0.7583\n",
      "Epoch 790/5000\n",
      "2252/2252 [==============================] - 1s 589us/step - loss: 0.0466 - acc: 0.8754 - val_loss: 0.0847 - val_acc: 0.7591\n",
      "Epoch 791/5000\n",
      "2252/2252 [==============================] - 1s 597us/step - loss: 0.0454 - acc: 0.8799 - val_loss: 0.0907 - val_acc: 0.7504\n",
      "Epoch 792/5000\n",
      "2252/2252 [==============================] - 1s 592us/step - loss: 0.0470 - acc: 0.8759 - val_loss: 0.0895 - val_acc: 0.7535\n",
      "Epoch 793/5000\n",
      "2252/2252 [==============================] - 1s 586us/step - loss: 0.0467 - acc: 0.8755 - val_loss: 0.0874 - val_acc: 0.7530\n",
      "Epoch 794/5000\n",
      "2252/2252 [==============================] - 1s 605us/step - loss: 0.0453 - acc: 0.8795 - val_loss: 0.0842 - val_acc: 0.7612\n",
      "Epoch 795/5000\n",
      "2252/2252 [==============================] - 1s 584us/step - loss: 0.0461 - acc: 0.8772 - val_loss: 0.0909 - val_acc: 0.7458\n",
      "Epoch 796/5000\n",
      "2252/2252 [==============================] - 1s 592us/step - loss: 0.0465 - acc: 0.8766 - val_loss: 0.0867 - val_acc: 0.7582\n",
      "Epoch 797/5000\n",
      "2252/2252 [==============================] - 1s 586us/step - loss: 0.0456 - acc: 0.8773 - val_loss: 0.0865 - val_acc: 0.7561\n",
      "Epoch 798/5000\n",
      "2252/2252 [==============================] - 1s 595us/step - loss: 0.0450 - acc: 0.8817 - val_loss: 0.0831 - val_acc: 0.7647\n",
      "Epoch 799/5000\n",
      "2252/2252 [==============================] - 1s 589us/step - loss: 0.0451 - acc: 0.8806 - val_loss: 0.0832 - val_acc: 0.7658\n",
      "Epoch 800/5000\n",
      "2252/2252 [==============================] - 1s 595us/step - loss: 0.0449 - acc: 0.8813 - val_loss: 0.0841 - val_acc: 0.7617\n",
      "Epoch 801/5000\n",
      "2252/2252 [==============================] - 1s 594us/step - loss: 0.0452 - acc: 0.8804 - val_loss: 0.0873 - val_acc: 0.7568\n",
      "Epoch 802/5000\n",
      "2252/2252 [==============================] - 1s 590us/step - loss: 0.0447 - acc: 0.8823 - val_loss: 0.0859 - val_acc: 0.7567\n",
      "Epoch 803/5000\n",
      "2252/2252 [==============================] - 1s 580us/step - loss: 0.0443 - acc: 0.8840 - val_loss: 0.0850 - val_acc: 0.7609\n",
      "Epoch 804/5000\n",
      "2252/2252 [==============================] - 1s 584us/step - loss: 0.0451 - acc: 0.8802 - val_loss: 0.0842 - val_acc: 0.7614\n",
      "Epoch 805/5000\n",
      "2252/2252 [==============================] - 1s 595us/step - loss: 0.0455 - acc: 0.8795 - val_loss: 0.0871 - val_acc: 0.7566\n",
      "Epoch 806/5000\n",
      "2252/2252 [==============================] - 1s 595us/step - loss: 0.0453 - acc: 0.8796 - val_loss: 0.0828 - val_acc: 0.7665\n",
      "Epoch 807/5000\n",
      "2252/2252 [==============================] - 1s 590us/step - loss: 0.0465 - acc: 0.8771 - val_loss: 0.0881 - val_acc: 0.7556\n",
      "Epoch 808/5000\n",
      "2252/2252 [==============================] - 1s 590us/step - loss: 0.0454 - acc: 0.8802 - val_loss: 0.0908 - val_acc: 0.7482\n",
      "Epoch 809/5000\n",
      "2252/2252 [==============================] - 1s 594us/step - loss: 0.0451 - acc: 0.8801 - val_loss: 0.0843 - val_acc: 0.7623\n",
      "Epoch 810/5000\n",
      "2252/2252 [==============================] - 1s 576us/step - loss: 0.0453 - acc: 0.8800 - val_loss: 0.0857 - val_acc: 0.7584\n",
      "Epoch 811/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.0452 - acc: 0.8806 - val_loss: 0.0837 - val_acc: 0.7622\n",
      "Epoch 812/5000\n",
      "2252/2252 [==============================] - 1s 594us/step - loss: 0.0450 - acc: 0.8796 - val_loss: 0.0827 - val_acc: 0.7683\n",
      "Epoch 813/5000\n",
      "2252/2252 [==============================] - 1s 596us/step - loss: 0.0448 - acc: 0.8820 - val_loss: 0.0825 - val_acc: 0.7647\n",
      "Epoch 814/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.0468 - acc: 0.8744 - val_loss: 0.0857 - val_acc: 0.7605\n",
      "Epoch 815/5000\n",
      "2252/2252 [==============================] - 1s 590us/step - loss: 0.0462 - acc: 0.8772 - val_loss: 0.0835 - val_acc: 0.7630\n",
      "Epoch 816/5000\n",
      "2252/2252 [==============================] - 1s 590us/step - loss: 0.0438 - acc: 0.8857 - val_loss: 0.0857 - val_acc: 0.7604\n",
      "Epoch 817/5000\n",
      "2252/2252 [==============================] - 1s 595us/step - loss: 0.0447 - acc: 0.8804 - val_loss: 0.0860 - val_acc: 0.7582\n",
      "Epoch 818/5000\n",
      "2252/2252 [==============================] - 1s 601us/step - loss: 0.0463 - acc: 0.8761 - val_loss: 0.0833 - val_acc: 0.7653\n",
      "Epoch 819/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.0449 - acc: 0.8802 - val_loss: 0.0878 - val_acc: 0.7565\n",
      "Epoch 820/5000\n",
      "2252/2252 [==============================] - 1s 596us/step - loss: 0.0446 - acc: 0.8827 - val_loss: 0.0841 - val_acc: 0.7627\n",
      "Epoch 821/5000\n",
      "2252/2252 [==============================] - 1s 600us/step - loss: 0.0451 - acc: 0.8806 - val_loss: 0.0844 - val_acc: 0.7606\n",
      "Epoch 822/5000\n",
      "2252/2252 [==============================] - 1s 596us/step - loss: 0.0438 - acc: 0.8858 - val_loss: 0.0850 - val_acc: 0.7631\n",
      "Epoch 823/5000\n",
      "2252/2252 [==============================] - 1s 583us/step - loss: 0.0441 - acc: 0.8830 - val_loss: 0.0842 - val_acc: 0.7599\n",
      "Epoch 824/5000\n",
      "2252/2252 [==============================] - 1s 581us/step - loss: 0.0446 - acc: 0.8813 - val_loss: 0.0854 - val_acc: 0.7592\n",
      "Epoch 825/5000\n",
      "2252/2252 [==============================] - 1s 592us/step - loss: 0.0460 - acc: 0.8771 - val_loss: 0.0881 - val_acc: 0.7537\n",
      "Epoch 826/5000\n",
      "2252/2252 [==============================] - 1s 596us/step - loss: 0.0442 - acc: 0.8832 - val_loss: 0.0833 - val_acc: 0.7651\n",
      "Epoch 827/5000\n",
      "2252/2252 [==============================] - 1s 591us/step - loss: 0.0450 - acc: 0.8811 - val_loss: 0.0853 - val_acc: 0.7598\n",
      "Epoch 828/5000\n",
      "2252/2252 [==============================] - 1s 586us/step - loss: 0.0439 - acc: 0.8832 - val_loss: 0.0833 - val_acc: 0.7653\n",
      "Epoch 829/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.0456 - acc: 0.8792 - val_loss: 0.0849 - val_acc: 0.7622\n",
      "Epoch 830/5000\n",
      "2252/2252 [==============================] - 1s 603us/step - loss: 0.0434 - acc: 0.8861 - val_loss: 0.0869 - val_acc: 0.7582\n",
      "Epoch 831/5000\n",
      "2252/2252 [==============================] - 1s 591us/step - loss: 0.0440 - acc: 0.8820 - val_loss: 0.0841 - val_acc: 0.7634\n",
      "Epoch 832/5000\n",
      "2252/2252 [==============================] - 1s 594us/step - loss: 0.0473 - acc: 0.8735 - val_loss: 0.0823 - val_acc: 0.7667\n",
      "Epoch 833/5000\n",
      "2252/2252 [==============================] - 1s 600us/step - loss: 0.0453 - acc: 0.8798 - val_loss: 0.0871 - val_acc: 0.7583\n",
      "Epoch 834/5000\n",
      "2252/2252 [==============================] - 1s 584us/step - loss: 0.0444 - acc: 0.8826 - val_loss: 0.0841 - val_acc: 0.7622\n",
      "Epoch 835/5000\n",
      "2252/2252 [==============================] - 1s 580us/step - loss: 0.0440 - acc: 0.8840 - val_loss: 0.0880 - val_acc: 0.7554\n",
      "Epoch 836/5000\n",
      "2252/2252 [==============================] - 1s 587us/step - loss: 0.0441 - acc: 0.8825 - val_loss: 0.0850 - val_acc: 0.7627\n",
      "Epoch 837/5000\n",
      "2252/2252 [==============================] - 1s 597us/step - loss: 0.0444 - acc: 0.8816 - val_loss: 0.0883 - val_acc: 0.7559\n",
      "Epoch 838/5000\n",
      "2252/2252 [==============================] - 1s 594us/step - loss: 0.0434 - acc: 0.8859 - val_loss: 0.0854 - val_acc: 0.7592\n",
      "Epoch 839/5000\n",
      "2252/2252 [==============================] - 1s 597us/step - loss: 0.0437 - acc: 0.8844 - val_loss: 0.0878 - val_acc: 0.7550\n",
      "Epoch 840/5000\n",
      "2252/2252 [==============================] - 1s 589us/step - loss: 0.0454 - acc: 0.8781 - val_loss: 0.0835 - val_acc: 0.7654\n",
      "Epoch 841/5000\n",
      "2252/2252 [==============================] - 1s 597us/step - loss: 0.0435 - acc: 0.8839 - val_loss: 0.0851 - val_acc: 0.7614\n",
      "Epoch 842/5000\n",
      "2252/2252 [==============================] - 1s 594us/step - loss: 0.0436 - acc: 0.8845 - val_loss: 0.0883 - val_acc: 0.7555\n",
      "Epoch 843/5000\n",
      "2252/2252 [==============================] - 1s 598us/step - loss: 0.0433 - acc: 0.8861 - val_loss: 0.0834 - val_acc: 0.7643\n",
      "Epoch 844/5000\n",
      "2252/2252 [==============================] - 1s 596us/step - loss: 0.0442 - acc: 0.8833 - val_loss: 0.0834 - val_acc: 0.7661\n",
      "Epoch 845/5000\n",
      "2252/2252 [==============================] - 1s 594us/step - loss: 0.0442 - acc: 0.8835 - val_loss: 0.0827 - val_acc: 0.7672\n",
      "Epoch 846/5000\n",
      "2252/2252 [==============================] - 1s 595us/step - loss: 0.0438 - acc: 0.8835 - val_loss: 0.0839 - val_acc: 0.7647\n",
      "Epoch 847/5000\n",
      "2252/2252 [==============================] - 1s 596us/step - loss: 0.0444 - acc: 0.8810 - val_loss: 0.0893 - val_acc: 0.7510\n",
      "Epoch 848/5000\n",
      "2252/2252 [==============================] - 1s 586us/step - loss: 0.0432 - acc: 0.8872 - val_loss: 0.0847 - val_acc: 0.7630\n",
      "Epoch 849/5000\n",
      "2252/2252 [==============================] - 1s 592us/step - loss: 0.0456 - acc: 0.8797 - val_loss: 0.0837 - val_acc: 0.7630\n",
      "Epoch 850/5000\n",
      "2252/2252 [==============================] - 1s 605us/step - loss: 0.0429 - acc: 0.8895 - val_loss: 0.0885 - val_acc: 0.7565\n",
      "Epoch 851/5000\n",
      "2252/2252 [==============================] - 1s 586us/step - loss: 0.0437 - acc: 0.8842 - val_loss: 0.0828 - val_acc: 0.7692\n",
      "Epoch 852/5000\n",
      "2252/2252 [==============================] - 1s 602us/step - loss: 0.0440 - acc: 0.8828 - val_loss: 0.0855 - val_acc: 0.7617\n",
      "Epoch 853/5000\n",
      "2252/2252 [==============================] - 1s 597us/step - loss: 0.0439 - acc: 0.8848 - val_loss: 0.0883 - val_acc: 0.7549\n",
      "Epoch 854/5000\n",
      "2252/2252 [==============================] - 1s 594us/step - loss: 0.0462 - acc: 0.8769 - val_loss: 0.0819 - val_acc: 0.7691\n",
      "Epoch 855/5000\n",
      "2252/2252 [==============================] - 1s 596us/step - loss: 0.0458 - acc: 0.8773 - val_loss: 0.0853 - val_acc: 0.7613\n",
      "Epoch 856/5000\n",
      "2252/2252 [==============================] - 1s 583us/step - loss: 0.0434 - acc: 0.8849 - val_loss: 0.0843 - val_acc: 0.7640\n",
      "Epoch 857/5000\n",
      "2252/2252 [==============================] - 1s 591us/step - loss: 0.0434 - acc: 0.8855 - val_loss: 0.0855 - val_acc: 0.7575\n",
      "Epoch 858/5000\n",
      "2252/2252 [==============================] - 1s 602us/step - loss: 0.0417 - acc: 0.8904 - val_loss: 0.0853 - val_acc: 0.7595\n",
      "Epoch 859/5000\n",
      "2252/2252 [==============================] - 1s 596us/step - loss: 0.0425 - acc: 0.8885 - val_loss: 0.0883 - val_acc: 0.7537\n",
      "Epoch 860/5000\n",
      "2252/2252 [==============================] - 1s 577us/step - loss: 0.0459 - acc: 0.8778 - val_loss: 0.0862 - val_acc: 0.7582\n",
      "Epoch 861/5000\n",
      "2252/2252 [==============================] - 1s 598us/step - loss: 0.0439 - acc: 0.8836 - val_loss: 0.0894 - val_acc: 0.7525\n",
      "Epoch 862/5000\n",
      "2252/2252 [==============================] - 1s 590us/step - loss: 0.0436 - acc: 0.8847 - val_loss: 0.0879 - val_acc: 0.7551\n",
      "Epoch 863/5000\n",
      "2252/2252 [==============================] - 1s 581us/step - loss: 0.0422 - acc: 0.8916 - val_loss: 0.0853 - val_acc: 0.7622\n",
      "Epoch 864/5000\n",
      "2252/2252 [==============================] - 1s 592us/step - loss: 0.0419 - acc: 0.8893 - val_loss: 0.0913 - val_acc: 0.7485\n",
      "Epoch 865/5000\n",
      "2252/2252 [==============================] - 1s 587us/step - loss: 0.0442 - acc: 0.8819 - val_loss: 0.0938 - val_acc: 0.7435\n",
      "Epoch 866/5000\n",
      "2252/2252 [==============================] - 1s 602us/step - loss: 0.0454 - acc: 0.8787 - val_loss: 0.0899 - val_acc: 0.7523\n",
      "Epoch 867/5000\n",
      "2252/2252 [==============================] - 1s 598us/step - loss: 0.0429 - acc: 0.8876 - val_loss: 0.0860 - val_acc: 0.7602\n",
      "Epoch 868/5000\n",
      "2252/2252 [==============================] - 1s 575us/step - loss: 0.0430 - acc: 0.8865 - val_loss: 0.0880 - val_acc: 0.7572\n",
      "Epoch 869/5000\n",
      "2252/2252 [==============================] - 1s 595us/step - loss: 0.0437 - acc: 0.8846 - val_loss: 0.0856 - val_acc: 0.7581\n",
      "Epoch 870/5000\n",
      "2252/2252 [==============================] - 1s 592us/step - loss: 0.0422 - acc: 0.8876 - val_loss: 0.0912 - val_acc: 0.7500\n",
      "Epoch 871/5000\n",
      "2252/2252 [==============================] - 1s 587us/step - loss: 0.0436 - acc: 0.8839 - val_loss: 0.0847 - val_acc: 0.7611\n",
      "Epoch 872/5000\n",
      "2252/2252 [==============================] - 1s 589us/step - loss: 0.0433 - acc: 0.8864 - val_loss: 0.0835 - val_acc: 0.7648\n",
      "Epoch 873/5000\n",
      "2252/2252 [==============================] - 1s 598us/step - loss: 0.0445 - acc: 0.8816 - val_loss: 0.0921 - val_acc: 0.7487\n",
      "Epoch 874/5000\n",
      "2252/2252 [==============================] - 1s 591us/step - loss: 0.0442 - acc: 0.8833 - val_loss: 0.0835 - val_acc: 0.7651\n",
      "Epoch 875/5000\n",
      "2252/2252 [==============================] - 1s 588us/step - loss: 0.0469 - acc: 0.8751 - val_loss: 0.0830 - val_acc: 0.7700\n",
      "Epoch 876/5000\n",
      "2252/2252 [==============================] - 1s 578us/step - loss: 0.0443 - acc: 0.8841 - val_loss: 0.0858 - val_acc: 0.7597\n",
      "Epoch 877/5000\n",
      "2252/2252 [==============================] - 1s 591us/step - loss: 0.0425 - acc: 0.8884 - val_loss: 0.0844 - val_acc: 0.7637\n",
      "Epoch 878/5000\n",
      "2252/2252 [==============================] - 1s 595us/step - loss: 0.0426 - acc: 0.8873 - val_loss: 0.0858 - val_acc: 0.7603\n",
      "Epoch 879/5000\n",
      "2252/2252 [==============================] - 1s 594us/step - loss: 0.0432 - acc: 0.8852 - val_loss: 0.0900 - val_acc: 0.7520\n",
      "Epoch 880/5000\n",
      "2252/2252 [==============================] - 1s 600us/step - loss: 0.0434 - acc: 0.8845 - val_loss: 0.0917 - val_acc: 0.7455\n",
      "Epoch 881/5000\n",
      "2252/2252 [==============================] - 1s 591us/step - loss: 0.0427 - acc: 0.8863 - val_loss: 0.0867 - val_acc: 0.7582\n",
      "Epoch 882/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.0423 - acc: 0.8899 - val_loss: 0.0862 - val_acc: 0.7603\n",
      "Epoch 883/5000\n",
      "2252/2252 [==============================] - 1s 598us/step - loss: 0.0423 - acc: 0.8900 - val_loss: 0.0841 - val_acc: 0.7659\n",
      "Epoch 884/5000\n",
      "2252/2252 [==============================] - 1s 578us/step - loss: 0.0436 - acc: 0.8847 - val_loss: 0.0919 - val_acc: 0.7461\n",
      "Epoch 885/5000\n",
      "2252/2252 [==============================] - 1s 584us/step - loss: 0.0439 - acc: 0.8842 - val_loss: 0.0897 - val_acc: 0.7527\n",
      "Epoch 886/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.0428 - acc: 0.8868 - val_loss: 0.0828 - val_acc: 0.7687\n",
      "Epoch 887/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.0453 - acc: 0.8791 - val_loss: 0.0833 - val_acc: 0.7630\n",
      "Epoch 888/5000\n",
      "2252/2252 [==============================] - 1s 598us/step - loss: 0.0426 - acc: 0.8881 - val_loss: 0.0856 - val_acc: 0.7599\n",
      "Epoch 889/5000\n",
      "2252/2252 [==============================] - 1s 603us/step - loss: 0.0418 - acc: 0.8905 - val_loss: 0.0860 - val_acc: 0.7604\n",
      "Epoch 890/5000\n",
      "2252/2252 [==============================] - 1s 591us/step - loss: 0.0440 - acc: 0.8841 - val_loss: 0.0824 - val_acc: 0.7694\n",
      "Epoch 891/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.0432 - acc: 0.8872 - val_loss: 0.0911 - val_acc: 0.7494\n",
      "Epoch 892/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.0422 - acc: 0.8888 - val_loss: 0.0857 - val_acc: 0.7587\n",
      "Epoch 893/5000\n",
      "2252/2252 [==============================] - 1s 598us/step - loss: 0.0430 - acc: 0.8865 - val_loss: 0.0884 - val_acc: 0.7556\n",
      "Epoch 894/5000\n",
      "2252/2252 [==============================] - 1s 597us/step - loss: 0.0433 - acc: 0.8861 - val_loss: 0.0850 - val_acc: 0.7627\n",
      "Epoch 895/5000\n",
      "2252/2252 [==============================] - 1s 592us/step - loss: 0.0417 - acc: 0.8901 - val_loss: 0.0834 - val_acc: 0.7677\n",
      "Epoch 896/5000\n",
      "2252/2252 [==============================] - 1s 590us/step - loss: 0.0428 - acc: 0.8884 - val_loss: 0.0835 - val_acc: 0.7659\n",
      "Epoch 897/5000\n",
      "2252/2252 [==============================] - 1s 582us/step - loss: 0.0418 - acc: 0.8912 - val_loss: 0.0854 - val_acc: 0.7610\n",
      "Epoch 898/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.0421 - acc: 0.8888 - val_loss: 0.0846 - val_acc: 0.7626\n",
      "Epoch 899/5000\n",
      "2252/2252 [==============================] - 1s 591us/step - loss: 0.0424 - acc: 0.8871 - val_loss: 0.0874 - val_acc: 0.7599\n",
      "Epoch 900/5000\n",
      "2252/2252 [==============================] - 1s 597us/step - loss: 0.0413 - acc: 0.8911 - val_loss: 0.0849 - val_acc: 0.7631\n",
      "Epoch 901/5000\n",
      "2252/2252 [==============================] - 1s 589us/step - loss: 0.0427 - acc: 0.8894 - val_loss: 0.0861 - val_acc: 0.7621\n",
      "Epoch 902/5000\n",
      "2252/2252 [==============================] - 1s 595us/step - loss: 0.0413 - acc: 0.8925 - val_loss: 0.0871 - val_acc: 0.7604\n",
      "Epoch 903/5000\n",
      "2252/2252 [==============================] - 1s 597us/step - loss: 0.0423 - acc: 0.8878 - val_loss: 0.0868 - val_acc: 0.7604\n",
      "Epoch 904/5000\n",
      "2252/2252 [==============================] - 1s 603us/step - loss: 0.0434 - acc: 0.8844 - val_loss: 0.0863 - val_acc: 0.7597\n",
      "Epoch 905/5000\n",
      "2252/2252 [==============================] - 1s 591us/step - loss: 0.0422 - acc: 0.8901 - val_loss: 0.0890 - val_acc: 0.7527\n",
      "Epoch 906/5000\n",
      "2252/2252 [==============================] - 1s 594us/step - loss: 0.0418 - acc: 0.8914 - val_loss: 0.0900 - val_acc: 0.7520\n",
      "Epoch 907/5000\n",
      "2252/2252 [==============================] - 1s 601us/step - loss: 0.0433 - acc: 0.8866 - val_loss: 0.0858 - val_acc: 0.7631\n",
      "Epoch 908/5000\n",
      "2252/2252 [==============================] - 1s 588us/step - loss: 0.0419 - acc: 0.8901 - val_loss: 0.0911 - val_acc: 0.7498\n",
      "Epoch 909/5000\n",
      "2252/2252 [==============================] - 1s 596us/step - loss: 0.0424 - acc: 0.8884 - val_loss: 0.0900 - val_acc: 0.7519\n",
      "Epoch 910/5000\n",
      "2252/2252 [==============================] - 1s 588us/step - loss: 0.0414 - acc: 0.8920 - val_loss: 0.0862 - val_acc: 0.7581\n",
      "Epoch 911/5000\n",
      "2252/2252 [==============================] - 1s 586us/step - loss: 0.0423 - acc: 0.8879 - val_loss: 0.0855 - val_acc: 0.7632\n",
      "Epoch 912/5000\n",
      "2252/2252 [==============================] - 1s 585us/step - loss: 0.0461 - acc: 0.8781 - val_loss: 0.0932 - val_acc: 0.7451\n",
      "Epoch 913/5000\n",
      "2252/2252 [==============================] - 1s 598us/step - loss: 0.0425 - acc: 0.8889 - val_loss: 0.0845 - val_acc: 0.7651\n",
      "Epoch 914/5000\n",
      "2252/2252 [==============================] - 1s 597us/step - loss: 0.0412 - acc: 0.8917 - val_loss: 0.0827 - val_acc: 0.7686\n",
      "Epoch 915/5000\n",
      "2252/2252 [==============================] - 1s 597us/step - loss: 0.0421 - acc: 0.8886 - val_loss: 0.0842 - val_acc: 0.7665\n",
      "Epoch 916/5000\n",
      "2252/2252 [==============================] - 1s 596us/step - loss: 0.0407 - acc: 0.8938 - val_loss: 0.0905 - val_acc: 0.7496\n",
      "Epoch 917/5000\n",
      "2252/2252 [==============================] - 1s 592us/step - loss: 0.0439 - acc: 0.8830 - val_loss: 0.0958 - val_acc: 0.7392\n",
      "Epoch 918/5000\n",
      "2252/2252 [==============================] - 1s 597us/step - loss: 0.0435 - acc: 0.8862 - val_loss: 0.0876 - val_acc: 0.7552\n",
      "Epoch 919/5000\n",
      "2252/2252 [==============================] - 1s 597us/step - loss: 0.0414 - acc: 0.8922 - val_loss: 0.0821 - val_acc: 0.7734\n",
      "Epoch 920/5000\n",
      "2252/2252 [==============================] - 1s 585us/step - loss: 0.0428 - acc: 0.8877 - val_loss: 0.0864 - val_acc: 0.7617\n",
      "Epoch 921/5000\n",
      "2252/2252 [==============================] - 1s 595us/step - loss: 0.0417 - acc: 0.8893 - val_loss: 0.0895 - val_acc: 0.7544\n",
      "Epoch 922/5000\n",
      "2252/2252 [==============================] - 1s 581us/step - loss: 0.0411 - acc: 0.8937 - val_loss: 0.0889 - val_acc: 0.7544\n",
      "Epoch 923/5000\n",
      "2252/2252 [==============================] - 1s 597us/step - loss: 0.0414 - acc: 0.8914 - val_loss: 0.0863 - val_acc: 0.7618\n",
      "Epoch 924/5000\n",
      "2252/2252 [==============================] - 1s 597us/step - loss: 0.0412 - acc: 0.8923 - val_loss: 0.0840 - val_acc: 0.7649\n",
      "Epoch 925/5000\n",
      "2252/2252 [==============================] - 1s 598us/step - loss: 0.0420 - acc: 0.8905 - val_loss: 0.0827 - val_acc: 0.7710\n",
      "Epoch 926/5000\n",
      "2252/2252 [==============================] - 1s 592us/step - loss: 0.0418 - acc: 0.8895 - val_loss: 0.0843 - val_acc: 0.7644\n",
      "Epoch 927/5000\n",
      "2252/2252 [==============================] - 1s 595us/step - loss: 0.0415 - acc: 0.8906 - val_loss: 0.0846 - val_acc: 0.7653\n",
      "Epoch 928/5000\n",
      "2252/2252 [==============================] - 1s 601us/step - loss: 0.0406 - acc: 0.8933 - val_loss: 0.0849 - val_acc: 0.7637\n",
      "Epoch 929/5000\n",
      "2252/2252 [==============================] - 1s 591us/step - loss: 0.0420 - acc: 0.8893 - val_loss: 0.0852 - val_acc: 0.7648\n",
      "Epoch 930/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2252/2252 [==============================] - 1s 588us/step - loss: 0.0415 - acc: 0.8915 - val_loss: 0.0919 - val_acc: 0.7501\n",
      "Epoch 931/5000\n",
      "2252/2252 [==============================] - 1s 581us/step - loss: 0.0415 - acc: 0.8917 - val_loss: 0.0847 - val_acc: 0.7629\n",
      "Epoch 932/5000\n",
      "2252/2252 [==============================] - 1s 600us/step - loss: 0.0420 - acc: 0.8873 - val_loss: 0.0846 - val_acc: 0.7640\n",
      "Epoch 933/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.0411 - acc: 0.8925 - val_loss: 0.0857 - val_acc: 0.7623\n",
      "Epoch 934/5000\n",
      "2252/2252 [==============================] - 1s 582us/step - loss: 0.0408 - acc: 0.8926 - val_loss: 0.0862 - val_acc: 0.7629\n",
      "Epoch 935/5000\n",
      "2252/2252 [==============================] - 1s 589us/step - loss: 0.0417 - acc: 0.8907 - val_loss: 0.0859 - val_acc: 0.7604\n",
      "Epoch 936/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.0421 - acc: 0.8882 - val_loss: 0.0850 - val_acc: 0.7642\n",
      "Epoch 937/5000\n",
      "2252/2252 [==============================] - 1s 589us/step - loss: 0.0415 - acc: 0.8907 - val_loss: 0.0884 - val_acc: 0.7562\n",
      "Epoch 938/5000\n",
      "2252/2252 [==============================] - 1s 584us/step - loss: 0.0438 - acc: 0.8857 - val_loss: 0.0912 - val_acc: 0.7519\n",
      "Epoch 939/5000\n",
      "2252/2252 [==============================] - 1s 592us/step - loss: 0.0411 - acc: 0.8927 - val_loss: 0.0870 - val_acc: 0.7590\n",
      "Epoch 940/5000\n",
      "2252/2252 [==============================] - 1s 594us/step - loss: 0.0409 - acc: 0.8928 - val_loss: 0.0888 - val_acc: 0.7574\n",
      "Epoch 941/5000\n",
      "2252/2252 [==============================] - 1s 601us/step - loss: 0.0407 - acc: 0.8936 - val_loss: 0.0869 - val_acc: 0.7630\n",
      "Epoch 942/5000\n",
      "2252/2252 [==============================] - 1s 600us/step - loss: 0.0411 - acc: 0.8927 - val_loss: 0.0895 - val_acc: 0.7526\n",
      "Epoch 943/5000\n",
      "2252/2252 [==============================] - 1s 605us/step - loss: 0.0419 - acc: 0.8897 - val_loss: 0.0914 - val_acc: 0.7499\n",
      "Epoch 944/5000\n",
      "2252/2252 [==============================] - 1s 592us/step - loss: 0.0412 - acc: 0.8928 - val_loss: 0.0857 - val_acc: 0.7634\n",
      "Epoch 945/5000\n",
      "2252/2252 [==============================] - 1s 589us/step - loss: 0.0409 - acc: 0.8930 - val_loss: 0.0858 - val_acc: 0.7618\n",
      "Epoch 946/5000\n",
      "2252/2252 [==============================] - 1s 596us/step - loss: 0.0408 - acc: 0.8928 - val_loss: 0.0852 - val_acc: 0.7649\n",
      "Epoch 947/5000\n",
      "2252/2252 [==============================] - 1s 602us/step - loss: 0.0418 - acc: 0.8910 - val_loss: 0.0843 - val_acc: 0.7665\n",
      "Epoch 948/5000\n",
      "2252/2252 [==============================] - 1s 588us/step - loss: 0.0405 - acc: 0.8952 - val_loss: 0.0845 - val_acc: 0.7656\n",
      "Epoch 949/5000\n",
      "2252/2252 [==============================] - 1s 597us/step - loss: 0.0407 - acc: 0.8937 - val_loss: 0.0853 - val_acc: 0.7631\n",
      "Epoch 950/5000\n",
      "2252/2252 [==============================] - 1s 598us/step - loss: 0.0400 - acc: 0.8945 - val_loss: 0.0870 - val_acc: 0.7584\n",
      "Epoch 951/5000\n",
      "2252/2252 [==============================] - 1s 598us/step - loss: 0.0405 - acc: 0.8945 - val_loss: 0.0911 - val_acc: 0.7496\n",
      "Epoch 952/5000\n",
      "2252/2252 [==============================] - 1s 599us/step - loss: 0.0399 - acc: 0.8963 - val_loss: 0.0873 - val_acc: 0.7594\n",
      "Epoch 953/5000\n",
      "2252/2252 [==============================] - 1s 599us/step - loss: 0.0425 - acc: 0.8889 - val_loss: 0.0866 - val_acc: 0.7580\n",
      "Epoch 954/5000\n",
      "2252/2252 [==============================] - 1s 598us/step - loss: 0.0413 - acc: 0.8913 - val_loss: 0.0882 - val_acc: 0.7585\n",
      "Epoch 955/5000\n",
      "2252/2252 [==============================] - 1s 602us/step - loss: 0.0405 - acc: 0.8944 - val_loss: 0.0853 - val_acc: 0.7646\n",
      "Epoch 956/5000\n",
      "2252/2252 [==============================] - 1s 589us/step - loss: 0.0403 - acc: 0.8956 - val_loss: 0.0917 - val_acc: 0.7522\n",
      "Epoch 957/5000\n",
      "2252/2252 [==============================] - 1s 585us/step - loss: 0.0418 - acc: 0.8905 - val_loss: 0.0848 - val_acc: 0.7642\n",
      "Epoch 958/5000\n",
      "2252/2252 [==============================] - 1s 595us/step - loss: 0.0402 - acc: 0.8955 - val_loss: 0.0862 - val_acc: 0.7603\n",
      "Epoch 959/5000\n",
      "2252/2252 [==============================] - 1s 590us/step - loss: 0.0398 - acc: 0.8959 - val_loss: 0.0838 - val_acc: 0.7682\n",
      "Epoch 960/5000\n",
      "2252/2252 [==============================] - 1s 604us/step - loss: 0.0412 - acc: 0.8918 - val_loss: 0.0846 - val_acc: 0.7637\n",
      "Epoch 961/5000\n",
      "2252/2252 [==============================] - 1s 591us/step - loss: 0.0408 - acc: 0.8924 - val_loss: 0.0860 - val_acc: 0.7615\n",
      "Epoch 962/5000\n",
      "2252/2252 [==============================] - 1s 594us/step - loss: 0.0405 - acc: 0.8936 - val_loss: 0.0846 - val_acc: 0.7646\n",
      "Epoch 963/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.0401 - acc: 0.8956 - val_loss: 0.0858 - val_acc: 0.7606\n",
      "Epoch 964/5000\n",
      "2252/2252 [==============================] - 1s 602us/step - loss: 0.0403 - acc: 0.8948 - val_loss: 0.0856 - val_acc: 0.7644\n",
      "Epoch 965/5000\n",
      "2252/2252 [==============================] - 1s 584us/step - loss: 0.0394 - acc: 0.8985 - val_loss: 0.0877 - val_acc: 0.7578\n",
      "Epoch 966/5000\n",
      "2252/2252 [==============================] - 1s 583us/step - loss: 0.0407 - acc: 0.8933 - val_loss: 0.0897 - val_acc: 0.7509\n",
      "Epoch 967/5000\n",
      "2252/2252 [==============================] - 1s 595us/step - loss: 0.0413 - acc: 0.8927 - val_loss: 0.0844 - val_acc: 0.7675\n",
      "Epoch 968/5000\n",
      "2252/2252 [==============================] - 1s 575us/step - loss: 0.0405 - acc: 0.8935 - val_loss: 0.0878 - val_acc: 0.7544\n",
      "Epoch 969/5000\n",
      "2252/2252 [==============================] - 1s 597us/step - loss: 0.0397 - acc: 0.8973 - val_loss: 0.0863 - val_acc: 0.7617\n",
      "Epoch 970/5000\n",
      "2252/2252 [==============================] - 1s 596us/step - loss: 0.0413 - acc: 0.8919 - val_loss: 0.0869 - val_acc: 0.7584\n",
      "Epoch 971/5000\n",
      "2252/2252 [==============================] - 1s 588us/step - loss: 0.0395 - acc: 0.8981 - val_loss: 0.0856 - val_acc: 0.7628\n",
      "Epoch 972/5000\n",
      "2252/2252 [==============================] - 1s 568us/step - loss: 0.0401 - acc: 0.8961 - val_loss: 0.0880 - val_acc: 0.7561\n",
      "Epoch 973/5000\n",
      "2252/2252 [==============================] - 1s 595us/step - loss: 0.0402 - acc: 0.8950 - val_loss: 0.0906 - val_acc: 0.7532\n",
      "Epoch 974/5000\n",
      "2252/2252 [==============================] - 1s 589us/step - loss: 0.0411 - acc: 0.8922 - val_loss: 0.0840 - val_acc: 0.7675\n",
      "Epoch 975/5000\n",
      "2252/2252 [==============================] - 1s 588us/step - loss: 0.0404 - acc: 0.8953 - val_loss: 0.0890 - val_acc: 0.7565\n",
      "Epoch 976/5000\n",
      "2252/2252 [==============================] - 1s 586us/step - loss: 0.0409 - acc: 0.8928 - val_loss: 0.0860 - val_acc: 0.7619\n",
      "Epoch 977/5000\n",
      "2252/2252 [==============================] - 1s 596us/step - loss: 0.0393 - acc: 0.8964 - val_loss: 0.0882 - val_acc: 0.7593\n",
      "Epoch 978/5000\n",
      "2252/2252 [==============================] - 1s 588us/step - loss: 0.0399 - acc: 0.8965 - val_loss: 0.0844 - val_acc: 0.7677\n",
      "Epoch 979/5000\n",
      "2252/2252 [==============================] - 1s 585us/step - loss: 0.0394 - acc: 0.8986 - val_loss: 0.0888 - val_acc: 0.7541\n",
      "Epoch 980/5000\n",
      "2252/2252 [==============================] - 1s 590us/step - loss: 0.0409 - acc: 0.8936 - val_loss: 0.0902 - val_acc: 0.7565\n",
      "Epoch 981/5000\n",
      "2252/2252 [==============================] - 1s 595us/step - loss: 0.0401 - acc: 0.8961 - val_loss: 0.0907 - val_acc: 0.7551\n",
      "Epoch 982/5000\n",
      "2252/2252 [==============================] - 1s 588us/step - loss: 0.0403 - acc: 0.8957 - val_loss: 0.0839 - val_acc: 0.7660\n",
      "Epoch 983/5000\n",
      "2252/2252 [==============================] - 1s 592us/step - loss: 0.0418 - acc: 0.8895 - val_loss: 0.0851 - val_acc: 0.7642\n",
      "Epoch 984/5000\n",
      "2252/2252 [==============================] - 1s 602us/step - loss: 0.0396 - acc: 0.8975 - val_loss: 0.0925 - val_acc: 0.7482\n",
      "Epoch 985/5000\n",
      "2252/2252 [==============================] - 1s 585us/step - loss: 0.0404 - acc: 0.8939 - val_loss: 0.0903 - val_acc: 0.7522\n",
      "Epoch 986/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.0405 - acc: 0.8950 - val_loss: 0.0887 - val_acc: 0.7563\n",
      "Epoch 987/5000\n",
      "2252/2252 [==============================] - 1s 580us/step - loss: 0.0417 - acc: 0.8897 - val_loss: 0.0843 - val_acc: 0.7670\n",
      "Epoch 988/5000\n",
      "2252/2252 [==============================] - 1s 601us/step - loss: 0.0409 - acc: 0.8929 - val_loss: 0.0852 - val_acc: 0.7656\n",
      "Epoch 989/5000\n",
      "2252/2252 [==============================] - 1s 584us/step - loss: 0.0400 - acc: 0.8960 - val_loss: 0.0900 - val_acc: 0.7520\n",
      "Epoch 990/5000\n",
      "2252/2252 [==============================] - 1s 586us/step - loss: 0.0400 - acc: 0.8956 - val_loss: 0.0923 - val_acc: 0.7499\n",
      "Epoch 991/5000\n",
      "2252/2252 [==============================] - 1s 583us/step - loss: 0.0398 - acc: 0.8973 - val_loss: 0.0842 - val_acc: 0.7669\n",
      "Epoch 992/5000\n",
      "2252/2252 [==============================] - 1s 590us/step - loss: 0.0397 - acc: 0.8956 - val_loss: 0.0861 - val_acc: 0.7610\n",
      "Epoch 993/5000\n",
      "2252/2252 [==============================] - 1s 590us/step - loss: 0.0395 - acc: 0.8973 - val_loss: 0.0851 - val_acc: 0.7675\n",
      "Epoch 994/5000\n",
      "2252/2252 [==============================] - 1s 598us/step - loss: 0.0421 - acc: 0.8877 - val_loss: 0.0844 - val_acc: 0.7648\n",
      "Epoch 995/5000\n",
      "2252/2252 [==============================] - 1s 576us/step - loss: 0.0401 - acc: 0.8947 - val_loss: 0.0907 - val_acc: 0.7524\n",
      "Epoch 996/5000\n",
      "2252/2252 [==============================] - 1s 587us/step - loss: 0.0395 - acc: 0.8956 - val_loss: 0.0873 - val_acc: 0.7577\n",
      "Epoch 997/5000\n",
      "2252/2252 [==============================] - 1s 582us/step - loss: 0.0404 - acc: 0.8931 - val_loss: 0.0873 - val_acc: 0.7604\n",
      "Epoch 998/5000\n",
      "2252/2252 [==============================] - 1s 589us/step - loss: 0.0386 - acc: 0.9005 - val_loss: 0.0847 - val_acc: 0.7658\n",
      "Epoch 999/5000\n",
      "2252/2252 [==============================] - 1s 598us/step - loss: 0.0395 - acc: 0.8980 - val_loss: 0.0877 - val_acc: 0.7583\n",
      "Epoch 1000/5000\n",
      "2252/2252 [==============================] - 1s 576us/step - loss: 0.0392 - acc: 0.8992 - val_loss: 0.0946 - val_acc: 0.7449\n",
      "Epoch 1001/5000\n",
      "2252/2252 [==============================] - 1s 591us/step - loss: 0.0418 - acc: 0.8914 - val_loss: 0.0872 - val_acc: 0.7585\n",
      "Epoch 1002/5000\n",
      "2252/2252 [==============================] - 1s 591us/step - loss: 0.0393 - acc: 0.8999 - val_loss: 0.0943 - val_acc: 0.7457\n",
      "Epoch 1003/5000\n",
      "2252/2252 [==============================] - 1s 597us/step - loss: 0.0395 - acc: 0.8982 - val_loss: 0.0894 - val_acc: 0.7540\n",
      "Epoch 1004/5000\n",
      "2252/2252 [==============================] - 1s 599us/step - loss: 0.0393 - acc: 0.8973 - val_loss: 0.0862 - val_acc: 0.7609\n",
      "Epoch 1005/5000\n",
      "2252/2252 [==============================] - 1s 590us/step - loss: 0.0399 - acc: 0.8954 - val_loss: 0.0880 - val_acc: 0.7546\n",
      "Epoch 1006/5000\n",
      "2252/2252 [==============================] - 1s 603us/step - loss: 0.0383 - acc: 0.9015 - val_loss: 0.0853 - val_acc: 0.7641\n",
      "Epoch 1007/5000\n",
      "2252/2252 [==============================] - 1s 606us/step - loss: 0.0391 - acc: 0.8985 - val_loss: 0.0863 - val_acc: 0.7618\n",
      "Epoch 1008/5000\n",
      "2252/2252 [==============================] - 1s 588us/step - loss: 0.0396 - acc: 0.8959 - val_loss: 0.0854 - val_acc: 0.7615\n",
      "Epoch 1009/5000\n",
      "2252/2252 [==============================] - 1s 570us/step - loss: 0.0390 - acc: 0.8989 - val_loss: 0.0876 - val_acc: 0.7592\n",
      "Epoch 1010/5000\n",
      "2252/2252 [==============================] - 1s 590us/step - loss: 0.0424 - acc: 0.8896 - val_loss: 0.0836 - val_acc: 0.7675\n",
      "Epoch 1011/5000\n",
      "2252/2252 [==============================] - 1s 588us/step - loss: 0.0389 - acc: 0.8991 - val_loss: 0.0912 - val_acc: 0.7506\n",
      "Epoch 1012/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.0385 - acc: 0.9003 - val_loss: 0.0904 - val_acc: 0.7552\n",
      "Epoch 1013/5000\n",
      "2252/2252 [==============================] - 1s 596us/step - loss: 0.0416 - acc: 0.8899 - val_loss: 0.0874 - val_acc: 0.7578\n",
      "Epoch 1014/5000\n",
      "2252/2252 [==============================] - 1s 600us/step - loss: 0.0410 - acc: 0.8930 - val_loss: 0.0838 - val_acc: 0.7694\n",
      "Epoch 1015/5000\n",
      "2252/2252 [==============================] - 1s 602us/step - loss: 0.0397 - acc: 0.8967 - val_loss: 0.0841 - val_acc: 0.7675\n",
      "Epoch 1016/5000\n",
      "2252/2252 [==============================] - 1s 598us/step - loss: 0.0388 - acc: 0.8998 - val_loss: 0.0842 - val_acc: 0.7682\n",
      "Epoch 1017/5000\n",
      "2252/2252 [==============================] - 1s 603us/step - loss: 0.0391 - acc: 0.8975 - val_loss: 0.0865 - val_acc: 0.7627\n",
      "Epoch 1018/5000\n",
      "2252/2252 [==============================] - 1s 584us/step - loss: 0.0387 - acc: 0.8988 - val_loss: 0.0857 - val_acc: 0.7629\n",
      "Epoch 1019/5000\n",
      "2252/2252 [==============================] - 1s 596us/step - loss: 0.0385 - acc: 0.8999 - val_loss: 0.0853 - val_acc: 0.7651\n",
      "Epoch 1020/5000\n",
      "2252/2252 [==============================] - 1s 587us/step - loss: 0.0395 - acc: 0.8971 - val_loss: 0.0849 - val_acc: 0.7684\n",
      "Epoch 1021/5000\n",
      "2252/2252 [==============================] - 1s 601us/step - loss: 0.0384 - acc: 0.9007 - val_loss: 0.0926 - val_acc: 0.7501\n",
      "Epoch 1022/5000\n",
      "2252/2252 [==============================] - 1s 600us/step - loss: 0.0389 - acc: 0.8993 - val_loss: 0.0861 - val_acc: 0.7644\n",
      "Epoch 1023/5000\n",
      "2252/2252 [==============================] - 1s 595us/step - loss: 0.0394 - acc: 0.8978 - val_loss: 0.0863 - val_acc: 0.7623\n",
      "Epoch 1024/5000\n",
      "2252/2252 [==============================] - 1s 589us/step - loss: 0.0388 - acc: 0.8994 - val_loss: 0.0930 - val_acc: 0.7480\n",
      "Epoch 1025/5000\n",
      "2252/2252 [==============================] - 1s 591us/step - loss: 0.0388 - acc: 0.8997 - val_loss: 0.0845 - val_acc: 0.7701\n",
      "Epoch 1026/5000\n",
      "2252/2252 [==============================] - 1s 601us/step - loss: 0.0408 - acc: 0.8914 - val_loss: 0.0850 - val_acc: 0.7648\n",
      "Epoch 1027/5000\n",
      "2252/2252 [==============================] - 1s 595us/step - loss: 0.0399 - acc: 0.8967 - val_loss: 0.0859 - val_acc: 0.7665\n",
      "Epoch 1028/5000\n",
      "2252/2252 [==============================] - 1s 600us/step - loss: 0.0392 - acc: 0.8986 - val_loss: 0.0886 - val_acc: 0.7547\n",
      "Epoch 1029/5000\n",
      "2252/2252 [==============================] - 1s 589us/step - loss: 0.0397 - acc: 0.8970 - val_loss: 0.0857 - val_acc: 0.7640\n",
      "Epoch 1030/5000\n",
      "2252/2252 [==============================] - 1s 590us/step - loss: 0.0391 - acc: 0.8994 - val_loss: 0.0946 - val_acc: 0.7459\n",
      "Epoch 1031/5000\n",
      "2252/2252 [==============================] - 1s 590us/step - loss: 0.0392 - acc: 0.8990 - val_loss: 0.0938 - val_acc: 0.7480\n",
      "Epoch 1032/5000\n",
      "2252/2252 [==============================] - 1s 592us/step - loss: 0.0394 - acc: 0.8974 - val_loss: 0.0904 - val_acc: 0.7550\n",
      "Epoch 1033/5000\n",
      "2252/2252 [==============================] - 1s 598us/step - loss: 0.0383 - acc: 0.9012 - val_loss: 0.0892 - val_acc: 0.7560\n",
      "Epoch 1034/5000\n",
      "2252/2252 [==============================] - 1s 590us/step - loss: 0.0395 - acc: 0.8992 - val_loss: 0.0927 - val_acc: 0.7487\n",
      "Epoch 1035/5000\n",
      "2252/2252 [==============================] - 1s 590us/step - loss: 0.0387 - acc: 0.8996 - val_loss: 0.0849 - val_acc: 0.7673\n",
      "Epoch 1036/5000\n",
      "2252/2252 [==============================] - 1s 601us/step - loss: 0.0385 - acc: 0.8995 - val_loss: 0.0880 - val_acc: 0.7591\n",
      "Epoch 1037/5000\n",
      "2252/2252 [==============================] - 1s 590us/step - loss: 0.0384 - acc: 0.9001 - val_loss: 0.0893 - val_acc: 0.7551\n",
      "Epoch 1038/5000\n",
      "2252/2252 [==============================] - 1s 582us/step - loss: 0.0376 - acc: 0.9025 - val_loss: 0.0859 - val_acc: 0.7625\n",
      "Epoch 1039/5000\n",
      "2252/2252 [==============================] - 1s 590us/step - loss: 0.0385 - acc: 0.9003 - val_loss: 0.0862 - val_acc: 0.7650\n",
      "Epoch 1040/5000\n",
      "2252/2252 [==============================] - 1s 592us/step - loss: 0.0374 - acc: 0.9038 - val_loss: 0.0890 - val_acc: 0.7561\n",
      "Epoch 1041/5000\n",
      "2252/2252 [==============================] - 1s 601us/step - loss: 0.0385 - acc: 0.8987 - val_loss: 0.0878 - val_acc: 0.7596\n",
      "Epoch 1042/5000\n",
      "2252/2252 [==============================] - 1s 589us/step - loss: 0.0390 - acc: 0.8961 - val_loss: 0.0881 - val_acc: 0.7577\n",
      "Epoch 1043/5000\n",
      "2252/2252 [==============================] - 1s 591us/step - loss: 0.0380 - acc: 0.9010 - val_loss: 0.0876 - val_acc: 0.7608\n",
      "Epoch 1044/5000\n",
      "2252/2252 [==============================] - 1s 590us/step - loss: 0.0383 - acc: 0.9021 - val_loss: 0.0846 - val_acc: 0.7672\n",
      "Epoch 1045/5000\n",
      "2252/2252 [==============================] - 1s 596us/step - loss: 0.0392 - acc: 0.8983 - val_loss: 0.0894 - val_acc: 0.7539\n",
      "Epoch 1046/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2252/2252 [==============================] - 1s 596us/step - loss: 0.0380 - acc: 0.9012 - val_loss: 0.0889 - val_acc: 0.7591\n",
      "Epoch 1047/5000\n",
      "2252/2252 [==============================] - 1s 588us/step - loss: 0.0385 - acc: 0.9002 - val_loss: 0.0917 - val_acc: 0.7534\n",
      "Epoch 1048/5000\n",
      "2252/2252 [==============================] - 1s 598us/step - loss: 0.0388 - acc: 0.9004 - val_loss: 0.0905 - val_acc: 0.7537\n",
      "Epoch 1049/5000\n",
      "2252/2252 [==============================] - 1s 599us/step - loss: 0.0401 - acc: 0.8955 - val_loss: 0.0856 - val_acc: 0.7655\n",
      "Epoch 1050/5000\n",
      "2252/2252 [==============================] - 1s 591us/step - loss: 0.0379 - acc: 0.9015 - val_loss: 0.0851 - val_acc: 0.7670\n",
      "Epoch 1051/5000\n",
      "2252/2252 [==============================] - 1s 599us/step - loss: 0.0377 - acc: 0.9024 - val_loss: 0.0853 - val_acc: 0.7696\n",
      "Epoch 1052/5000\n",
      "2252/2252 [==============================] - 1s 591us/step - loss: 0.0411 - acc: 0.8913 - val_loss: 0.0847 - val_acc: 0.7692\n",
      "Epoch 1053/5000\n",
      "2252/2252 [==============================] - 1s 600us/step - loss: 0.0383 - acc: 0.9016 - val_loss: 0.0877 - val_acc: 0.7581\n",
      "Epoch 1054/5000\n",
      "2252/2252 [==============================] - 1s 601us/step - loss: 0.0384 - acc: 0.9006 - val_loss: 0.0868 - val_acc: 0.7621\n",
      "Epoch 1055/5000\n",
      "2252/2252 [==============================] - 1s 603us/step - loss: 0.0380 - acc: 0.9037 - val_loss: 0.0854 - val_acc: 0.7668\n",
      "Epoch 1056/5000\n",
      "2252/2252 [==============================] - 1s 589us/step - loss: 0.0383 - acc: 0.9010 - val_loss: 0.0937 - val_acc: 0.7479\n",
      "Epoch 1057/5000\n",
      "2252/2252 [==============================] - 1s 589us/step - loss: 0.0390 - acc: 0.8982 - val_loss: 0.0853 - val_acc: 0.7675\n",
      "Epoch 1058/5000\n",
      "2252/2252 [==============================] - 1s 591us/step - loss: 0.0376 - acc: 0.9021 - val_loss: 0.0853 - val_acc: 0.7663\n",
      "Epoch 1059/5000\n",
      "2252/2252 [==============================] - 1s 582us/step - loss: 0.0393 - acc: 0.8972 - val_loss: 0.1035 - val_acc: 0.7251\n",
      "Epoch 1060/5000\n",
      "2252/2252 [==============================] - 1s 586us/step - loss: 0.0406 - acc: 0.8934 - val_loss: 0.0941 - val_acc: 0.7486\n",
      "Epoch 1061/5000\n",
      "2252/2252 [==============================] - 1s 577us/step - loss: 0.0383 - acc: 0.9010 - val_loss: 0.0904 - val_acc: 0.7527\n",
      "Epoch 1062/5000\n",
      "2252/2252 [==============================] - 1s 592us/step - loss: 0.0379 - acc: 0.9017 - val_loss: 0.0872 - val_acc: 0.7625\n",
      "Epoch 1063/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.0381 - acc: 0.8998 - val_loss: 0.0871 - val_acc: 0.7607\n",
      "Epoch 1064/5000\n",
      "2252/2252 [==============================] - 1s 597us/step - loss: 0.0380 - acc: 0.9020 - val_loss: 0.0854 - val_acc: 0.7667\n",
      "Epoch 1065/5000\n",
      "2252/2252 [==============================] - 1s 592us/step - loss: 0.0391 - acc: 0.8980 - val_loss: 0.0859 - val_acc: 0.7673\n",
      "Epoch 1066/5000\n",
      "2252/2252 [==============================] - 1s 580us/step - loss: 0.0378 - acc: 0.9029 - val_loss: 0.0868 - val_acc: 0.7651\n",
      "Epoch 1067/5000\n",
      "2252/2252 [==============================] - 1s 589us/step - loss: 0.0381 - acc: 0.9006 - val_loss: 0.0865 - val_acc: 0.7639\n",
      "Epoch 1068/5000\n",
      "2252/2252 [==============================] - 1s 584us/step - loss: 0.0377 - acc: 0.9027 - val_loss: 0.0878 - val_acc: 0.7611\n",
      "Epoch 1069/5000\n",
      "2252/2252 [==============================] - 1s 587us/step - loss: 0.0375 - acc: 0.9032 - val_loss: 0.0875 - val_acc: 0.7603\n",
      "Epoch 1070/5000\n",
      "2252/2252 [==============================] - 1s 598us/step - loss: 0.0369 - acc: 0.9051 - val_loss: 0.0908 - val_acc: 0.7543\n",
      "Epoch 1071/5000\n",
      "2252/2252 [==============================] - 1s 596us/step - loss: 0.0377 - acc: 0.9026 - val_loss: 0.0949 - val_acc: 0.7454\n",
      "Epoch 1072/5000\n",
      "2252/2252 [==============================] - 1s 583us/step - loss: 0.0391 - acc: 0.8968 - val_loss: 0.0855 - val_acc: 0.7649\n",
      "Epoch 1073/5000\n",
      "2252/2252 [==============================] - 1s 590us/step - loss: 0.0374 - acc: 0.9045 - val_loss: 0.0852 - val_acc: 0.7660\n",
      "Epoch 1074/5000\n",
      "2252/2252 [==============================] - 1s 586us/step - loss: 0.0383 - acc: 0.9013 - val_loss: 0.0906 - val_acc: 0.7541\n",
      "Epoch 1075/5000\n",
      "2252/2252 [==============================] - 1s 600us/step - loss: 0.0376 - acc: 0.9011 - val_loss: 0.0880 - val_acc: 0.7574\n",
      "Epoch 1076/5000\n",
      "2252/2252 [==============================] - 1s 591us/step - loss: 0.0394 - acc: 0.8971 - val_loss: 0.0876 - val_acc: 0.7608\n",
      "Epoch 1077/5000\n",
      "2252/2252 [==============================] - 1s 584us/step - loss: 0.0373 - acc: 0.9028 - val_loss: 0.0902 - val_acc: 0.7556\n",
      "Epoch 1078/5000\n",
      "2252/2252 [==============================] - 1s 583us/step - loss: 0.0386 - acc: 0.8994 - val_loss: 0.0882 - val_acc: 0.7585\n",
      "Epoch 1079/5000\n",
      "2252/2252 [==============================] - 1s 587us/step - loss: 0.0380 - acc: 0.9019 - val_loss: 0.0927 - val_acc: 0.7498\n",
      "Epoch 1080/5000\n",
      "2252/2252 [==============================] - 1s 598us/step - loss: 0.0406 - acc: 0.8956 - val_loss: 0.0890 - val_acc: 0.7563\n",
      "Epoch 1081/5000\n",
      "2252/2252 [==============================] - 1s 592us/step - loss: 0.0376 - acc: 0.9025 - val_loss: 0.0885 - val_acc: 0.7592\n",
      "Epoch 1082/5000\n",
      "2252/2252 [==============================] - 1s 568us/step - loss: 0.0377 - acc: 0.9027 - val_loss: 0.0920 - val_acc: 0.7529\n",
      "Epoch 1083/5000\n",
      "2252/2252 [==============================] - 1s 590us/step - loss: 0.0385 - acc: 0.8992 - val_loss: 0.0967 - val_acc: 0.7401\n",
      "Epoch 1084/5000\n",
      "2252/2252 [==============================] - 1s 599us/step - loss: 0.0388 - acc: 0.8990 - val_loss: 0.0864 - val_acc: 0.7634\n",
      "Epoch 1085/5000\n",
      "2252/2252 [==============================] - 1s 595us/step - loss: 0.0367 - acc: 0.9043 - val_loss: 0.0890 - val_acc: 0.7587\n",
      "Epoch 1086/5000\n",
      "2252/2252 [==============================] - 1s 587us/step - loss: 0.0367 - acc: 0.9056 - val_loss: 0.0865 - val_acc: 0.7634\n",
      "Epoch 1087/5000\n",
      "2252/2252 [==============================] - 1s 596us/step - loss: 0.0375 - acc: 0.9023 - val_loss: 0.0882 - val_acc: 0.7585\n",
      "Epoch 1088/5000\n",
      "2252/2252 [==============================] - 1s 594us/step - loss: 0.0369 - acc: 0.9053 - val_loss: 0.0890 - val_acc: 0.7551\n",
      "Epoch 1089/5000\n",
      "2252/2252 [==============================] - 1s 587us/step - loss: 0.0375 - acc: 0.9031 - val_loss: 0.0907 - val_acc: 0.7533\n",
      "Epoch 1090/5000\n",
      "2252/2252 [==============================] - 1s 586us/step - loss: 0.0375 - acc: 0.9026 - val_loss: 0.0850 - val_acc: 0.7687\n",
      "Epoch 1091/5000\n",
      "2252/2252 [==============================] - 1s 601us/step - loss: 0.0373 - acc: 0.9031 - val_loss: 0.0883 - val_acc: 0.7585\n",
      "Epoch 1092/5000\n",
      "2252/2252 [==============================] - 1s 584us/step - loss: 0.0366 - acc: 0.9058 - val_loss: 0.0933 - val_acc: 0.7487\n",
      "Epoch 1093/5000\n",
      "2252/2252 [==============================] - 1s 590us/step - loss: 0.0376 - acc: 0.9026 - val_loss: 0.0919 - val_acc: 0.7513\n",
      "Epoch 1094/5000\n",
      "2252/2252 [==============================] - 1s 601us/step - loss: 0.0375 - acc: 0.9024 - val_loss: 0.0905 - val_acc: 0.7542\n",
      "Epoch 1095/5000\n",
      "2252/2252 [==============================] - 1s 590us/step - loss: 0.0378 - acc: 0.9031 - val_loss: 0.0887 - val_acc: 0.7563\n",
      "Epoch 1096/5000\n",
      "2252/2252 [==============================] - 1s 595us/step - loss: 0.0363 - acc: 0.9072 - val_loss: 0.0884 - val_acc: 0.7591\n",
      "Epoch 1097/5000\n",
      "2252/2252 [==============================] - 1s 601us/step - loss: 0.0373 - acc: 0.9047 - val_loss: 0.0881 - val_acc: 0.7561\n",
      "Epoch 1098/5000\n",
      "2252/2252 [==============================] - 1s 601us/step - loss: 0.0371 - acc: 0.9044 - val_loss: 0.0887 - val_acc: 0.7576\n",
      "Epoch 1099/5000\n",
      "2252/2252 [==============================] - 1s 600us/step - loss: 0.0362 - acc: 0.9076 - val_loss: 0.0895 - val_acc: 0.7561\n",
      "Epoch 1100/5000\n",
      "2252/2252 [==============================] - 1s 602us/step - loss: 0.0382 - acc: 0.9000 - val_loss: 0.0869 - val_acc: 0.7657\n",
      "Epoch 1101/5000\n",
      "2252/2252 [==============================] - 1s 594us/step - loss: 0.0368 - acc: 0.9041 - val_loss: 0.0867 - val_acc: 0.7639\n",
      "Epoch 1102/5000\n",
      "2252/2252 [==============================] - 1s 595us/step - loss: 0.0389 - acc: 0.8993 - val_loss: 0.0896 - val_acc: 0.7542\n",
      "Epoch 1103/5000\n",
      "2252/2252 [==============================] - 1s 602us/step - loss: 0.0376 - acc: 0.9025 - val_loss: 0.0903 - val_acc: 0.7570\n",
      "Epoch 1104/5000\n",
      "2252/2252 [==============================] - 1s 589us/step - loss: 0.0370 - acc: 0.9055 - val_loss: 0.0862 - val_acc: 0.7698\n",
      "Epoch 1105/5000\n",
      "2252/2252 [==============================] - 1s 587us/step - loss: 0.0401 - acc: 0.8942 - val_loss: 0.0874 - val_acc: 0.7623\n",
      "Epoch 1106/5000\n",
      "2252/2252 [==============================] - 1s 595us/step - loss: 0.0374 - acc: 0.9028 - val_loss: 0.0863 - val_acc: 0.7682\n",
      "Epoch 1107/5000\n",
      "2252/2252 [==============================] - 1s 580us/step - loss: 0.0403 - acc: 0.8939 - val_loss: 0.0847 - val_acc: 0.7665\n",
      "Epoch 1108/5000\n",
      "2252/2252 [==============================] - 1s 592us/step - loss: 0.0389 - acc: 0.8986 - val_loss: 0.0865 - val_acc: 0.7643\n",
      "Epoch 1109/5000\n",
      "2252/2252 [==============================] - 1s 597us/step - loss: 0.0387 - acc: 0.8994 - val_loss: 0.0931 - val_acc: 0.7475\n",
      "Epoch 1110/5000\n",
      "2252/2252 [==============================] - 1s 596us/step - loss: 0.0378 - acc: 0.9019 - val_loss: 0.0871 - val_acc: 0.7651\n",
      "Epoch 1111/5000\n",
      "2252/2252 [==============================] - 1s 591us/step - loss: 0.0365 - acc: 0.9056 - val_loss: 0.0918 - val_acc: 0.7549\n",
      "Epoch 1112/5000\n",
      "2252/2252 [==============================] - 1s 591us/step - loss: 0.0358 - acc: 0.9078 - val_loss: 0.0902 - val_acc: 0.7546\n",
      "Epoch 1113/5000\n",
      "2252/2252 [==============================] - 1s 597us/step - loss: 0.0370 - acc: 0.9052 - val_loss: 0.0855 - val_acc: 0.7682\n",
      "Epoch 1114/5000\n",
      "2252/2252 [==============================] - 1s 588us/step - loss: 0.0369 - acc: 0.9062 - val_loss: 0.0897 - val_acc: 0.7566\n",
      "Epoch 1115/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.0365 - acc: 0.9064 - val_loss: 0.0899 - val_acc: 0.7564\n",
      "Epoch 1116/5000\n",
      "2252/2252 [==============================] - 1s 589us/step - loss: 0.0356 - acc: 0.9083 - val_loss: 0.0884 - val_acc: 0.7619\n",
      "Epoch 1117/5000\n",
      "2252/2252 [==============================] - 1s 591us/step - loss: 0.0371 - acc: 0.9025 - val_loss: 0.0894 - val_acc: 0.7595\n",
      "Epoch 1118/5000\n",
      "2252/2252 [==============================] - 1s 584us/step - loss: 0.0360 - acc: 0.9073 - val_loss: 0.0876 - val_acc: 0.7592\n",
      "Epoch 1119/5000\n",
      "2252/2252 [==============================] - 1s 588us/step - loss: 0.0364 - acc: 0.9053 - val_loss: 0.0868 - val_acc: 0.7656\n",
      "Epoch 1120/5000\n",
      "2252/2252 [==============================] - 1s 601us/step - loss: 0.0366 - acc: 0.9055 - val_loss: 0.0861 - val_acc: 0.7672\n",
      "Epoch 1121/5000\n",
      "2252/2252 [==============================] - 1s 601us/step - loss: 0.0365 - acc: 0.9059 - val_loss: 0.0869 - val_acc: 0.7645\n",
      "Epoch 1122/5000\n",
      "2252/2252 [==============================] - 1s 584us/step - loss: 0.0363 - acc: 0.9058 - val_loss: 0.0872 - val_acc: 0.7650\n",
      "Epoch 1123/5000\n",
      "2252/2252 [==============================] - 1s 598us/step - loss: 0.0358 - acc: 0.9069 - val_loss: 0.0896 - val_acc: 0.7588\n",
      "Epoch 1124/5000\n",
      "2252/2252 [==============================] - 1s 597us/step - loss: 0.0363 - acc: 0.9064 - val_loss: 0.0908 - val_acc: 0.7551\n",
      "Epoch 1125/5000\n",
      "2252/2252 [==============================] - 1s 600us/step - loss: 0.0379 - acc: 0.9029 - val_loss: 0.0893 - val_acc: 0.7578\n",
      "Epoch 1126/5000\n",
      "2252/2252 [==============================] - 1s 587us/step - loss: 0.0365 - acc: 0.9050 - val_loss: 0.0874 - val_acc: 0.7618\n",
      "Epoch 1127/5000\n",
      "2252/2252 [==============================] - 1s 591us/step - loss: 0.0363 - acc: 0.9054 - val_loss: 0.0845 - val_acc: 0.7691\n",
      "Epoch 1128/5000\n",
      "2252/2252 [==============================] - 1s 591us/step - loss: 0.0403 - acc: 0.8945 - val_loss: 0.0853 - val_acc: 0.7667\n",
      "Epoch 1129/5000\n",
      "2252/2252 [==============================] - 1s 586us/step - loss: 0.0381 - acc: 0.8998 - val_loss: 0.0880 - val_acc: 0.7613\n",
      "Epoch 1130/5000\n",
      "2252/2252 [==============================] - 1s 587us/step - loss: 0.0369 - acc: 0.9052 - val_loss: 0.0851 - val_acc: 0.7704\n",
      "Epoch 1131/5000\n",
      "2252/2252 [==============================] - 1s 594us/step - loss: 0.0367 - acc: 0.9054 - val_loss: 0.0940 - val_acc: 0.7500\n",
      "Epoch 1132/5000\n",
      "2252/2252 [==============================] - 1s 586us/step - loss: 0.0362 - acc: 0.9084 - val_loss: 0.0871 - val_acc: 0.7633\n",
      "Epoch 1133/5000\n",
      "2252/2252 [==============================] - 1s 589us/step - loss: 0.0366 - acc: 0.9054 - val_loss: 0.0870 - val_acc: 0.7648\n",
      "Epoch 1134/5000\n",
      "2252/2252 [==============================] - 1s 583us/step - loss: 0.0363 - acc: 0.9063 - val_loss: 0.0893 - val_acc: 0.7561\n",
      "Epoch 1135/5000\n",
      "2252/2252 [==============================] - 1s 581us/step - loss: 0.0377 - acc: 0.9031 - val_loss: 0.0922 - val_acc: 0.7518\n",
      "Epoch 1136/5000\n",
      "2252/2252 [==============================] - 1s 601us/step - loss: 0.0368 - acc: 0.9061 - val_loss: 0.0875 - val_acc: 0.7631\n",
      "Epoch 1137/5000\n",
      "2252/2252 [==============================] - 1s 598us/step - loss: 0.0362 - acc: 0.9060 - val_loss: 0.0892 - val_acc: 0.7581\n",
      "Epoch 1138/5000\n",
      "2252/2252 [==============================] - 1s 573us/step - loss: 0.0358 - acc: 0.9077 - val_loss: 0.0867 - val_acc: 0.7657\n",
      "Epoch 1139/5000\n",
      "2252/2252 [==============================] - 1s 575us/step - loss: 0.0369 - acc: 0.9040 - val_loss: 0.0908 - val_acc: 0.7561\n",
      "Epoch 1140/5000\n",
      "2252/2252 [==============================] - 1s 577us/step - loss: 0.0366 - acc: 0.9055 - val_loss: 0.0895 - val_acc: 0.7592\n",
      "Epoch 1141/5000\n",
      "2252/2252 [==============================] - 1s 586us/step - loss: 0.0355 - acc: 0.9083 - val_loss: 0.0895 - val_acc: 0.7593\n",
      "Epoch 1142/5000\n",
      "2252/2252 [==============================] - 1s 598us/step - loss: 0.0360 - acc: 0.9080 - val_loss: 0.0936 - val_acc: 0.7526\n",
      "Epoch 1143/5000\n",
      "2252/2252 [==============================] - 1s 581us/step - loss: 0.0369 - acc: 0.9044 - val_loss: 0.0890 - val_acc: 0.7589\n",
      "Epoch 1144/5000\n",
      "2252/2252 [==============================] - 1s 595us/step - loss: 0.0369 - acc: 0.9039 - val_loss: 0.0898 - val_acc: 0.7570\n",
      "Epoch 1145/5000\n",
      "2252/2252 [==============================] - 1s 595us/step - loss: 0.0362 - acc: 0.9073 - val_loss: 0.0899 - val_acc: 0.7577\n",
      "Epoch 1146/5000\n",
      "2252/2252 [==============================] - 1s 602us/step - loss: 0.0353 - acc: 0.9099 - val_loss: 0.0914 - val_acc: 0.7554\n",
      "Epoch 1147/5000\n",
      "2252/2252 [==============================] - 1s 591us/step - loss: 0.0377 - acc: 0.9033 - val_loss: 0.0938 - val_acc: 0.7480\n",
      "Epoch 1148/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.0368 - acc: 0.9053 - val_loss: 0.0885 - val_acc: 0.7619\n",
      "Epoch 1149/5000\n",
      "2252/2252 [==============================] - 1s 596us/step - loss: 0.0358 - acc: 0.9078 - val_loss: 0.0866 - val_acc: 0.7679\n",
      "Epoch 1150/5000\n",
      "2252/2252 [==============================] - 1s 607us/step - loss: 0.0355 - acc: 0.9101 - val_loss: 0.0897 - val_acc: 0.7600\n",
      "Epoch 1151/5000\n",
      "2252/2252 [==============================] - 1s 595us/step - loss: 0.0355 - acc: 0.9096 - val_loss: 0.0890 - val_acc: 0.7580\n",
      "Epoch 1152/5000\n",
      "2252/2252 [==============================] - 1s 599us/step - loss: 0.0368 - acc: 0.9048 - val_loss: 0.0867 - val_acc: 0.7665\n",
      "Epoch 1153/5000\n",
      "2252/2252 [==============================] - 1s 597us/step - loss: 0.0370 - acc: 0.9040 - val_loss: 0.0855 - val_acc: 0.7676\n",
      "Epoch 1154/5000\n",
      "2252/2252 [==============================] - 1s 599us/step - loss: 0.0355 - acc: 0.9090 - val_loss: 0.0864 - val_acc: 0.7665\n",
      "Epoch 1155/5000\n",
      "2252/2252 [==============================] - 1s 587us/step - loss: 0.0358 - acc: 0.9083 - val_loss: 0.0852 - val_acc: 0.7698\n",
      "Epoch 1156/5000\n",
      "2252/2252 [==============================] - 1s 600us/step - loss: 0.0363 - acc: 0.9052 - val_loss: 0.0933 - val_acc: 0.7522\n",
      "Epoch 1157/5000\n",
      "2252/2252 [==============================] - 1s 584us/step - loss: 0.0365 - acc: 0.9053 - val_loss: 0.0908 - val_acc: 0.7552\n",
      "Epoch 1158/5000\n",
      "2252/2252 [==============================] - 1s 596us/step - loss: 0.0368 - acc: 0.9055 - val_loss: 0.0869 - val_acc: 0.7667\n",
      "Epoch 1159/5000\n",
      "2252/2252 [==============================] - 1s 589us/step - loss: 0.0360 - acc: 0.9077 - val_loss: 0.0894 - val_acc: 0.7635\n",
      "Epoch 1160/5000\n",
      "2252/2252 [==============================] - 1s 599us/step - loss: 0.0353 - acc: 0.9096 - val_loss: 0.0886 - val_acc: 0.7613\n",
      "Epoch 1161/5000\n",
      "2252/2252 [==============================] - 1s 602us/step - loss: 0.0358 - acc: 0.9072 - val_loss: 0.0898 - val_acc: 0.7610\n",
      "Epoch 1162/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2252/2252 [==============================] - 1s 597us/step - loss: 0.0359 - acc: 0.9076 - val_loss: 0.0844 - val_acc: 0.7710\n",
      "Epoch 1163/5000\n",
      "2252/2252 [==============================] - 1s 596us/step - loss: 0.0351 - acc: 0.9098 - val_loss: 0.0887 - val_acc: 0.7611\n",
      "Epoch 1164/5000\n",
      "2252/2252 [==============================] - 1s 592us/step - loss: 0.0376 - acc: 0.9033 - val_loss: 0.1023 - val_acc: 0.7298\n",
      "Epoch 1165/5000\n",
      "2252/2252 [==============================] - 1s 596us/step - loss: 0.0373 - acc: 0.9034 - val_loss: 0.0898 - val_acc: 0.7561\n",
      "Epoch 1166/5000\n",
      "2252/2252 [==============================] - 1s 586us/step - loss: 0.0353 - acc: 0.9087 - val_loss: 0.0872 - val_acc: 0.7648\n",
      "Epoch 1167/5000\n",
      "2252/2252 [==============================] - 1s 571us/step - loss: 0.0359 - acc: 0.9066 - val_loss: 0.0910 - val_acc: 0.7557\n",
      "Epoch 1168/5000\n",
      "2252/2252 [==============================] - 1s 591us/step - loss: 0.0358 - acc: 0.9086 - val_loss: 0.0896 - val_acc: 0.7570\n",
      "Epoch 1169/5000\n",
      "2252/2252 [==============================] - 1s 583us/step - loss: 0.0357 - acc: 0.9073 - val_loss: 0.0906 - val_acc: 0.7563\n",
      "Epoch 1170/5000\n",
      "2252/2252 [==============================] - 1s 591us/step - loss: 0.0352 - acc: 0.9106 - val_loss: 0.0930 - val_acc: 0.7508\n",
      "Epoch 1171/5000\n",
      "2252/2252 [==============================] - 1s 601us/step - loss: 0.0356 - acc: 0.9084 - val_loss: 0.0908 - val_acc: 0.7564\n",
      "Epoch 1172/5000\n",
      "2252/2252 [==============================] - 1s 599us/step - loss: 0.0367 - acc: 0.9054 - val_loss: 0.0932 - val_acc: 0.7537\n",
      "Epoch 1173/5000\n",
      "2252/2252 [==============================] - 1s 596us/step - loss: 0.0363 - acc: 0.9055 - val_loss: 0.0878 - val_acc: 0.7622\n",
      "Epoch 1174/5000\n",
      "2252/2252 [==============================] - 1s 603us/step - loss: 0.0365 - acc: 0.9075 - val_loss: 0.0897 - val_acc: 0.7561\n",
      "Epoch 1175/5000\n",
      "2252/2252 [==============================] - 1s 602us/step - loss: 0.0350 - acc: 0.9104 - val_loss: 0.0894 - val_acc: 0.7608\n",
      "Epoch 1176/5000\n",
      "2252/2252 [==============================] - 1s 596us/step - loss: 0.0343 - acc: 0.9119 - val_loss: 0.0880 - val_acc: 0.7626\n",
      "Epoch 1177/5000\n",
      "2252/2252 [==============================] - 1s 603us/step - loss: 0.0347 - acc: 0.9111 - val_loss: 0.0891 - val_acc: 0.7609\n",
      "Epoch 1178/5000\n",
      "2252/2252 [==============================] - 1s 601us/step - loss: 0.0353 - acc: 0.9103 - val_loss: 0.0867 - val_acc: 0.7666\n",
      "Epoch 1179/5000\n",
      "2252/2252 [==============================] - 1s 596us/step - loss: 0.0352 - acc: 0.9083 - val_loss: 0.0873 - val_acc: 0.7652\n",
      "Epoch 1180/5000\n",
      "2252/2252 [==============================] - 1s 592us/step - loss: 0.0356 - acc: 0.9098 - val_loss: 0.0907 - val_acc: 0.7577\n",
      "Epoch 1181/5000\n",
      "2252/2252 [==============================] - 1s 580us/step - loss: 0.0354 - acc: 0.9092 - val_loss: 0.0921 - val_acc: 0.7560\n",
      "Epoch 1182/5000\n",
      "2252/2252 [==============================] - 1s 600us/step - loss: 0.0362 - acc: 0.9068 - val_loss: 0.0883 - val_acc: 0.7614\n",
      "Epoch 1183/5000\n",
      "2252/2252 [==============================] - 1s 606us/step - loss: 0.0350 - acc: 0.9108 - val_loss: 0.0888 - val_acc: 0.7637\n",
      "Epoch 1184/5000\n",
      "2252/2252 [==============================] - 1s 597us/step - loss: 0.0354 - acc: 0.9103 - val_loss: 0.0861 - val_acc: 0.7670\n",
      "Epoch 1185/5000\n",
      "2252/2252 [==============================] - 1s 599us/step - loss: 0.0378 - acc: 0.9031 - val_loss: 0.0907 - val_acc: 0.7562\n",
      "Epoch 1186/5000\n",
      "2252/2252 [==============================] - 1s 600us/step - loss: 0.0360 - acc: 0.9069 - val_loss: 0.0904 - val_acc: 0.7575\n",
      "Epoch 1187/5000\n",
      "2252/2252 [==============================] - 1s 595us/step - loss: 0.0346 - acc: 0.9118 - val_loss: 0.0869 - val_acc: 0.7680\n",
      "Epoch 1188/5000\n",
      "2252/2252 [==============================] - 1s 581us/step - loss: 0.0343 - acc: 0.9132 - val_loss: 0.0882 - val_acc: 0.7628\n",
      "Epoch 1189/5000\n",
      "2252/2252 [==============================] - 1s 592us/step - loss: 0.0353 - acc: 0.9085 - val_loss: 0.0859 - val_acc: 0.7673\n",
      "Epoch 1190/5000\n",
      "2252/2252 [==============================] - 1s 592us/step - loss: 0.0356 - acc: 0.9074 - val_loss: 0.0888 - val_acc: 0.7609\n",
      "Epoch 1191/5000\n",
      "2252/2252 [==============================] - 1s 597us/step - loss: 0.0360 - acc: 0.9068 - val_loss: 0.0927 - val_acc: 0.7546\n",
      "Epoch 1192/5000\n",
      "2252/2252 [==============================] - 1s 589us/step - loss: 0.0352 - acc: 0.9086 - val_loss: 0.0875 - val_acc: 0.7661\n",
      "Epoch 1193/5000\n",
      "2252/2252 [==============================] - 1s 592us/step - loss: 0.0353 - acc: 0.9101 - val_loss: 0.0904 - val_acc: 0.7585\n",
      "Epoch 1194/5000\n",
      "2252/2252 [==============================] - 1s 596us/step - loss: 0.0371 - acc: 0.9044 - val_loss: 0.0862 - val_acc: 0.7674\n",
      "Epoch 1195/5000\n",
      "2252/2252 [==============================] - 1s 586us/step - loss: 0.0368 - acc: 0.9046 - val_loss: 0.0879 - val_acc: 0.7641\n",
      "Epoch 1196/5000\n",
      "2252/2252 [==============================] - 1s 591us/step - loss: 0.0355 - acc: 0.9084 - val_loss: 0.0863 - val_acc: 0.7665\n",
      "Epoch 1197/5000\n",
      "2252/2252 [==============================] - 1s 599us/step - loss: 0.0352 - acc: 0.9099 - val_loss: 0.0879 - val_acc: 0.7635\n",
      "Epoch 1198/5000\n",
      "2252/2252 [==============================] - 1s 595us/step - loss: 0.0347 - acc: 0.9108 - val_loss: 0.0869 - val_acc: 0.7648\n",
      "Epoch 1199/5000\n",
      "2252/2252 [==============================] - 1s 583us/step - loss: 0.0349 - acc: 0.9116 - val_loss: 0.0892 - val_acc: 0.7589\n",
      "Epoch 1200/5000\n",
      "2252/2252 [==============================] - 1s 591us/step - loss: 0.0340 - acc: 0.9145 - val_loss: 0.0927 - val_acc: 0.7523\n",
      "Epoch 1201/5000\n",
      "2252/2252 [==============================] - 1s 601us/step - loss: 0.0342 - acc: 0.9112 - val_loss: 0.0919 - val_acc: 0.7566\n",
      "Epoch 1202/5000\n",
      "2252/2252 [==============================] - 1s 596us/step - loss: 0.0362 - acc: 0.9080 - val_loss: 0.0883 - val_acc: 0.7624\n",
      "Epoch 1203/5000\n",
      "2252/2252 [==============================] - 1s 596us/step - loss: 0.0346 - acc: 0.9101 - val_loss: 0.0905 - val_acc: 0.7598\n",
      "Epoch 1204/5000\n",
      "2252/2252 [==============================] - 1s 579us/step - loss: 0.0352 - acc: 0.9092 - val_loss: 0.0862 - val_acc: 0.7668\n",
      "Epoch 1205/5000\n",
      "2252/2252 [==============================] - 1s 595us/step - loss: 0.0357 - acc: 0.9085 - val_loss: 0.0892 - val_acc: 0.7601\n",
      "Epoch 1206/5000\n",
      "2252/2252 [==============================] - 1s 587us/step - loss: 0.0345 - acc: 0.9119 - val_loss: 0.0876 - val_acc: 0.7675\n",
      "Epoch 1207/5000\n",
      "2252/2252 [==============================] - 1s 604us/step - loss: 0.0342 - acc: 0.9125 - val_loss: 0.0909 - val_acc: 0.7590\n",
      "Epoch 1208/5000\n",
      "2252/2252 [==============================] - 1s 585us/step - loss: 0.0345 - acc: 0.9114 - val_loss: 0.0872 - val_acc: 0.7659\n",
      "Epoch 1209/5000\n",
      "2252/2252 [==============================] - 1s 599us/step - loss: 0.0353 - acc: 0.9090 - val_loss: 0.0851 - val_acc: 0.7710\n",
      "Epoch 1210/5000\n",
      "2252/2252 [==============================] - 1s 592us/step - loss: 0.0370 - acc: 0.9046 - val_loss: 0.0905 - val_acc: 0.7600\n",
      "Epoch 1211/5000\n",
      "2252/2252 [==============================] - 1s 588us/step - loss: 0.0341 - acc: 0.9137 - val_loss: 0.0898 - val_acc: 0.7608\n",
      "Epoch 1212/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.0345 - acc: 0.9115 - val_loss: 0.0888 - val_acc: 0.7636\n",
      "Epoch 1213/5000\n",
      "2252/2252 [==============================] - 1s 598us/step - loss: 0.0344 - acc: 0.9119 - val_loss: 0.0886 - val_acc: 0.7609\n",
      "Epoch 1214/5000\n",
      "2252/2252 [==============================] - 1s 605us/step - loss: 0.0352 - acc: 0.9098 - val_loss: 0.0926 - val_acc: 0.7565\n",
      "Epoch 1215/5000\n",
      "2252/2252 [==============================] - 1s 587us/step - loss: 0.0344 - acc: 0.9133 - val_loss: 0.0863 - val_acc: 0.7694\n",
      "Epoch 1216/5000\n",
      "2252/2252 [==============================] - 1s 595us/step - loss: 0.0345 - acc: 0.9119 - val_loss: 0.0885 - val_acc: 0.7620\n",
      "Epoch 1217/5000\n",
      "2252/2252 [==============================] - 1s 605us/step - loss: 0.0339 - acc: 0.9139 - val_loss: 0.0901 - val_acc: 0.7603\n",
      "Epoch 1218/5000\n",
      "2252/2252 [==============================] - 1s 589us/step - loss: 0.0342 - acc: 0.9130 - val_loss: 0.0904 - val_acc: 0.7592\n",
      "Epoch 1219/5000\n",
      "2252/2252 [==============================] - 1s 596us/step - loss: 0.0346 - acc: 0.9110 - val_loss: 0.0888 - val_acc: 0.7627\n",
      "Epoch 1220/5000\n",
      "2252/2252 [==============================] - 1s 582us/step - loss: 0.0349 - acc: 0.9103 - val_loss: 0.0910 - val_acc: 0.7582\n",
      "Epoch 1221/5000\n",
      "2252/2252 [==============================] - 1s 591us/step - loss: 0.0340 - acc: 0.9135 - val_loss: 0.0891 - val_acc: 0.7636\n",
      "Epoch 1222/5000\n",
      "2252/2252 [==============================] - 1s 592us/step - loss: 0.0339 - acc: 0.9130 - val_loss: 0.0884 - val_acc: 0.7652\n",
      "Epoch 1223/5000\n",
      "2252/2252 [==============================] - 1s 587us/step - loss: 0.0340 - acc: 0.9129 - val_loss: 0.0889 - val_acc: 0.7625\n",
      "Epoch 1224/5000\n",
      "2252/2252 [==============================] - 1s 583us/step - loss: 0.0344 - acc: 0.9116 - val_loss: 0.0900 - val_acc: 0.7583\n",
      "Epoch 1225/5000\n",
      "2252/2252 [==============================] - 1s 589us/step - loss: 0.0344 - acc: 0.9114 - val_loss: 0.0895 - val_acc: 0.7625\n",
      "Epoch 1226/5000\n",
      "2252/2252 [==============================] - 1s 588us/step - loss: 0.0349 - acc: 0.9106 - val_loss: 0.0914 - val_acc: 0.7547\n",
      "Epoch 1227/5000\n",
      "2252/2252 [==============================] - 1s 606us/step - loss: 0.0334 - acc: 0.9163 - val_loss: 0.0901 - val_acc: 0.7600\n",
      "Epoch 1228/5000\n",
      "2252/2252 [==============================] - 1s 601us/step - loss: 0.0330 - acc: 0.9170 - val_loss: 0.0900 - val_acc: 0.7593\n",
      "Epoch 1229/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.0345 - acc: 0.9110 - val_loss: 0.0872 - val_acc: 0.7680\n",
      "Epoch 1230/5000\n",
      "2252/2252 [==============================] - 1s 583us/step - loss: 0.0343 - acc: 0.9115 - val_loss: 0.0947 - val_acc: 0.7524\n",
      "Epoch 1231/5000\n",
      "2252/2252 [==============================] - 1s 596us/step - loss: 0.0351 - acc: 0.9107 - val_loss: 0.0891 - val_acc: 0.7615\n",
      "Epoch 1232/5000\n",
      "2252/2252 [==============================] - 1s 594us/step - loss: 0.0354 - acc: 0.9094 - val_loss: 0.0901 - val_acc: 0.7599\n",
      "Epoch 1233/5000\n",
      "2252/2252 [==============================] - 1s 595us/step - loss: 0.0342 - acc: 0.9134 - val_loss: 0.0890 - val_acc: 0.7619\n",
      "Epoch 1234/5000\n",
      "2252/2252 [==============================] - 1s 597us/step - loss: 0.0349 - acc: 0.9089 - val_loss: 0.0864 - val_acc: 0.7675\n",
      "Epoch 1235/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.0355 - acc: 0.9091 - val_loss: 0.0885 - val_acc: 0.7667\n",
      "Epoch 1236/5000\n",
      "2252/2252 [==============================] - 1s 597us/step - loss: 0.0374 - acc: 0.9021 - val_loss: 0.0872 - val_acc: 0.7669\n",
      "Epoch 1237/5000\n",
      "2252/2252 [==============================] - 1s 594us/step - loss: 0.0355 - acc: 0.9077 - val_loss: 0.0910 - val_acc: 0.7573\n",
      "Epoch 1238/5000\n",
      "2252/2252 [==============================] - 1s 581us/step - loss: 0.0339 - acc: 0.9139 - val_loss: 0.0943 - val_acc: 0.7525\n",
      "Epoch 1239/5000\n",
      "2252/2252 [==============================] - 1s 597us/step - loss: 0.0348 - acc: 0.9103 - val_loss: 0.0873 - val_acc: 0.7687\n",
      "Epoch 1240/5000\n",
      "2252/2252 [==============================] - 1s 603us/step - loss: 0.0343 - acc: 0.9136 - val_loss: 0.0899 - val_acc: 0.7618\n",
      "Epoch 1241/5000\n",
      "2252/2252 [==============================] - 1s 592us/step - loss: 0.0333 - acc: 0.9158 - val_loss: 0.0896 - val_acc: 0.7602\n",
      "Epoch 1242/5000\n",
      "2252/2252 [==============================] - 1s 582us/step - loss: 0.0342 - acc: 0.9120 - val_loss: 0.0880 - val_acc: 0.7661\n",
      "Epoch 1243/5000\n",
      "2252/2252 [==============================] - 1s 592us/step - loss: 0.0341 - acc: 0.9127 - val_loss: 0.0917 - val_acc: 0.7582\n",
      "Epoch 1244/5000\n",
      "2252/2252 [==============================] - 1s 589us/step - loss: 0.0348 - acc: 0.9103 - val_loss: 0.0925 - val_acc: 0.7550\n",
      "Epoch 1245/5000\n",
      "2252/2252 [==============================] - 1s 586us/step - loss: 0.0350 - acc: 0.9110 - val_loss: 0.0876 - val_acc: 0.7656\n",
      "Epoch 1246/5000\n",
      "2252/2252 [==============================] - 1s 597us/step - loss: 0.0351 - acc: 0.9092 - val_loss: 0.0886 - val_acc: 0.7644\n",
      "Epoch 1247/5000\n",
      "2252/2252 [==============================] - 1s 594us/step - loss: 0.0336 - acc: 0.9142 - val_loss: 0.0887 - val_acc: 0.7660\n",
      "Epoch 1248/5000\n",
      "2252/2252 [==============================] - 1s 595us/step - loss: 0.0364 - acc: 0.9061 - val_loss: 0.0938 - val_acc: 0.7515\n",
      "Epoch 1249/5000\n",
      "2252/2252 [==============================] - 1s 588us/step - loss: 0.0352 - acc: 0.9094 - val_loss: 0.0900 - val_acc: 0.7601\n",
      "Epoch 1250/5000\n",
      "2252/2252 [==============================] - 1s 584us/step - loss: 0.0343 - acc: 0.9124 - val_loss: 0.0894 - val_acc: 0.7584\n",
      "Epoch 1251/5000\n",
      "2252/2252 [==============================] - 1s 589us/step - loss: 0.0336 - acc: 0.9146 - val_loss: 0.0864 - val_acc: 0.7691\n",
      "Epoch 1252/5000\n",
      "2252/2252 [==============================] - 1s 597us/step - loss: 0.0357 - acc: 0.9100 - val_loss: 0.0867 - val_acc: 0.7702\n",
      "Epoch 1253/5000\n",
      "2252/2252 [==============================] - 1s 589us/step - loss: 0.0348 - acc: 0.9114 - val_loss: 0.0901 - val_acc: 0.7623\n",
      "Epoch 1254/5000\n",
      "2252/2252 [==============================] - 1s 582us/step - loss: 0.0344 - acc: 0.9121 - val_loss: 0.0926 - val_acc: 0.7558\n",
      "Epoch 1255/5000\n",
      "2252/2252 [==============================] - 1s 594us/step - loss: 0.0341 - acc: 0.9127 - val_loss: 0.0886 - val_acc: 0.7648\n",
      "Epoch 1256/5000\n",
      "2252/2252 [==============================] - 1s 595us/step - loss: 0.0354 - acc: 0.9082 - val_loss: 0.0861 - val_acc: 0.7713\n",
      "Epoch 1257/5000\n",
      "2252/2252 [==============================] - 1s 589us/step - loss: 0.0367 - acc: 0.9047 - val_loss: 0.0910 - val_acc: 0.7598\n",
      "Epoch 1258/5000\n",
      "2252/2252 [==============================] - 1s 596us/step - loss: 0.0334 - acc: 0.9150 - val_loss: 0.0875 - val_acc: 0.7670\n",
      "Epoch 1259/5000\n",
      "2252/2252 [==============================] - 1s 590us/step - loss: 0.0331 - acc: 0.9157 - val_loss: 0.0874 - val_acc: 0.7656\n",
      "Epoch 1260/5000\n",
      "2252/2252 [==============================] - 1s 592us/step - loss: 0.0340 - acc: 0.9121 - val_loss: 0.0905 - val_acc: 0.7596\n",
      "Epoch 1261/5000\n",
      "2252/2252 [==============================] - 1s 585us/step - loss: 0.0350 - acc: 0.9109 - val_loss: 0.0860 - val_acc: 0.7689\n",
      "Epoch 1262/5000\n",
      "2252/2252 [==============================] - 1s 595us/step - loss: 0.0326 - acc: 0.9190 - val_loss: 0.0912 - val_acc: 0.7610\n",
      "Epoch 1263/5000\n",
      "2252/2252 [==============================] - 1s 586us/step - loss: 0.0346 - acc: 0.9113 - val_loss: 0.0895 - val_acc: 0.7598\n",
      "Epoch 1264/5000\n",
      "2252/2252 [==============================] - 1s 594us/step - loss: 0.0354 - acc: 0.9091 - val_loss: 0.0878 - val_acc: 0.7656\n",
      "Epoch 1265/5000\n",
      "2252/2252 [==============================] - 1s 576us/step - loss: 0.0324 - acc: 0.9174 - val_loss: 0.0939 - val_acc: 0.7545\n",
      "Epoch 1266/5000\n",
      "2252/2252 [==============================] - 1s 592us/step - loss: 0.0342 - acc: 0.9137 - val_loss: 0.0907 - val_acc: 0.7619\n",
      "Epoch 1267/5000\n",
      "2252/2252 [==============================] - 1s 597us/step - loss: 0.0342 - acc: 0.9124 - val_loss: 0.0876 - val_acc: 0.7675\n",
      "Epoch 1268/5000\n",
      "2252/2252 [==============================] - 1s 586us/step - loss: 0.0344 - acc: 0.9128 - val_loss: 0.0865 - val_acc: 0.7689\n",
      "Epoch 1269/5000\n",
      "2252/2252 [==============================] - 1s 598us/step - loss: 0.0383 - acc: 0.8995 - val_loss: 0.0873 - val_acc: 0.7656\n",
      "Epoch 1270/5000\n",
      "2252/2252 [==============================] - 1s 607us/step - loss: 0.0335 - acc: 0.9147 - val_loss: 0.0895 - val_acc: 0.7620\n",
      "Epoch 1271/5000\n",
      "2252/2252 [==============================] - 1s 590us/step - loss: 0.0338 - acc: 0.9139 - val_loss: 0.0858 - val_acc: 0.7706\n",
      "Epoch 1272/5000\n",
      "2252/2252 [==============================] - 1s 594us/step - loss: 0.0338 - acc: 0.9145 - val_loss: 0.0911 - val_acc: 0.7599\n",
      "Epoch 1273/5000\n",
      "2252/2252 [==============================] - 1s 595us/step - loss: 0.0346 - acc: 0.9127 - val_loss: 0.0903 - val_acc: 0.7588\n",
      "Epoch 1274/5000\n",
      "2252/2252 [==============================] - 1s 597us/step - loss: 0.0341 - acc: 0.9134 - val_loss: 0.0882 - val_acc: 0.7665\n",
      "Epoch 1275/5000\n",
      "2252/2252 [==============================] - 1s 572us/step - loss: 0.0333 - acc: 0.9159 - val_loss: 0.0863 - val_acc: 0.7693\n",
      "Epoch 1276/5000\n",
      "2252/2252 [==============================] - 1s 594us/step - loss: 0.0332 - acc: 0.9138 - val_loss: 0.0896 - val_acc: 0.7622\n",
      "Epoch 1277/5000\n",
      "2252/2252 [==============================] - 1s 596us/step - loss: 0.0324 - acc: 0.9178 - val_loss: 0.0872 - val_acc: 0.7667\n",
      "Epoch 1278/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2252/2252 [==============================] - 1s 596us/step - loss: 0.0333 - acc: 0.9150 - val_loss: 0.0946 - val_acc: 0.7527\n",
      "Epoch 1279/5000\n",
      "2252/2252 [==============================] - 1s 596us/step - loss: 0.0355 - acc: 0.9089 - val_loss: 0.0878 - val_acc: 0.7673\n",
      "Epoch 1280/5000\n",
      "2252/2252 [==============================] - 1s 587us/step - loss: 0.0334 - acc: 0.9157 - val_loss: 0.0891 - val_acc: 0.7641\n",
      "Epoch 1281/5000\n",
      "2252/2252 [==============================] - 1s 591us/step - loss: 0.0339 - acc: 0.9136 - val_loss: 0.0883 - val_acc: 0.7664\n",
      "Epoch 1282/5000\n",
      "2252/2252 [==============================] - 1s 592us/step - loss: 0.0339 - acc: 0.9139 - val_loss: 0.0889 - val_acc: 0.7620\n",
      "Epoch 1283/5000\n",
      "2252/2252 [==============================] - 1s 592us/step - loss: 0.0327 - acc: 0.9170 - val_loss: 0.0893 - val_acc: 0.7626\n",
      "Epoch 1284/5000\n",
      "2252/2252 [==============================] - 1s 596us/step - loss: 0.0328 - acc: 0.9165 - val_loss: 0.0872 - val_acc: 0.7682\n",
      "Epoch 1285/5000\n",
      "2252/2252 [==============================] - 1s 590us/step - loss: 0.0328 - acc: 0.9167 - val_loss: 0.0902 - val_acc: 0.7604\n",
      "Epoch 1286/5000\n",
      "2252/2252 [==============================] - 1s 584us/step - loss: 0.0323 - acc: 0.9195 - val_loss: 0.0887 - val_acc: 0.7639\n",
      "Epoch 1287/5000\n",
      "2252/2252 [==============================] - 1s 603us/step - loss: 0.0329 - acc: 0.9165 - val_loss: 0.0957 - val_acc: 0.7537\n",
      "Epoch 1288/5000\n",
      "2252/2252 [==============================] - 1s 596us/step - loss: 0.0339 - acc: 0.9135 - val_loss: 0.0898 - val_acc: 0.7607\n",
      "Epoch 1289/5000\n",
      "2252/2252 [==============================] - 1s 580us/step - loss: 0.0327 - acc: 0.9163 - val_loss: 0.0922 - val_acc: 0.7577\n",
      "Epoch 1290/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.0328 - acc: 0.9161 - val_loss: 0.0894 - val_acc: 0.7625\n",
      "Epoch 1291/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.0326 - acc: 0.9183 - val_loss: 0.0867 - val_acc: 0.7696\n",
      "Epoch 1292/5000\n",
      "2252/2252 [==============================] - 1s 592us/step - loss: 0.0334 - acc: 0.9138 - val_loss: 0.0887 - val_acc: 0.7648\n",
      "Epoch 1293/5000\n",
      "2252/2252 [==============================] - 1s 585us/step - loss: 0.0326 - acc: 0.9169 - val_loss: 0.0892 - val_acc: 0.7634\n",
      "Epoch 1294/5000\n",
      "2252/2252 [==============================] - 1s 585us/step - loss: 0.0324 - acc: 0.9189 - val_loss: 0.0862 - val_acc: 0.7715\n",
      "Epoch 1295/5000\n",
      "2252/2252 [==============================] - 1s 596us/step - loss: 0.0331 - acc: 0.9155 - val_loss: 0.0866 - val_acc: 0.7688\n",
      "Epoch 1296/5000\n",
      "2252/2252 [==============================] - 1s 595us/step - loss: 0.0336 - acc: 0.9143 - val_loss: 0.0876 - val_acc: 0.7662\n",
      "Epoch 1297/5000\n",
      "2252/2252 [==============================] - 1s 587us/step - loss: 0.0330 - acc: 0.9155 - val_loss: 0.0884 - val_acc: 0.7646\n",
      "Epoch 1298/5000\n",
      "2252/2252 [==============================] - 1s 588us/step - loss: 0.0323 - acc: 0.9183 - val_loss: 0.0861 - val_acc: 0.7706\n",
      "Epoch 1299/5000\n",
      "2252/2252 [==============================] - 1s 601us/step - loss: 0.0324 - acc: 0.9185 - val_loss: 0.0874 - val_acc: 0.7667\n",
      "Epoch 1300/5000\n",
      "2252/2252 [==============================] - 1s 596us/step - loss: 0.0331 - acc: 0.9165 - val_loss: 0.0905 - val_acc: 0.7614\n",
      "Epoch 1301/5000\n",
      "2252/2252 [==============================] - 1s 580us/step - loss: 0.0339 - acc: 0.9112 - val_loss: 0.0934 - val_acc: 0.7560\n",
      "Epoch 1302/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.0331 - acc: 0.9148 - val_loss: 0.0889 - val_acc: 0.7666\n",
      "Epoch 1303/5000\n",
      "2252/2252 [==============================] - 1s 592us/step - loss: 0.0328 - acc: 0.9164 - val_loss: 0.0891 - val_acc: 0.7656\n",
      "Epoch 1304/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.0326 - acc: 0.9175 - val_loss: 0.0883 - val_acc: 0.7649\n",
      "Epoch 1305/5000\n",
      "2252/2252 [==============================] - 1s 592us/step - loss: 0.0330 - acc: 0.9155 - val_loss: 0.0918 - val_acc: 0.7564\n",
      "Epoch 1306/5000\n",
      "2252/2252 [==============================] - 1s 587us/step - loss: 0.0339 - acc: 0.9134 - val_loss: 0.0924 - val_acc: 0.7582\n",
      "Epoch 1307/5000\n",
      "2252/2252 [==============================] - 1s 581us/step - loss: 0.0327 - acc: 0.9175 - val_loss: 0.0871 - val_acc: 0.7680\n",
      "Epoch 1308/5000\n",
      "2252/2252 [==============================] - 1s 599us/step - loss: 0.0324 - acc: 0.9170 - val_loss: 0.0884 - val_acc: 0.7678\n",
      "Epoch 1309/5000\n",
      "2252/2252 [==============================] - 1s 586us/step - loss: 0.0321 - acc: 0.9191 - val_loss: 0.0891 - val_acc: 0.7641\n",
      "Epoch 1310/5000\n",
      "2252/2252 [==============================] - 1s 598us/step - loss: 0.0320 - acc: 0.9191 - val_loss: 0.0917 - val_acc: 0.7588\n",
      "Epoch 1311/5000\n",
      "2252/2252 [==============================] - 1s 584us/step - loss: 0.0328 - acc: 0.9163 - val_loss: 0.0910 - val_acc: 0.7620\n",
      "Epoch 1312/5000\n",
      "2252/2252 [==============================] - 1s 590us/step - loss: 0.0319 - acc: 0.9195 - val_loss: 0.0906 - val_acc: 0.7602\n",
      "Epoch 1313/5000\n",
      "2252/2252 [==============================] - 1s 588us/step - loss: 0.0322 - acc: 0.9182 - val_loss: 0.0910 - val_acc: 0.7589\n",
      "Epoch 1314/5000\n",
      "2252/2252 [==============================] - 1s 595us/step - loss: 0.0329 - acc: 0.9165 - val_loss: 0.0871 - val_acc: 0.7679\n",
      "Epoch 1315/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.0336 - acc: 0.9132 - val_loss: 0.0910 - val_acc: 0.7578\n",
      "Epoch 1316/5000\n",
      "2252/2252 [==============================] - 1s 607us/step - loss: 0.0327 - acc: 0.9171 - val_loss: 0.0884 - val_acc: 0.7655\n",
      "Epoch 1317/5000\n",
      "2252/2252 [==============================] - 1s 586us/step - loss: 0.0340 - acc: 0.9140 - val_loss: 0.0866 - val_acc: 0.7699\n",
      "Epoch 1318/5000\n",
      "2252/2252 [==============================] - 1s 592us/step - loss: 0.0332 - acc: 0.9161 - val_loss: 0.0893 - val_acc: 0.7654\n",
      "Epoch 1319/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.0352 - acc: 0.9092 - val_loss: 0.0930 - val_acc: 0.7563\n",
      "Epoch 1320/5000\n",
      "2252/2252 [==============================] - 1s 598us/step - loss: 0.0344 - acc: 0.9115 - val_loss: 0.0916 - val_acc: 0.7614\n",
      "Epoch 1321/5000\n",
      "2252/2252 [==============================] - 1s 597us/step - loss: 0.0340 - acc: 0.9134 - val_loss: 0.0886 - val_acc: 0.7643\n",
      "Epoch 1322/5000\n",
      "2252/2252 [==============================] - 1s 599us/step - loss: 0.0315 - acc: 0.9200 - val_loss: 0.0871 - val_acc: 0.7700\n",
      "Epoch 1323/5000\n",
      "2252/2252 [==============================] - 1s 595us/step - loss: 0.0328 - acc: 0.9148 - val_loss: 0.0971 - val_acc: 0.7485\n",
      "Epoch 1324/5000\n",
      "2252/2252 [==============================] - 1s 604us/step - loss: 0.0330 - acc: 0.9148 - val_loss: 0.0896 - val_acc: 0.7642\n",
      "Epoch 1325/5000\n",
      "2252/2252 [==============================] - 1s 588us/step - loss: 0.0320 - acc: 0.9195 - val_loss: 0.0895 - val_acc: 0.7650\n",
      "Epoch 1326/5000\n",
      "2252/2252 [==============================] - 1s 590us/step - loss: 0.0321 - acc: 0.9183 - val_loss: 0.0875 - val_acc: 0.7689\n",
      "Epoch 1327/5000\n",
      "2252/2252 [==============================] - 1s 588us/step - loss: 0.0323 - acc: 0.9182 - val_loss: 0.0913 - val_acc: 0.7603\n",
      "Epoch 1328/5000\n",
      "2252/2252 [==============================] - 1s 590us/step - loss: 0.0319 - acc: 0.9190 - val_loss: 0.0957 - val_acc: 0.7519\n",
      "Epoch 1329/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.0345 - acc: 0.9116 - val_loss: 0.0885 - val_acc: 0.7637\n",
      "Epoch 1330/5000\n",
      "2252/2252 [==============================] - 1s 587us/step - loss: 0.0323 - acc: 0.9188 - val_loss: 0.0877 - val_acc: 0.7665\n",
      "Epoch 1331/5000\n",
      "2252/2252 [==============================] - 1s 594us/step - loss: 0.0328 - acc: 0.9158 - val_loss: 0.0935 - val_acc: 0.7545\n",
      "Epoch 1332/5000\n",
      "2252/2252 [==============================] - 1s 591us/step - loss: 0.0325 - acc: 0.9171 - val_loss: 0.0912 - val_acc: 0.7622\n",
      "Epoch 1333/5000\n",
      "2252/2252 [==============================] - 1s 598us/step - loss: 0.0327 - acc: 0.9179 - val_loss: 0.0883 - val_acc: 0.7660\n",
      "Epoch 1334/5000\n",
      "2252/2252 [==============================] - 1s 588us/step - loss: 0.0321 - acc: 0.9191 - val_loss: 0.0898 - val_acc: 0.7632\n",
      "Epoch 1335/5000\n",
      "2252/2252 [==============================] - 1s 595us/step - loss: 0.0330 - acc: 0.9152 - val_loss: 0.0914 - val_acc: 0.7591\n",
      "Epoch 1336/5000\n",
      "2252/2252 [==============================] - 1s 595us/step - loss: 0.0332 - acc: 0.9157 - val_loss: 0.0967 - val_acc: 0.7514\n",
      "Epoch 1337/5000\n",
      "2252/2252 [==============================] - 1s 598us/step - loss: 0.0333 - acc: 0.9151 - val_loss: 0.0929 - val_acc: 0.7592\n",
      "Epoch 1338/5000\n",
      "2252/2252 [==============================] - 1s 600us/step - loss: 0.0328 - acc: 0.9163 - val_loss: 0.0880 - val_acc: 0.7674\n",
      "Epoch 1339/5000\n",
      "2252/2252 [==============================] - 1s 602us/step - loss: 0.0314 - acc: 0.9207 - val_loss: 0.0881 - val_acc: 0.7659\n",
      "Epoch 1340/5000\n",
      "2252/2252 [==============================] - 1s 591us/step - loss: 0.0323 - acc: 0.9187 - val_loss: 0.0938 - val_acc: 0.7568\n",
      "Epoch 1341/5000\n",
      "2252/2252 [==============================] - 1s 585us/step - loss: 0.0331 - acc: 0.9162 - val_loss: 0.0872 - val_acc: 0.7713\n",
      "Epoch 1342/5000\n",
      "2252/2252 [==============================] - 1s 580us/step - loss: 0.0324 - acc: 0.9168 - val_loss: 0.0888 - val_acc: 0.7667\n",
      "Epoch 1343/5000\n",
      "2252/2252 [==============================] - 1s 583us/step - loss: 0.0321 - acc: 0.9185 - val_loss: 0.0901 - val_acc: 0.7610\n",
      "Epoch 1344/5000\n",
      "2252/2252 [==============================] - 1s 581us/step - loss: 0.0337 - acc: 0.9131 - val_loss: 0.0937 - val_acc: 0.7561\n",
      "Epoch 1345/5000\n",
      "2252/2252 [==============================] - 1s 586us/step - loss: 0.0320 - acc: 0.9203 - val_loss: 0.0926 - val_acc: 0.7579\n",
      "Epoch 1346/5000\n",
      "2252/2252 [==============================] - 1s 584us/step - loss: 0.0318 - acc: 0.9200 - val_loss: 0.0935 - val_acc: 0.7562\n",
      "Epoch 1347/5000\n",
      "2252/2252 [==============================] - 1s 590us/step - loss: 0.0319 - acc: 0.9181 - val_loss: 0.0899 - val_acc: 0.7651\n",
      "Epoch 1348/5000\n",
      "2252/2252 [==============================] - 1s 605us/step - loss: 0.0319 - acc: 0.9204 - val_loss: 0.0888 - val_acc: 0.7646\n",
      "Epoch 1349/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.0314 - acc: 0.9203 - val_loss: 0.0906 - val_acc: 0.7620\n",
      "Epoch 1350/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.0314 - acc: 0.9203 - val_loss: 0.0883 - val_acc: 0.7661\n",
      "Epoch 1351/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.0325 - acc: 0.9167 - val_loss: 0.0875 - val_acc: 0.7676\n",
      "Epoch 1352/5000\n",
      "2252/2252 [==============================] - 1s 602us/step - loss: 0.0317 - acc: 0.9200 - val_loss: 0.0890 - val_acc: 0.7632\n",
      "Epoch 1353/5000\n",
      "2252/2252 [==============================] - 1s 590us/step - loss: 0.0328 - acc: 0.9164 - val_loss: 0.0935 - val_acc: 0.7545\n",
      "Epoch 1354/5000\n",
      "2252/2252 [==============================] - 1s 596us/step - loss: 0.0334 - acc: 0.9145 - val_loss: 0.0879 - val_acc: 0.7656\n",
      "Epoch 1355/5000\n",
      "2252/2252 [==============================] - 1s 588us/step - loss: 0.0315 - acc: 0.9194 - val_loss: 0.0933 - val_acc: 0.7554\n",
      "Epoch 1356/5000\n",
      "2252/2252 [==============================] - 1s 597us/step - loss: 0.0321 - acc: 0.9185 - val_loss: 0.0925 - val_acc: 0.7597\n",
      "Epoch 1357/5000\n",
      "2252/2252 [==============================] - 1s 587us/step - loss: 0.0333 - acc: 0.9147 - val_loss: 0.0900 - val_acc: 0.7626\n",
      "Epoch 1358/5000\n",
      "2252/2252 [==============================] - 1s 594us/step - loss: 0.0319 - acc: 0.9197 - val_loss: 0.0879 - val_acc: 0.7659\n",
      "Epoch 1359/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.0323 - acc: 0.9191 - val_loss: 0.0954 - val_acc: 0.7530\n",
      "Epoch 1360/5000\n",
      "2252/2252 [==============================] - 1s 605us/step - loss: 0.0327 - acc: 0.9165 - val_loss: 0.0913 - val_acc: 0.7609\n",
      "Epoch 1361/5000\n",
      "2252/2252 [==============================] - 1s 599us/step - loss: 0.0330 - acc: 0.9171 - val_loss: 0.0905 - val_acc: 0.7628\n",
      "Epoch 1362/5000\n",
      "2252/2252 [==============================] - 1s 596us/step - loss: 0.0332 - acc: 0.9160 - val_loss: 0.0896 - val_acc: 0.7643\n",
      "Epoch 1363/5000\n",
      "2252/2252 [==============================] - 1s 592us/step - loss: 0.0315 - acc: 0.9199 - val_loss: 0.0914 - val_acc: 0.7594\n",
      "Epoch 1364/5000\n",
      "2252/2252 [==============================] - 1s 599us/step - loss: 0.0324 - acc: 0.9180 - val_loss: 0.0915 - val_acc: 0.7592\n",
      "Epoch 1365/5000\n",
      "2252/2252 [==============================] - 1s 597us/step - loss: 0.0322 - acc: 0.9177 - val_loss: 0.0885 - val_acc: 0.7659\n",
      "Epoch 1366/5000\n",
      "2252/2252 [==============================] - 1s 597us/step - loss: 0.0312 - acc: 0.9202 - val_loss: 0.0877 - val_acc: 0.7701\n",
      "Epoch 1367/5000\n",
      "2252/2252 [==============================] - 1s 587us/step - loss: 0.0317 - acc: 0.9199 - val_loss: 0.0904 - val_acc: 0.7634\n",
      "Epoch 1368/5000\n",
      "2252/2252 [==============================] - 1s 592us/step - loss: 0.0316 - acc: 0.9195 - val_loss: 0.0887 - val_acc: 0.7670\n",
      "Epoch 1369/5000\n",
      "2252/2252 [==============================] - 1s 605us/step - loss: 0.0309 - acc: 0.9220 - val_loss: 0.0885 - val_acc: 0.7658\n",
      "Epoch 1370/5000\n",
      "2252/2252 [==============================] - 1s 592us/step - loss: 0.0321 - acc: 0.9196 - val_loss: 0.0973 - val_acc: 0.7529\n",
      "Epoch 1371/5000\n",
      "2252/2252 [==============================] - 1s 607us/step - loss: 0.0319 - acc: 0.9187 - val_loss: 0.0941 - val_acc: 0.7556\n",
      "Epoch 1372/5000\n",
      "2252/2252 [==============================] - 1s 594us/step - loss: 0.0324 - acc: 0.9176 - val_loss: 0.0917 - val_acc: 0.7592\n",
      "Epoch 1373/5000\n",
      "2252/2252 [==============================] - 1s 590us/step - loss: 0.0322 - acc: 0.9182 - val_loss: 0.0904 - val_acc: 0.7615\n",
      "Epoch 1374/5000\n",
      "2252/2252 [==============================] - 1s 575us/step - loss: 0.0327 - acc: 0.9162 - val_loss: 0.0916 - val_acc: 0.7610\n",
      "Epoch 1375/5000\n",
      "2252/2252 [==============================] - 1s 590us/step - loss: 0.0319 - acc: 0.9189 - val_loss: 0.0890 - val_acc: 0.7659\n",
      "Epoch 1376/5000\n",
      "2252/2252 [==============================] - 1s 600us/step - loss: 0.0311 - acc: 0.9216 - val_loss: 0.0955 - val_acc: 0.7539\n",
      "Epoch 1377/5000\n",
      "2252/2252 [==============================] - 1s 584us/step - loss: 0.0321 - acc: 0.9189 - val_loss: 0.0888 - val_acc: 0.7656\n",
      "Epoch 1378/5000\n",
      "2252/2252 [==============================] - 1s 597us/step - loss: 0.0313 - acc: 0.9218 - val_loss: 0.0951 - val_acc: 0.7542\n",
      "Epoch 1379/5000\n",
      "2252/2252 [==============================] - 1s 595us/step - loss: 0.0322 - acc: 0.9182 - val_loss: 0.0958 - val_acc: 0.7515\n",
      "Epoch 1380/5000\n",
      "2252/2252 [==============================] - 1s 589us/step - loss: 0.0331 - acc: 0.9152 - val_loss: 0.0896 - val_acc: 0.7635\n",
      "Epoch 1381/5000\n",
      "2252/2252 [==============================] - 1s 584us/step - loss: 0.0314 - acc: 0.9205 - val_loss: 0.0947 - val_acc: 0.7531\n",
      "Epoch 1382/5000\n",
      "2252/2252 [==============================] - 1s 582us/step - loss: 0.0320 - acc: 0.9194 - val_loss: 0.0887 - val_acc: 0.7677\n",
      "Epoch 1383/5000\n",
      "2252/2252 [==============================] - 1s 590us/step - loss: 0.0313 - acc: 0.9212 - val_loss: 0.0899 - val_acc: 0.7617\n",
      "Epoch 1384/5000\n",
      "2252/2252 [==============================] - 1s 599us/step - loss: 0.0314 - acc: 0.9207 - val_loss: 0.0917 - val_acc: 0.7592\n",
      "Epoch 1385/5000\n",
      "2252/2252 [==============================] - 1s 567us/step - loss: 0.0307 - acc: 0.9226 - val_loss: 0.0937 - val_acc: 0.7559\n",
      "Epoch 1386/5000\n",
      "2252/2252 [==============================] - 1s 580us/step - loss: 0.0333 - acc: 0.9149 - val_loss: 0.0896 - val_acc: 0.7623\n",
      "Epoch 1387/5000\n",
      "2252/2252 [==============================] - 1s 596us/step - loss: 0.0322 - acc: 0.9176 - val_loss: 0.0982 - val_acc: 0.7482\n",
      "Epoch 1388/5000\n",
      "2252/2252 [==============================] - 1s 602us/step - loss: 0.0322 - acc: 0.9187 - val_loss: 0.0928 - val_acc: 0.7589\n",
      "Epoch 1389/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.0310 - acc: 0.9219 - val_loss: 0.0896 - val_acc: 0.7642\n",
      "Epoch 1390/5000\n",
      "2252/2252 [==============================] - 1s 582us/step - loss: 0.0323 - acc: 0.9167 - val_loss: 0.0884 - val_acc: 0.7694\n",
      "Epoch 1391/5000\n",
      "2252/2252 [==============================] - 1s 583us/step - loss: 0.0333 - acc: 0.9148 - val_loss: 0.0987 - val_acc: 0.7478\n",
      "Epoch 1392/5000\n",
      "2252/2252 [==============================] - 1s 583us/step - loss: 0.0335 - acc: 0.9140 - val_loss: 0.0937 - val_acc: 0.7561\n",
      "Epoch 1393/5000\n",
      "2252/2252 [==============================] - 1s 605us/step - loss: 0.0320 - acc: 0.9188 - val_loss: 0.0891 - val_acc: 0.7645\n",
      "Epoch 1394/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2252/2252 [==============================] - 1s 598us/step - loss: 0.0310 - acc: 0.9207 - val_loss: 0.0924 - val_acc: 0.7597\n",
      "Epoch 1395/5000\n",
      "2252/2252 [==============================] - 1s 598us/step - loss: 0.0314 - acc: 0.9208 - val_loss: 0.0891 - val_acc: 0.7652\n",
      "Epoch 1396/5000\n",
      "2252/2252 [==============================] - 1s 595us/step - loss: 0.0309 - acc: 0.9218 - val_loss: 0.0895 - val_acc: 0.7648\n",
      "Epoch 1397/5000\n",
      "2252/2252 [==============================] - 1s 598us/step - loss: 0.0319 - acc: 0.9191 - val_loss: 0.0918 - val_acc: 0.7597\n",
      "Epoch 1398/5000\n",
      "2252/2252 [==============================] - 1s 579us/step - loss: 0.0314 - acc: 0.9205 - val_loss: 0.0880 - val_acc: 0.7677\n",
      "Epoch 1399/5000\n",
      "2252/2252 [==============================] - 1s 597us/step - loss: 0.0310 - acc: 0.9220 - val_loss: 0.0874 - val_acc: 0.7686\n",
      "Epoch 1400/5000\n",
      "2252/2252 [==============================] - 1s 592us/step - loss: 0.0325 - acc: 0.9180 - val_loss: 0.0908 - val_acc: 0.7617\n",
      "Epoch 1401/5000\n",
      "2252/2252 [==============================] - 1s 599us/step - loss: 0.0311 - acc: 0.9207 - val_loss: 0.0904 - val_acc: 0.7632\n",
      "Epoch 1402/5000\n",
      "2252/2252 [==============================] - 1s 591us/step - loss: 0.0322 - acc: 0.9183 - val_loss: 0.0901 - val_acc: 0.7643\n",
      "Epoch 1403/5000\n",
      "2252/2252 [==============================] - 1s 586us/step - loss: 0.0306 - acc: 0.9236 - val_loss: 0.0911 - val_acc: 0.7609\n",
      "Epoch 1404/5000\n",
      "2252/2252 [==============================] - 1s 601us/step - loss: 0.0306 - acc: 0.9218 - val_loss: 0.0938 - val_acc: 0.7561\n",
      "Epoch 1405/5000\n",
      "2252/2252 [==============================] - 1s 602us/step - loss: 0.0312 - acc: 0.9216 - val_loss: 0.0905 - val_acc: 0.7623\n",
      "Epoch 1406/5000\n",
      "2252/2252 [==============================] - 1s 589us/step - loss: 0.0308 - acc: 0.9231 - val_loss: 0.0914 - val_acc: 0.7611\n",
      "Epoch 1407/5000\n",
      "2252/2252 [==============================] - 1s 594us/step - loss: 0.0308 - acc: 0.9209 - val_loss: 0.0893 - val_acc: 0.7674\n",
      "Epoch 1408/5000\n",
      "2252/2252 [==============================] - 1s 598us/step - loss: 0.0318 - acc: 0.9187 - val_loss: 0.0904 - val_acc: 0.7646\n",
      "Epoch 1409/5000\n",
      "2252/2252 [==============================] - 1s 594us/step - loss: 0.0302 - acc: 0.9244 - val_loss: 0.0895 - val_acc: 0.7650\n",
      "Epoch 1410/5000\n",
      "2252/2252 [==============================] - 1s 594us/step - loss: 0.0301 - acc: 0.9220 - val_loss: 0.0944 - val_acc: 0.7545\n",
      "Epoch 1411/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.0312 - acc: 0.9213 - val_loss: 0.0900 - val_acc: 0.7642\n",
      "Epoch 1412/5000\n",
      "2252/2252 [==============================] - 1s 587us/step - loss: 0.0310 - acc: 0.9219 - val_loss: 0.0917 - val_acc: 0.7629\n",
      "Epoch 1413/5000\n",
      "2252/2252 [==============================] - 1s 578us/step - loss: 0.0310 - acc: 0.9216 - val_loss: 0.0928 - val_acc: 0.7592\n",
      "Epoch 1414/5000\n",
      "2252/2252 [==============================] - 1s 585us/step - loss: 0.0306 - acc: 0.9219 - val_loss: 0.0884 - val_acc: 0.7677\n",
      "Epoch 1415/5000\n",
      "2252/2252 [==============================] - 1s 588us/step - loss: 0.0305 - acc: 0.9232 - val_loss: 0.0892 - val_acc: 0.7661\n",
      "Epoch 1416/5000\n",
      "2252/2252 [==============================] - 1s 596us/step - loss: 0.0306 - acc: 0.9230 - val_loss: 0.0898 - val_acc: 0.7657\n",
      "Epoch 1417/5000\n",
      "2252/2252 [==============================] - 1s 582us/step - loss: 0.0315 - acc: 0.9206 - val_loss: 0.0913 - val_acc: 0.7615\n",
      "Epoch 1418/5000\n",
      "2252/2252 [==============================] - 1s 585us/step - loss: 0.0303 - acc: 0.9234 - val_loss: 0.0937 - val_acc: 0.7566\n",
      "Epoch 1419/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.0325 - acc: 0.9167 - val_loss: 0.0928 - val_acc: 0.7608\n",
      "Epoch 1420/5000\n",
      "2252/2252 [==============================] - 1s 591us/step - loss: 0.0305 - acc: 0.9224 - val_loss: 0.0890 - val_acc: 0.7672\n",
      "Epoch 1421/5000\n",
      "2252/2252 [==============================] - 1s 586us/step - loss: 0.0312 - acc: 0.9209 - val_loss: 0.0897 - val_acc: 0.7639\n",
      "Epoch 1422/5000\n",
      "2252/2252 [==============================] - 1s 581us/step - loss: 0.0304 - acc: 0.9229 - val_loss: 0.0883 - val_acc: 0.7696\n",
      "Epoch 1423/5000\n",
      "2252/2252 [==============================] - 1s 583us/step - loss: 0.0333 - acc: 0.9153 - val_loss: 0.0894 - val_acc: 0.7656\n",
      "Epoch 1424/5000\n",
      "2252/2252 [==============================] - 1s 596us/step - loss: 0.0314 - acc: 0.9197 - val_loss: 0.0879 - val_acc: 0.7668\n",
      "Epoch 1425/5000\n",
      "2252/2252 [==============================] - 1s 603us/step - loss: 0.0313 - acc: 0.9208 - val_loss: 0.0893 - val_acc: 0.7664\n",
      "Epoch 1426/5000\n",
      "2252/2252 [==============================] - 1s 586us/step - loss: 0.0305 - acc: 0.9222 - val_loss: 0.0899 - val_acc: 0.7665\n",
      "Epoch 1427/5000\n",
      "2252/2252 [==============================] - 1s 591us/step - loss: 0.0310 - acc: 0.9206 - val_loss: 0.0895 - val_acc: 0.7616\n",
      "Epoch 1428/5000\n",
      "2252/2252 [==============================] - 1s 594us/step - loss: 0.0308 - acc: 0.9222 - val_loss: 0.0885 - val_acc: 0.7679\n",
      "Epoch 1429/5000\n",
      "2252/2252 [==============================] - 1s 592us/step - loss: 0.0315 - acc: 0.9201 - val_loss: 0.0910 - val_acc: 0.7632\n",
      "Epoch 1430/5000\n",
      "2252/2252 [==============================] - 1s 596us/step - loss: 0.0297 - acc: 0.9252 - val_loss: 0.0883 - val_acc: 0.7689\n",
      "Epoch 1431/5000\n",
      "2252/2252 [==============================] - 1s 592us/step - loss: 0.0315 - acc: 0.9198 - val_loss: 0.0912 - val_acc: 0.7619\n",
      "Epoch 1432/5000\n",
      "2252/2252 [==============================] - 1s 594us/step - loss: 0.0307 - acc: 0.9228 - val_loss: 0.0955 - val_acc: 0.7525\n",
      "Epoch 1433/5000\n",
      "2252/2252 [==============================] - 1s 591us/step - loss: 0.0314 - acc: 0.9204 - val_loss: 0.0897 - val_acc: 0.7641\n",
      "Epoch 1434/5000\n",
      "2252/2252 [==============================] - 1s 579us/step - loss: 0.0315 - acc: 0.9194 - val_loss: 0.0880 - val_acc: 0.7710\n",
      "Epoch 1435/5000\n",
      "2252/2252 [==============================] - 1s 589us/step - loss: 0.0305 - acc: 0.9240 - val_loss: 0.0883 - val_acc: 0.7701\n",
      "Epoch 1436/5000\n",
      "2252/2252 [==============================] - 1s 588us/step - loss: 0.0310 - acc: 0.9209 - val_loss: 0.0938 - val_acc: 0.7589\n",
      "Epoch 1437/5000\n",
      "2252/2252 [==============================] - 1s 595us/step - loss: 0.0313 - acc: 0.9186 - val_loss: 0.0889 - val_acc: 0.7668\n",
      "Epoch 1438/5000\n",
      "2252/2252 [==============================] - 1s 598us/step - loss: 0.0314 - acc: 0.9196 - val_loss: 0.0925 - val_acc: 0.7587\n",
      "Epoch 1439/5000\n",
      "2252/2252 [==============================] - 1s 583us/step - loss: 0.0303 - acc: 0.9225 - val_loss: 0.0915 - val_acc: 0.7623\n",
      "Epoch 1440/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.0309 - acc: 0.9222 - val_loss: 0.0918 - val_acc: 0.7638\n",
      "Epoch 1441/5000\n",
      "2252/2252 [==============================] - 1s 584us/step - loss: 0.0305 - acc: 0.9237 - val_loss: 0.0882 - val_acc: 0.7698\n",
      "Epoch 1442/5000\n",
      "2252/2252 [==============================] - 1s 584us/step - loss: 0.0336 - acc: 0.9143 - val_loss: 0.0889 - val_acc: 0.7660\n",
      "Epoch 1443/5000\n",
      "2252/2252 [==============================] - 1s 595us/step - loss: 0.0311 - acc: 0.9205 - val_loss: 0.0895 - val_acc: 0.7664\n",
      "Epoch 1444/5000\n",
      "2252/2252 [==============================] - 1s 598us/step - loss: 0.0304 - acc: 0.9230 - val_loss: 0.0913 - val_acc: 0.7620\n",
      "Epoch 1445/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.0303 - acc: 0.9228 - val_loss: 0.0896 - val_acc: 0.7673\n",
      "Epoch 1446/5000\n",
      "2252/2252 [==============================] - 1s 599us/step - loss: 0.0298 - acc: 0.9254 - val_loss: 0.0904 - val_acc: 0.7636\n",
      "Epoch 1447/5000\n",
      "2252/2252 [==============================] - 1s 594us/step - loss: 0.0305 - acc: 0.9228 - val_loss: 0.0905 - val_acc: 0.7643\n",
      "Epoch 1448/5000\n",
      "2252/2252 [==============================] - 1s 596us/step - loss: 0.0319 - acc: 0.9179 - val_loss: 0.0883 - val_acc: 0.7670\n",
      "Epoch 1449/5000\n",
      "2252/2252 [==============================] - 1s 599us/step - loss: 0.0302 - acc: 0.9240 - val_loss: 0.0899 - val_acc: 0.7666\n",
      "Epoch 1450/5000\n",
      "2252/2252 [==============================] - 1s 587us/step - loss: 0.0307 - acc: 0.9229 - val_loss: 0.0925 - val_acc: 0.7602\n",
      "Epoch 1451/5000\n",
      "2252/2252 [==============================] - 1s 594us/step - loss: 0.0308 - acc: 0.9214 - val_loss: 0.0957 - val_acc: 0.7577\n",
      "Epoch 1452/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.0310 - acc: 0.9216 - val_loss: 0.0935 - val_acc: 0.7599\n",
      "Epoch 1453/5000\n",
      "2252/2252 [==============================] - 1s 589us/step - loss: 0.0316 - acc: 0.9199 - val_loss: 0.0936 - val_acc: 0.7566\n",
      "Epoch 1454/5000\n",
      "2252/2252 [==============================] - 1s 584us/step - loss: 0.0303 - acc: 0.9238 - val_loss: 0.0896 - val_acc: 0.7687\n",
      "Epoch 1455/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.0308 - acc: 0.9211 - val_loss: 0.0889 - val_acc: 0.7661\n",
      "Epoch 1456/5000\n",
      "2252/2252 [==============================] - 1s 588us/step - loss: 0.0312 - acc: 0.9207 - val_loss: 0.0901 - val_acc: 0.7639\n",
      "Epoch 1457/5000\n",
      "2252/2252 [==============================] - 1s 589us/step - loss: 0.0298 - acc: 0.9249 - val_loss: 0.0903 - val_acc: 0.7622\n",
      "Epoch 1458/5000\n",
      "2252/2252 [==============================] - 1s 588us/step - loss: 0.0294 - acc: 0.9265 - val_loss: 0.0986 - val_acc: 0.7483\n",
      "Epoch 1459/5000\n",
      "2252/2252 [==============================] - 1s 592us/step - loss: 0.0313 - acc: 0.9202 - val_loss: 0.0913 - val_acc: 0.7647\n",
      "Epoch 1460/5000\n",
      "2252/2252 [==============================] - 1s 601us/step - loss: 0.0298 - acc: 0.9245 - val_loss: 0.0912 - val_acc: 0.7617\n",
      "Epoch 1461/5000\n",
      "2252/2252 [==============================] - 1s 594us/step - loss: 0.0305 - acc: 0.9224 - val_loss: 0.0919 - val_acc: 0.7610\n",
      "Epoch 1462/5000\n",
      "2252/2252 [==============================] - 1s 595us/step - loss: 0.0315 - acc: 0.9207 - val_loss: 0.0937 - val_acc: 0.7573\n",
      "Epoch 1463/5000\n",
      "2252/2252 [==============================] - 1s 597us/step - loss: 0.0349 - acc: 0.9095 - val_loss: 0.1040 - val_acc: 0.7342\n",
      "Epoch 1464/5000\n",
      "2252/2252 [==============================] - 1s 599us/step - loss: 0.0336 - acc: 0.9139 - val_loss: 0.0913 - val_acc: 0.7623\n",
      "Epoch 1465/5000\n",
      "2252/2252 [==============================] - 1s 596us/step - loss: 0.0305 - acc: 0.9236 - val_loss: 0.0901 - val_acc: 0.7661\n",
      "Epoch 1466/5000\n",
      "2252/2252 [==============================] - 1s 597us/step - loss: 0.0293 - acc: 0.9280 - val_loss: 0.0896 - val_acc: 0.7670\n",
      "Epoch 1467/5000\n",
      "2252/2252 [==============================] - 1s 598us/step - loss: 0.0303 - acc: 0.9234 - val_loss: 0.0915 - val_acc: 0.7626\n",
      "Epoch 1468/5000\n",
      "2252/2252 [==============================] - 1s 588us/step - loss: 0.0308 - acc: 0.9216 - val_loss: 0.0939 - val_acc: 0.7592\n",
      "Epoch 1469/5000\n",
      "2252/2252 [==============================] - 1s 601us/step - loss: 0.0301 - acc: 0.9246 - val_loss: 0.0903 - val_acc: 0.7654\n",
      "Epoch 1470/5000\n",
      "2252/2252 [==============================] - 1s 602us/step - loss: 0.0295 - acc: 0.9265 - val_loss: 0.0893 - val_acc: 0.7670\n",
      "Epoch 1471/5000\n",
      "2252/2252 [==============================] - 1s 589us/step - loss: 0.0295 - acc: 0.9262 - val_loss: 0.0897 - val_acc: 0.7668\n",
      "Epoch 1472/5000\n",
      "2252/2252 [==============================] - 1s 582us/step - loss: 0.0301 - acc: 0.9253 - val_loss: 0.0914 - val_acc: 0.7637\n",
      "Epoch 1473/5000\n",
      "2252/2252 [==============================] - 1s 594us/step - loss: 0.0310 - acc: 0.9224 - val_loss: 0.0929 - val_acc: 0.7598\n",
      "Epoch 1474/5000\n",
      "2252/2252 [==============================] - 1s 600us/step - loss: 0.0288 - acc: 0.9286 - val_loss: 0.0918 - val_acc: 0.7647\n",
      "Epoch 1475/5000\n",
      "2252/2252 [==============================] - 1s 586us/step - loss: 0.0293 - acc: 0.9276 - val_loss: 0.0915 - val_acc: 0.7629\n",
      "Epoch 1476/5000\n",
      "2252/2252 [==============================] - 1s 594us/step - loss: 0.0297 - acc: 0.9258 - val_loss: 0.0919 - val_acc: 0.7617\n",
      "Epoch 1477/5000\n",
      "2252/2252 [==============================] - 1s 598us/step - loss: 0.0294 - acc: 0.9257 - val_loss: 0.0946 - val_acc: 0.7600\n",
      "Epoch 1478/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.0314 - acc: 0.9202 - val_loss: 0.0914 - val_acc: 0.7639\n",
      "Epoch 1479/5000\n",
      "2252/2252 [==============================] - 1s 578us/step - loss: 0.0301 - acc: 0.9239 - val_loss: 0.0983 - val_acc: 0.7475\n",
      "Epoch 1480/5000\n",
      "2252/2252 [==============================] - 1s 597us/step - loss: 0.0349 - acc: 0.9092 - val_loss: 0.0927 - val_acc: 0.7603\n",
      "Epoch 1481/5000\n",
      "2252/2252 [==============================] - 1s 591us/step - loss: 0.0304 - acc: 0.9232 - val_loss: 0.0897 - val_acc: 0.7681\n",
      "Epoch 1482/5000\n",
      "2252/2252 [==============================] - 1s 601us/step - loss: 0.0300 - acc: 0.9246 - val_loss: 0.0948 - val_acc: 0.7555\n",
      "Epoch 1483/5000\n",
      "2252/2252 [==============================] - 1s 580us/step - loss: 0.0292 - acc: 0.9275 - val_loss: 0.0902 - val_acc: 0.7629\n",
      "Epoch 1484/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.0306 - acc: 0.9213 - val_loss: 0.0901 - val_acc: 0.7656\n",
      "Epoch 1485/5000\n",
      "2252/2252 [==============================] - 1s 586us/step - loss: 0.0296 - acc: 0.9254 - val_loss: 0.0918 - val_acc: 0.7617\n",
      "Epoch 1486/5000\n",
      "2252/2252 [==============================] - 1s 597us/step - loss: 0.0294 - acc: 0.9254 - val_loss: 0.0936 - val_acc: 0.7600\n",
      "Epoch 1487/5000\n",
      "2252/2252 [==============================] - 1s 594us/step - loss: 0.0304 - acc: 0.9233 - val_loss: 0.0925 - val_acc: 0.7625\n",
      "Epoch 1488/5000\n",
      "2252/2252 [==============================] - 1s 599us/step - loss: 0.0297 - acc: 0.9249 - val_loss: 0.0918 - val_acc: 0.7622\n",
      "Epoch 1489/5000\n",
      "2252/2252 [==============================] - 1s 604us/step - loss: 0.0284 - acc: 0.9292 - val_loss: 0.0928 - val_acc: 0.7606\n",
      "Epoch 1490/5000\n",
      "2252/2252 [==============================] - 1s 583us/step - loss: 0.0309 - acc: 0.9208 - val_loss: 0.0988 - val_acc: 0.7461\n",
      "Epoch 1491/5000\n",
      "2252/2252 [==============================] - 1s 587us/step - loss: 0.0309 - acc: 0.9205 - val_loss: 0.0887 - val_acc: 0.7699\n",
      "Epoch 1492/5000\n",
      "2252/2252 [==============================] - 1s 590us/step - loss: 0.0292 - acc: 0.9272 - val_loss: 0.0890 - val_acc: 0.7675\n",
      "Epoch 1493/5000\n",
      "2252/2252 [==============================] - 1s 589us/step - loss: 0.0300 - acc: 0.9247 - val_loss: 0.0907 - val_acc: 0.7647\n",
      "Epoch 1494/5000\n",
      "2252/2252 [==============================] - 1s 579us/step - loss: 0.0287 - acc: 0.9288 - val_loss: 0.0918 - val_acc: 0.7629\n",
      "Epoch 1495/5000\n",
      "2252/2252 [==============================] - 1s 596us/step - loss: 0.0293 - acc: 0.9257 - val_loss: 0.0924 - val_acc: 0.7601\n",
      "Epoch 1496/5000\n",
      "2252/2252 [==============================] - 1s 594us/step - loss: 0.0294 - acc: 0.9260 - val_loss: 0.0899 - val_acc: 0.7644\n",
      "Epoch 1497/5000\n",
      "2252/2252 [==============================] - 1s 590us/step - loss: 0.0289 - acc: 0.9271 - val_loss: 0.0920 - val_acc: 0.7637\n",
      "Epoch 1498/5000\n",
      "2252/2252 [==============================] - 1s 597us/step - loss: 0.0314 - acc: 0.9196 - val_loss: 0.0912 - val_acc: 0.7628\n",
      "Epoch 1499/5000\n",
      "2252/2252 [==============================] - 1s 588us/step - loss: 0.0296 - acc: 0.9255 - val_loss: 0.0945 - val_acc: 0.7579\n",
      "Epoch 1500/5000\n",
      "2252/2252 [==============================] - 1s 589us/step - loss: 0.0292 - acc: 0.9260 - val_loss: 0.0886 - val_acc: 0.7698\n",
      "Epoch 1501/5000\n",
      "2252/2252 [==============================] - 1s 600us/step - loss: 0.0290 - acc: 0.9260 - val_loss: 0.0891 - val_acc: 0.7696\n",
      "Epoch 1502/5000\n",
      "2252/2252 [==============================] - 1s 598us/step - loss: 0.0294 - acc: 0.9263 - val_loss: 0.0948 - val_acc: 0.7570\n",
      "Epoch 1503/5000\n",
      "2252/2252 [==============================] - 1s 584us/step - loss: 0.0296 - acc: 0.9255 - val_loss: 0.0904 - val_acc: 0.7644\n",
      "Epoch 1504/5000\n",
      "2252/2252 [==============================] - 1s 598us/step - loss: 0.0295 - acc: 0.9248 - val_loss: 0.0893 - val_acc: 0.7697\n",
      "Epoch 1505/5000\n",
      "2252/2252 [==============================] - 1s 588us/step - loss: 0.0305 - acc: 0.9231 - val_loss: 0.0925 - val_acc: 0.7591\n",
      "Epoch 1506/5000\n",
      "2252/2252 [==============================] - 1s 604us/step - loss: 0.0291 - acc: 0.9272 - val_loss: 0.0895 - val_acc: 0.7679\n",
      "Epoch 1507/5000\n",
      "2252/2252 [==============================] - 1s 581us/step - loss: 0.0297 - acc: 0.9235 - val_loss: 0.0913 - val_acc: 0.7641\n",
      "Epoch 1508/5000\n",
      "2252/2252 [==============================] - 1s 582us/step - loss: 0.0290 - acc: 0.9270 - val_loss: 0.0930 - val_acc: 0.7606\n",
      "Epoch 1509/5000\n",
      "2252/2252 [==============================] - 1s 598us/step - loss: 0.0300 - acc: 0.9241 - val_loss: 0.0915 - val_acc: 0.7635\n",
      "Epoch 1510/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2252/2252 [==============================] - 1s 598us/step - loss: 0.0295 - acc: 0.9255 - val_loss: 0.0915 - val_acc: 0.7635\n",
      "Epoch 1511/5000\n",
      "2252/2252 [==============================] - 1s 596us/step - loss: 0.0295 - acc: 0.9248 - val_loss: 0.0952 - val_acc: 0.7554\n",
      "Epoch 1512/5000\n",
      "2252/2252 [==============================] - 1s 596us/step - loss: 0.0301 - acc: 0.9244 - val_loss: 0.0931 - val_acc: 0.7601\n",
      "Epoch 1513/5000\n",
      "2252/2252 [==============================] - 1s 594us/step - loss: 0.0301 - acc: 0.9238 - val_loss: 0.0907 - val_acc: 0.7639\n",
      "Epoch 1514/5000\n",
      "2252/2252 [==============================] - 1s 595us/step - loss: 0.0295 - acc: 0.9263 - val_loss: 0.0918 - val_acc: 0.7629\n",
      "Epoch 1515/5000\n",
      "2252/2252 [==============================] - 1s 594us/step - loss: 0.0288 - acc: 0.9284 - val_loss: 0.0897 - val_acc: 0.7672\n",
      "Epoch 1516/5000\n",
      "2252/2252 [==============================] - 1s 600us/step - loss: 0.0295 - acc: 0.9258 - val_loss: 0.0891 - val_acc: 0.7686\n",
      "Epoch 1517/5000\n",
      "2252/2252 [==============================] - 1s 600us/step - loss: 0.0297 - acc: 0.9244 - val_loss: 0.0940 - val_acc: 0.7604\n",
      "Epoch 1518/5000\n",
      "2252/2252 [==============================] - 1s 600us/step - loss: 0.0303 - acc: 0.9239 - val_loss: 0.0898 - val_acc: 0.7654\n",
      "Epoch 1519/5000\n",
      "2252/2252 [==============================] - 1s 594us/step - loss: 0.0294 - acc: 0.9252 - val_loss: 0.0883 - val_acc: 0.7687\n",
      "Epoch 1520/5000\n",
      "2252/2252 [==============================] - 1s 596us/step - loss: 0.0293 - acc: 0.9257 - val_loss: 0.0940 - val_acc: 0.7573\n",
      "Epoch 1521/5000\n",
      "2252/2252 [==============================] - 1s 585us/step - loss: 0.0293 - acc: 0.9261 - val_loss: 0.0924 - val_acc: 0.7591\n",
      "Epoch 1522/5000\n",
      "2252/2252 [==============================] - 1s 599us/step - loss: 0.0292 - acc: 0.9263 - val_loss: 0.0934 - val_acc: 0.7603\n",
      "Epoch 1523/5000\n",
      "2252/2252 [==============================] - 1s 595us/step - loss: 0.0293 - acc: 0.9260 - val_loss: 0.0928 - val_acc: 0.7603\n",
      "Epoch 1524/5000\n",
      "2252/2252 [==============================] - 1s 591us/step - loss: 0.0280 - acc: 0.9302 - val_loss: 0.0899 - val_acc: 0.7658\n",
      "Epoch 1525/5000\n",
      "2252/2252 [==============================] - 1s 599us/step - loss: 0.0292 - acc: 0.9276 - val_loss: 0.0906 - val_acc: 0.7644\n",
      "Epoch 1526/5000\n",
      "2252/2252 [==============================] - 1s 601us/step - loss: 0.0300 - acc: 0.9244 - val_loss: 0.0930 - val_acc: 0.7615\n",
      "Epoch 1527/5000\n",
      "2252/2252 [==============================] - 1s 594us/step - loss: 0.0302 - acc: 0.9237 - val_loss: 0.0933 - val_acc: 0.7599\n",
      "Epoch 1528/5000\n",
      "2252/2252 [==============================] - 1s 588us/step - loss: 0.0284 - acc: 0.9291 - val_loss: 0.0920 - val_acc: 0.7626\n",
      "Epoch 1529/5000\n",
      "2252/2252 [==============================] - 1s 590us/step - loss: 0.0293 - acc: 0.9255 - val_loss: 0.0907 - val_acc: 0.7661\n",
      "Epoch 1530/5000\n",
      "2252/2252 [==============================] - 1s 604us/step - loss: 0.0290 - acc: 0.9262 - val_loss: 0.0990 - val_acc: 0.7453\n",
      "Epoch 1531/5000\n",
      "2252/2252 [==============================] - 1s 596us/step - loss: 0.0315 - acc: 0.9206 - val_loss: 0.0900 - val_acc: 0.7691\n",
      "Epoch 1532/5000\n",
      "2252/2252 [==============================] - 1s 600us/step - loss: 0.0291 - acc: 0.9269 - val_loss: 0.0881 - val_acc: 0.7699\n",
      "Epoch 1533/5000\n",
      "2252/2252 [==============================] - 1s 598us/step - loss: 0.0313 - acc: 0.9205 - val_loss: 0.0886 - val_acc: 0.7693\n",
      "Epoch 1534/5000\n",
      "2252/2252 [==============================] - 1s 592us/step - loss: 0.0295 - acc: 0.9256 - val_loss: 0.0915 - val_acc: 0.7641\n",
      "Epoch 1535/5000\n",
      "2252/2252 [==============================] - 1s 603us/step - loss: 0.0286 - acc: 0.9277 - val_loss: 0.0933 - val_acc: 0.7601\n",
      "Epoch 1536/5000\n",
      "2252/2252 [==============================] - 1s 587us/step - loss: 0.0303 - acc: 0.9233 - val_loss: 0.0897 - val_acc: 0.7672\n",
      "Epoch 1537/5000\n",
      "2252/2252 [==============================] - 1s 588us/step - loss: 0.0287 - acc: 0.9281 - val_loss: 0.0925 - val_acc: 0.7613\n",
      "Epoch 1538/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.0287 - acc: 0.9279 - val_loss: 0.0893 - val_acc: 0.7678\n",
      "Epoch 1539/5000\n",
      "2252/2252 [==============================] - 1s 596us/step - loss: 0.0288 - acc: 0.9275 - val_loss: 0.0938 - val_acc: 0.7592\n",
      "Epoch 1540/5000\n",
      "2252/2252 [==============================] - 1s 585us/step - loss: 0.0293 - acc: 0.9257 - val_loss: 0.0929 - val_acc: 0.7618\n",
      "Epoch 1541/5000\n",
      "2252/2252 [==============================] - 1s 587us/step - loss: 0.0302 - acc: 0.9237 - val_loss: 0.0926 - val_acc: 0.7609\n",
      "Epoch 1542/5000\n",
      "2252/2252 [==============================] - 1s 598us/step - loss: 0.0307 - acc: 0.9221 - val_loss: 0.0923 - val_acc: 0.7622\n",
      "Epoch 1543/5000\n",
      "2252/2252 [==============================] - 1s 594us/step - loss: 0.0288 - acc: 0.9267 - val_loss: 0.0928 - val_acc: 0.7607\n",
      "Epoch 1544/5000\n",
      "2252/2252 [==============================] - 1s 588us/step - loss: 0.0288 - acc: 0.9272 - val_loss: 0.0902 - val_acc: 0.7655\n",
      "Epoch 1545/5000\n",
      "2252/2252 [==============================] - 1s 581us/step - loss: 0.0299 - acc: 0.9237 - val_loss: 0.0925 - val_acc: 0.7624\n",
      "Epoch 1546/5000\n",
      "2252/2252 [==============================] - 1s 594us/step - loss: 0.0284 - acc: 0.9294 - val_loss: 0.0938 - val_acc: 0.7583\n",
      "Epoch 1547/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.0276 - acc: 0.9305 - val_loss: 0.0920 - val_acc: 0.7616\n",
      "Epoch 1548/5000\n",
      "2252/2252 [==============================] - 1s 590us/step - loss: 0.0292 - acc: 0.9269 - val_loss: 0.0922 - val_acc: 0.7623\n",
      "Epoch 1549/5000\n",
      "2252/2252 [==============================] - 1s 590us/step - loss: 0.0288 - acc: 0.9273 - val_loss: 0.0917 - val_acc: 0.7635\n",
      "Epoch 1550/5000\n",
      "2252/2252 [==============================] - 1s 588us/step - loss: 0.0287 - acc: 0.9274 - val_loss: 0.0915 - val_acc: 0.7644\n",
      "Epoch 1551/5000\n",
      "2252/2252 [==============================] - 1s 595us/step - loss: 0.0290 - acc: 0.9279 - val_loss: 0.0915 - val_acc: 0.7630\n",
      "Epoch 1552/5000\n",
      "2252/2252 [==============================] - 1s 597us/step - loss: 0.0285 - acc: 0.9287 - val_loss: 0.0898 - val_acc: 0.7695\n",
      "Epoch 1553/5000\n",
      "2252/2252 [==============================] - 1s 585us/step - loss: 0.0283 - acc: 0.9295 - val_loss: 0.0931 - val_acc: 0.7606\n",
      "Epoch 1554/5000\n",
      "2252/2252 [==============================] - 1s 596us/step - loss: 0.0291 - acc: 0.9267 - val_loss: 0.0907 - val_acc: 0.7639\n",
      "Epoch 1555/5000\n",
      "2252/2252 [==============================] - 1s 596us/step - loss: 0.0284 - acc: 0.9298 - val_loss: 0.0912 - val_acc: 0.7642\n",
      "Epoch 1556/5000\n",
      "2252/2252 [==============================] - 1s 603us/step - loss: 0.0290 - acc: 0.9268 - val_loss: 0.0914 - val_acc: 0.7644\n",
      "Epoch 1557/5000\n",
      "2252/2252 [==============================] - 1s 595us/step - loss: 0.0285 - acc: 0.9278 - val_loss: 0.0956 - val_acc: 0.7556\n",
      "Epoch 1558/5000\n",
      "2252/2252 [==============================] - 1s 596us/step - loss: 0.0287 - acc: 0.9281 - val_loss: 0.1111 - val_acc: 0.7177\n",
      "Epoch 1559/5000\n",
      "2252/2252 [==============================] - 1s 581us/step - loss: 0.0309 - acc: 0.9215 - val_loss: 0.0898 - val_acc: 0.7662\n",
      "Epoch 1560/5000\n",
      "2252/2252 [==============================] - 1s 582us/step - loss: 0.0280 - acc: 0.9297 - val_loss: 0.0931 - val_acc: 0.7603\n",
      "Epoch 1561/5000\n",
      "2252/2252 [==============================] - 1s 586us/step - loss: 0.0284 - acc: 0.9283 - val_loss: 0.0963 - val_acc: 0.7554\n",
      "Epoch 1562/5000\n",
      "2252/2252 [==============================] - 1s 584us/step - loss: 0.0302 - acc: 0.9233 - val_loss: 0.0956 - val_acc: 0.7565\n",
      "Epoch 1563/5000\n",
      "2252/2252 [==============================] - 1s 592us/step - loss: 0.0304 - acc: 0.9214 - val_loss: 0.0930 - val_acc: 0.7613\n",
      "Epoch 1564/5000\n",
      "2252/2252 [==============================] - 1s 601us/step - loss: 0.0284 - acc: 0.9289 - val_loss: 0.0899 - val_acc: 0.7665\n",
      "Epoch 1565/5000\n",
      "2252/2252 [==============================] - 1s 586us/step - loss: 0.0280 - acc: 0.9298 - val_loss: 0.0917 - val_acc: 0.7643\n",
      "Epoch 1566/5000\n",
      "2252/2252 [==============================] - 1s 596us/step - loss: 0.0285 - acc: 0.9282 - val_loss: 0.0945 - val_acc: 0.7579\n",
      "Epoch 1567/5000\n",
      "2252/2252 [==============================] - 1s 597us/step - loss: 0.0285 - acc: 0.9283 - val_loss: 0.0930 - val_acc: 0.7617\n",
      "Epoch 1568/5000\n",
      "2252/2252 [==============================] - 1s 591us/step - loss: 0.0289 - acc: 0.9273 - val_loss: 0.0917 - val_acc: 0.7627\n",
      "Epoch 1569/5000\n",
      "2252/2252 [==============================] - 1s 596us/step - loss: 0.0285 - acc: 0.9281 - val_loss: 0.0933 - val_acc: 0.7595\n",
      "Epoch 1570/5000\n",
      "2252/2252 [==============================] - 1s 590us/step - loss: 0.0295 - acc: 0.9260 - val_loss: 0.0907 - val_acc: 0.7655\n",
      "Epoch 1571/5000\n",
      "2252/2252 [==============================] - 1s 587us/step - loss: 0.0296 - acc: 0.9234 - val_loss: 0.0888 - val_acc: 0.7694\n",
      "Epoch 1572/5000\n",
      "2252/2252 [==============================] - 1s 605us/step - loss: 0.0291 - acc: 0.9266 - val_loss: 0.0906 - val_acc: 0.7655\n",
      "Epoch 1573/5000\n",
      "2252/2252 [==============================] - 1s 602us/step - loss: 0.0286 - acc: 0.9279 - val_loss: 0.0893 - val_acc: 0.7706\n",
      "Epoch 1574/5000\n",
      "2252/2252 [==============================] - 1s 586us/step - loss: 0.0300 - acc: 0.9237 - val_loss: 0.0934 - val_acc: 0.7585\n",
      "Epoch 1575/5000\n",
      "2252/2252 [==============================] - 1s 589us/step - loss: 0.0280 - acc: 0.9288 - val_loss: 0.0918 - val_acc: 0.7644\n",
      "Epoch 1576/5000\n",
      "2252/2252 [==============================] - 1s 596us/step - loss: 0.0285 - acc: 0.9271 - val_loss: 0.0928 - val_acc: 0.7607\n",
      "Epoch 1577/5000\n",
      "2252/2252 [==============================] - 1s 598us/step - loss: 0.0296 - acc: 0.9246 - val_loss: 0.0926 - val_acc: 0.7615\n",
      "Epoch 1578/5000\n",
      "2252/2252 [==============================] - 1s 586us/step - loss: 0.0291 - acc: 0.9266 - val_loss: 0.0940 - val_acc: 0.7579\n",
      "Epoch 1579/5000\n",
      "2252/2252 [==============================] - 1s 576us/step - loss: 0.0282 - acc: 0.9281 - val_loss: 0.0948 - val_acc: 0.7561\n",
      "Epoch 1580/5000\n",
      "2252/2252 [==============================] - 1s 598us/step - loss: 0.0296 - acc: 0.9251 - val_loss: 0.0913 - val_acc: 0.7671\n",
      "Epoch 1581/5000\n",
      "2252/2252 [==============================] - 1s 591us/step - loss: 0.0305 - acc: 0.9229 - val_loss: 0.0908 - val_acc: 0.7630\n",
      "Epoch 1582/5000\n",
      "2252/2252 [==============================] - 1s 605us/step - loss: 0.0289 - acc: 0.9267 - val_loss: 0.0916 - val_acc: 0.7630\n",
      "Epoch 1583/5000\n",
      "2252/2252 [==============================] - 1s 594us/step - loss: 0.0282 - acc: 0.9286 - val_loss: 0.0909 - val_acc: 0.7667\n",
      "Epoch 1584/5000\n",
      "2252/2252 [==============================] - 1s 592us/step - loss: 0.0284 - acc: 0.9282 - val_loss: 0.0919 - val_acc: 0.7636\n",
      "Epoch 1585/5000\n",
      "2252/2252 [==============================] - 1s 597us/step - loss: 0.0287 - acc: 0.9280 - val_loss: 0.0916 - val_acc: 0.7632\n",
      "Epoch 1586/5000\n",
      "2252/2252 [==============================] - 1s 600us/step - loss: 0.0275 - acc: 0.9306 - val_loss: 0.0926 - val_acc: 0.7622\n",
      "Epoch 1587/5000\n",
      "2252/2252 [==============================] - 1s 603us/step - loss: 0.0288 - acc: 0.9282 - val_loss: 0.0902 - val_acc: 0.7677\n",
      "Epoch 1588/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.0281 - acc: 0.9294 - val_loss: 0.0906 - val_acc: 0.7680\n",
      "Epoch 1589/5000\n",
      "2252/2252 [==============================] - 1s 596us/step - loss: 0.0271 - acc: 0.9321 - val_loss: 0.0923 - val_acc: 0.7620\n",
      "Epoch 1590/5000\n",
      "2252/2252 [==============================] - 1s 590us/step - loss: 0.0287 - acc: 0.9276 - val_loss: 0.0931 - val_acc: 0.7602\n",
      "Epoch 1591/5000\n",
      "2252/2252 [==============================] - 1s 592us/step - loss: 0.0275 - acc: 0.9324 - val_loss: 0.0925 - val_acc: 0.7643\n",
      "Epoch 1592/5000\n",
      "2252/2252 [==============================] - 1s 594us/step - loss: 0.0284 - acc: 0.9276 - val_loss: 0.0902 - val_acc: 0.7687\n",
      "Epoch 1593/5000\n",
      "2252/2252 [==============================] - 1s 598us/step - loss: 0.0281 - acc: 0.9303 - val_loss: 0.0903 - val_acc: 0.7670\n",
      "Epoch 1594/5000\n",
      "2252/2252 [==============================] - 1s 589us/step - loss: 0.0294 - acc: 0.9249 - val_loss: 0.0919 - val_acc: 0.7625\n",
      "Epoch 1595/5000\n",
      "2252/2252 [==============================] - 1s 583us/step - loss: 0.0299 - acc: 0.9228 - val_loss: 0.0942 - val_acc: 0.7606\n",
      "Epoch 1596/5000\n",
      "2252/2252 [==============================] - 1s 604us/step - loss: 0.0288 - acc: 0.9277 - val_loss: 0.0917 - val_acc: 0.7633\n",
      "Epoch 1597/5000\n",
      "2252/2252 [==============================] - 1s 586us/step - loss: 0.0296 - acc: 0.9249 - val_loss: 0.0928 - val_acc: 0.7624\n",
      "Epoch 1598/5000\n",
      "2252/2252 [==============================] - 1s 601us/step - loss: 0.0289 - acc: 0.9275 - val_loss: 0.0907 - val_acc: 0.7659\n",
      "Epoch 1599/5000\n",
      "2252/2252 [==============================] - 1s 603us/step - loss: 0.0279 - acc: 0.9291 - val_loss: 0.0919 - val_acc: 0.7634\n",
      "Epoch 1600/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.0296 - acc: 0.9252 - val_loss: 0.0909 - val_acc: 0.7656\n",
      "Epoch 1601/5000\n",
      "2252/2252 [==============================] - 1s 576us/step - loss: 0.0284 - acc: 0.9286 - val_loss: 0.0923 - val_acc: 0.7610\n",
      "Epoch 1602/5000\n",
      "2252/2252 [==============================] - 1s 596us/step - loss: 0.0287 - acc: 0.9272 - val_loss: 0.0904 - val_acc: 0.7675\n",
      "Epoch 1603/5000\n",
      "2252/2252 [==============================] - 1s 602us/step - loss: 0.0283 - acc: 0.9281 - val_loss: 0.0920 - val_acc: 0.7622\n",
      "Epoch 1604/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.0278 - acc: 0.9304 - val_loss: 0.0916 - val_acc: 0.7661\n",
      "Epoch 1605/5000\n",
      "2252/2252 [==============================] - 1s 600us/step - loss: 0.0268 - acc: 0.9317 - val_loss: 0.0901 - val_acc: 0.7696\n",
      "Epoch 1606/5000\n",
      "2252/2252 [==============================] - 1s 596us/step - loss: 0.0293 - acc: 0.9256 - val_loss: 0.0918 - val_acc: 0.7667\n",
      "Epoch 1607/5000\n",
      "2252/2252 [==============================] - 1s 595us/step - loss: 0.0291 - acc: 0.9264 - val_loss: 0.0955 - val_acc: 0.7560\n",
      "Epoch 1608/5000\n",
      "2252/2252 [==============================] - 1s 599us/step - loss: 0.0287 - acc: 0.9281 - val_loss: 0.0904 - val_acc: 0.7671\n",
      "Epoch 1609/5000\n",
      "2252/2252 [==============================] - 1s 598us/step - loss: 0.0282 - acc: 0.9283 - val_loss: 0.0905 - val_acc: 0.7686\n",
      "Epoch 1610/5000\n",
      "2252/2252 [==============================] - 1s 579us/step - loss: 0.0285 - acc: 0.9287 - val_loss: 0.0924 - val_acc: 0.7636\n",
      "Epoch 1611/5000\n",
      "2252/2252 [==============================] - 1s 595us/step - loss: 0.0275 - acc: 0.9308 - val_loss: 0.0945 - val_acc: 0.7593\n",
      "Epoch 1612/5000\n",
      "2252/2252 [==============================] - 1s 596us/step - loss: 0.0296 - acc: 0.9252 - val_loss: 0.0893 - val_acc: 0.7706\n",
      "Epoch 1613/5000\n",
      "2252/2252 [==============================] - 1s 594us/step - loss: 0.0282 - acc: 0.9302 - val_loss: 0.0910 - val_acc: 0.7655\n",
      "Epoch 1614/5000\n",
      "2252/2252 [==============================] - 1s 594us/step - loss: 0.0282 - acc: 0.9288 - val_loss: 0.0953 - val_acc: 0.7564\n",
      "Epoch 1615/5000\n",
      "2252/2252 [==============================] - 1s 595us/step - loss: 0.0278 - acc: 0.9296 - val_loss: 0.0923 - val_acc: 0.7610\n",
      "Epoch 1616/5000\n",
      "2252/2252 [==============================] - 1s 595us/step - loss: 0.0291 - acc: 0.9264 - val_loss: 0.0985 - val_acc: 0.7501\n",
      "Epoch 1617/5000\n",
      "2252/2252 [==============================] - 1s 600us/step - loss: 0.0280 - acc: 0.9305 - val_loss: 0.0906 - val_acc: 0.7677\n",
      "Epoch 1618/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.0272 - acc: 0.9316 - val_loss: 0.0924 - val_acc: 0.7642\n",
      "Epoch 1619/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.0276 - acc: 0.9311 - val_loss: 0.0917 - val_acc: 0.7637\n",
      "Epoch 1620/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.0274 - acc: 0.9315 - val_loss: 0.0923 - val_acc: 0.7644\n",
      "Epoch 1621/5000\n",
      "2252/2252 [==============================] - 1s 596us/step - loss: 0.0271 - acc: 0.9316 - val_loss: 0.0910 - val_acc: 0.7655\n",
      "Epoch 1622/5000\n",
      "2252/2252 [==============================] - 1s 597us/step - loss: 0.0277 - acc: 0.9300 - val_loss: 0.0949 - val_acc: 0.7587\n",
      "Epoch 1623/5000\n",
      "2252/2252 [==============================] - 1s 589us/step - loss: 0.0289 - acc: 0.9276 - val_loss: 0.0924 - val_acc: 0.7624\n",
      "Epoch 1624/5000\n",
      "2252/2252 [==============================] - 1s 599us/step - loss: 0.0279 - acc: 0.9297 - val_loss: 0.0951 - val_acc: 0.7574\n",
      "Epoch 1625/5000\n",
      "2252/2252 [==============================] - 1s 602us/step - loss: 0.0281 - acc: 0.9293 - val_loss: 0.0936 - val_acc: 0.7598\n",
      "Epoch 1626/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2252/2252 [==============================] - 1s 603us/step - loss: 0.0279 - acc: 0.9299 - val_loss: 0.0907 - val_acc: 0.7680\n",
      "Epoch 1627/5000\n",
      "2252/2252 [==============================] - 1s 591us/step - loss: 0.0280 - acc: 0.9297 - val_loss: 0.0912 - val_acc: 0.7661\n",
      "Epoch 1628/5000\n",
      "2252/2252 [==============================] - 1s 584us/step - loss: 0.0271 - acc: 0.9321 - val_loss: 0.0931 - val_acc: 0.7615\n",
      "Epoch 1629/5000\n",
      "2252/2252 [==============================] - 1s 592us/step - loss: 0.0270 - acc: 0.9321 - val_loss: 0.0922 - val_acc: 0.7639\n",
      "Epoch 1630/5000\n",
      "2252/2252 [==============================] - 1s 576us/step - loss: 0.0279 - acc: 0.9297 - val_loss: 0.0908 - val_acc: 0.7668\n",
      "Epoch 1631/5000\n",
      "2252/2252 [==============================] - 1s 598us/step - loss: 0.0280 - acc: 0.9291 - val_loss: 0.0907 - val_acc: 0.7687\n",
      "Epoch 1632/5000\n",
      "2252/2252 [==============================] - 1s 599us/step - loss: 0.0277 - acc: 0.9302 - val_loss: 0.0934 - val_acc: 0.7608\n",
      "Epoch 1633/5000\n",
      "2252/2252 [==============================] - 1s 589us/step - loss: 0.0281 - acc: 0.9290 - val_loss: 0.0944 - val_acc: 0.7602\n",
      "Epoch 1634/5000\n",
      "2252/2252 [==============================] - 1s 590us/step - loss: 0.0281 - acc: 0.9287 - val_loss: 0.0910 - val_acc: 0.7664\n",
      "Epoch 1635/5000\n",
      "2252/2252 [==============================] - 1s 587us/step - loss: 0.0283 - acc: 0.9292 - val_loss: 0.0899 - val_acc: 0.7671\n",
      "Epoch 1636/5000\n",
      "2252/2252 [==============================] - 1s 601us/step - loss: 0.0277 - acc: 0.9300 - val_loss: 0.0903 - val_acc: 0.7693\n",
      "Epoch 1637/5000\n",
      "2252/2252 [==============================] - 1s 584us/step - loss: 0.0301 - acc: 0.9233 - val_loss: 0.0916 - val_acc: 0.7651\n",
      "Epoch 1638/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.0275 - acc: 0.9308 - val_loss: 0.0905 - val_acc: 0.7661\n",
      "Epoch 1639/5000\n",
      "2252/2252 [==============================] - 1s 598us/step - loss: 0.0284 - acc: 0.9281 - val_loss: 0.0948 - val_acc: 0.7573\n",
      "Epoch 1640/5000\n",
      "2252/2252 [==============================] - 1s 607us/step - loss: 0.0274 - acc: 0.9319 - val_loss: 0.0931 - val_acc: 0.7611\n",
      "Epoch 1641/5000\n",
      "2252/2252 [==============================] - 1s 604us/step - loss: 0.0272 - acc: 0.9322 - val_loss: 0.0932 - val_acc: 0.7615\n",
      "Epoch 1642/5000\n",
      "2252/2252 [==============================] - 1s 588us/step - loss: 0.0272 - acc: 0.9313 - val_loss: 0.0915 - val_acc: 0.7649\n",
      "Epoch 1643/5000\n",
      "2252/2252 [==============================] - 1s 588us/step - loss: 0.0272 - acc: 0.9323 - val_loss: 0.0901 - val_acc: 0.7694\n",
      "Epoch 1644/5000\n",
      "2252/2252 [==============================] - 1s 588us/step - loss: 0.0267 - acc: 0.9335 - val_loss: 0.0929 - val_acc: 0.7641\n",
      "Epoch 1645/5000\n",
      "2252/2252 [==============================] - 1s 595us/step - loss: 0.0273 - acc: 0.9313 - val_loss: 0.0911 - val_acc: 0.7647\n",
      "Epoch 1646/5000\n",
      "2252/2252 [==============================] - 1s 583us/step - loss: 0.0275 - acc: 0.9305 - val_loss: 0.0944 - val_acc: 0.7585\n",
      "Epoch 1647/5000\n",
      "2252/2252 [==============================] - 1s 575us/step - loss: 0.0270 - acc: 0.9315 - val_loss: 0.1009 - val_acc: 0.7455\n",
      "Epoch 1648/5000\n",
      "2252/2252 [==============================] - 1s 596us/step - loss: 0.0286 - acc: 0.9276 - val_loss: 0.0941 - val_acc: 0.7606\n",
      "Epoch 1649/5000\n",
      "2252/2252 [==============================] - 1s 593us/step - loss: 0.0297 - acc: 0.9234 - val_loss: 0.0911 - val_acc: 0.7686\n",
      "Epoch 1650/5000\n",
      "2252/2252 [==============================] - 1s 596us/step - loss: 0.0276 - acc: 0.9306 - val_loss: 0.0928 - val_acc: 0.7633\n",
      "Epoch 1651/5000\n",
      "2252/2252 [==============================] - 1s 580us/step - loss: 0.0268 - acc: 0.9341 - val_loss: 0.0957 - val_acc: 0.7551\n",
      "Epoch 1652/5000\n",
      "2252/2252 [==============================] - 1s 595us/step - loss: 0.0273 - acc: 0.9318 - val_loss: 0.0898 - val_acc: 0.7709\n",
      "Epoch 1653/5000\n",
      "2252/2252 [==============================] - 1s 596us/step - loss: 0.0281 - acc: 0.9292 - val_loss: 0.0908 - val_acc: 0.7685\n",
      "Epoch 1654/5000\n",
      "2252/2252 [==============================] - 1s 580us/step - loss: 0.0266 - acc: 0.9340 - val_loss: 0.0931 - val_acc: 0.7631\n",
      "Epoch 1655/5000\n",
      "2252/2252 [==============================] - 1s 599us/step - loss: 0.0273 - acc: 0.9304 - val_loss: 0.0948 - val_acc: 0.7594\n",
      "Epoch 1656/5000\n",
      "2252/2252 [==============================] - 1s 597us/step - loss: 0.0279 - acc: 0.9301 - val_loss: 0.1003 - val_acc: 0.7471\n",
      "Epoch 1657/5000\n",
      "2252/2252 [==============================] - 1s 604us/step - loss: 0.0284 - acc: 0.9279 - val_loss: 0.0950 - val_acc: 0.7595\n",
      "Epoch 1658/5000\n",
      "2252/2252 [==============================] - 1s 577us/step - loss: 0.0279 - acc: 0.9294 - val_loss: 0.0921 - val_acc: 0.7638\n",
      "Epoch 1659/5000\n",
      "2252/2252 [==============================] - 1s 568us/step - loss: 0.0279 - acc: 0.9293 - val_loss: 0.0918 - val_acc: 0.7651\n",
      "Epoch 1660/5000\n",
      " 320/2252 [===>..........................] - ETA: 0s - loss: 0.0252 - acc: 0.9378"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-106-20a165ccd6d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m             )\n",
      "\u001b[0;32m~/miniconda3/envs/models/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/miniconda3/envs/models/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    183\u001b[0m                         \u001b[0;31m# Do not slice the training phase flag.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                         ins_batch = slice_arrays(\n\u001b[0;32m--> 185\u001b[0;31m                             ins[:-1], batch_ids) + [ins[-1]]\n\u001b[0m\u001b[1;32m    186\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                         \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/models/lib/python3.6/site-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mslice_arrays\u001b[0;34m(arrays, start, stop)\u001b[0m\n\u001b[1;32m    524\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/models/lib/python3.6/site-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    524\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dcnn_model.fit(\n",
    "    X_train_lstm,  # trying with lstm features instead of dcnn_features\n",
    "    y_train,\n",
    "    validation_split=validation_split,\n",
    "    batch_size=batch_size,\n",
    "    epochs=5000,\n",
    "    shuffle=True,\n",
    "    callbacks=[plot_losses],\n",
    "    verbose=0\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights = None\n",
    "# if weights is None:\n",
    "#     base_model = InceptionV3(\n",
    "#         weights='imagenet',\n",
    "#         include_top=True\n",
    "#     )\n",
    "#     feature_model = Model(\n",
    "#         inputs=base_model.input,\n",
    "#         outputs=base_model.get_layer('avg_pool').output\n",
    "#     )\n",
    "# else:\n",
    "#     feature_model = load_model(weights)\n",
    "#     feature_model.layers.pop()\n",
    "#     feature_model.layers.pop()  # get to pool layer\n",
    "#     feature_model.outputs = [self.model.layers[-1].output]\n",
    "#     feature_model.output_layers = [self.model.layers[-1]]\n",
    "#     feature_model.layers[-1].outbound_nodes = []\n",
    "\n",
    "# def extract(model, image_path):\n",
    "#     img = image.load_img(image_path, target_size=(299, 299))\n",
    "#     x = image.img_to_array(img)\n",
    "#     x = np.expand_dims(x, axis=0)\n",
    "#     x = preprocess_input(x)\n",
    "\n",
    "#     # Get the prediction.\n",
    "#     features = model.predict(x)\n",
    "\n",
    "#     features = features[0]\n",
    "\n",
    "#     return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ls 'data/ocellatus_video_frames/' | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_model.output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEATS = np.empty((40620,2048))\n",
    "# for i, file in enumerate(video_frames):\n",
    "#     features = extract(feature_model, file)\n",
    "#     FEATS[i] = features\n",
    "# np.save('data/ocellatus_features', FEATS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/jpeg": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(filename=video_frames[np.random.randint(0, len(video_frames)-1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40620, 4) (40620, 2048)\n"
     ]
    }
   ],
   "source": [
    "labels = np.loadtxt(annotations, skiprows=1, delimiter=',')\n",
    "features = np.load(inception_features)\n",
    "labels = (labels > 0.5).astype(np.int_)  # make labels onehot\n",
    "_, idx, counts = np.unique(labels, axis=0, return_inverse=True, return_counts=True)\n",
    "labels = to_categorical(idx)\n",
    "print(labels.shape, features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2816, 28, 2048) (2816, 28, 4)\n"
     ]
    }
   ],
   "source": [
    "# dealing with biases\n",
    "X, Y = evenly_subsample_features(labels, features, idx, counts, seq_len=seq_len, n_features=features.shape[1])\n",
    "print(X.shape, Y.shape)\n",
    "np.save('data/occelatus_LSTM_features', X)\n",
    "np.save('data/occelatus_LSTM_labels', Y)\n",
    "del X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm_model(input_shape=1, nb_classes=4):    \n",
    "    inputs = Input(shape=input_shape, name='input')\n",
    "    x = Bidirectional(LSTM(32, return_sequences=True))(inputs)\n",
    "    x = Dropout(0.6)(x)\n",
    "    x = Bidirectional(LSTM(32, return_sequences=True))(x)\n",
    "    x = Dropout(0.6)(x)\n",
    "    x = Bidirectional(LSTM(32, return_sequences=True))(x)\n",
    "    x = Dropout(0.6)(x)\n",
    "    x = TimeDistributed(Dense(nb_classes, activation='sigmoid'))(x)\n",
    "    model = Model(inputs, x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train_lstm = np.load(LSTM_features_file)\n",
    "y_train = np.load(LSTM_labels_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 28, 2048)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_16 (Bidirectio (None, 28, 64)            532736    \n",
      "_________________________________________________________________\n",
      "dropout_65 (Dropout)         (None, 28, 64)            0         \n",
      "_________________________________________________________________\n",
      "bidirectional_17 (Bidirectio (None, 28, 64)            24832     \n",
      "_________________________________________________________________\n",
      "dropout_66 (Dropout)         (None, 28, 64)            0         \n",
      "_________________________________________________________________\n",
      "bidirectional_18 (Bidirectio (None, 28, 64)            24832     \n",
      "_________________________________________________________________\n",
      "dropout_67 (Dropout)         (None, 28, 64)            0         \n",
      "_________________________________________________________________\n",
      "time_distributed_78 (TimeDis (None, 28, 4)             260       \n",
      "=================================================================\n",
      "Total params: 582,660\n",
      "Trainable params: 582,660\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "features = \n",
    "\n",
    "seq_len = 32\n",
    "seq_stps = 1\n",
    "\n",
    "batch_size = 64\n",
    "validation_split = 0.2\n",
    "n_epochs = 500\n",
    "\n",
    "loss = 'mse'\n",
    "optimizer = Adam(lr=1e-5)\n",
    "metrics = ['accuracy']\n",
    "\n",
    "X_train, Y_train = evenly_subsample_features(\n",
    "    labels,\n",
    "    features,\n",
    "    idx,\n",
    "    counts,\n",
    "    seq_stps=seq_stps,\n",
    "    seq_len=seq_len,\n",
    "    n_features=features.shape[1],\n",
    ")\n",
    "\n",
    "lstm_model = build_lstm_model(\n",
    "    input_shape=(X_train.shape[1], X_train.shape[2]),\n",
    "    nb_classes=y_train.shape[2])\n",
    "\n",
    "lstm_model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "lstm_model.summary()\n",
    "\n",
    "lstm_model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    validation_split=validation_split,\n",
    "    batch_size=batch_size,\n",
    "    epochs=n_epochs,\n",
    "    shuffle=True,\n",
    "    callbacks=[plot_losses],\n",
    "    verbose=0\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-221-5dc7acc3702e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mplot_losses\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             )\n",
      "\u001b[0;32m~/miniconda3/envs/models/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/miniconda3/envs/models/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/models/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/models/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/models/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull out to utils file\n",
    "\n",
    "def build_cnn_lstm_model(input_shape=1, nb_classes=4):    \n",
    "    inputs = Input(shape=input_shape, name='input')\n",
    "    x = TimeDistributed(Conv1D(filters=64, kernel_size=3, activation='relu'))(inputs)\n",
    "    x = TimeDistributed(Conv1D(filters=64, kernel_size=3, activation='relu'))(x)\n",
    "    x = TimeDistributed(Dropout(0.5))(x)\n",
    "    x = TimeDistributed(MaxPooling1D(pool_size=2))(x)\n",
    "    x = TimeDistributed(Flatten())(x)\n",
    "    x = LSTM(100)(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(100, activation='relu')(x)\n",
    "    x = Dense(nb_classes, activation='softmax')(x)\n",
    "    model = Model(inputs, x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-229-ccbf3a493270>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         X_train.shape[3]),\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mnb_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m )\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "seq_len = 32\n",
    "seq_stps = 1\n",
    "\n",
    "batch_size = 64\n",
    "validation_split = 0.2\n",
    "n_epochs = 500\n",
    "\n",
    "loss = 'mse'\n",
    "optimizer = Adam(lr=1e-5)\n",
    "metrics = ['accuracy']\n",
    "\n",
    "\n",
    "X_train, Y_train = evenly_subsample_features(\n",
    "    labels,\n",
    "    features,\n",
    "    idx,\n",
    "    counts,\n",
    "    seq_stps=seq_stps,\n",
    "    seq_len=seq_len,\n",
    "    n_features=features.shape[1],\n",
    ")\n",
    "\n",
    "cnn_lstm_model = build_cnn_lstm_model(\n",
    "    input_shape=(\n",
    "        X_train.shape[1],\n",
    "        X_train.shape[2],\n",
    "        X_train.shape[3]),\n",
    "    nb_classes=4,\n",
    ")\n",
    "\n",
    "cnn_lstm_model.compile(\n",
    "    loss=loss,\n",
    "    optimizer=optimizer,\n",
    "    metrics=metrics)\n",
    "\n",
    "cnn_lstm_model.summary()\n",
    "\n",
    "cnn_lstm_model.fit(\n",
    "    X_train, Y_train,\n",
    "    validation_split=validation_split,\n",
    "    batch_size=batch_size,\n",
    "    epochs=n_epochs,\n",
    "    shuffle=True,\n",
    "    callbacks=[plot_losses],\n",
    "    verbose=0\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_convlstm_model(input_shape=1, nb_classes=4):\n",
    "    inputs = Input(shape=input_shape, name='input')\n",
    "    x = ConvLSTM2D(filters=32, kernel_size=(1,1), activation='relu')(inputs)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(100, activation='relu')(x)\n",
    "    x = Dense(nb_classes, activation='softmax')(x)\n",
    "    model = Model(inputs, x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 is incompatible with layer conv_lst_m2d_4: expected ndim=5, found ndim=3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-135-6e188b182b62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclstm_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_convlstm_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_lstm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train_lstm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mclstm_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmdn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_mixture_loss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mclstm_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-134-aec0070a085a>\u001b[0m in \u001b[0;36mbuild_convlstm_model\u001b[0;34m(input_shape, nb_classes)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbuild_convlstm_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'input'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConvLSTM2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/models/lib/python3.6/site-packages/keras/layers/convolutional_recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConvRNN2D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/models/lib/python3.6/site-packages/keras/layers/recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m         \u001b[0;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/models/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    412\u001b[0m                 \u001b[0;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m                 \u001b[0;31m# with the input_spec specified in the layer constructor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m                 \u001b[0;31m# Collect input shapes to build layer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/models/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                                      \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m': expected ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                                      \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', found ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m                                      str(K.ndim(x)))\n\u001b[0m\u001b[1;32m    312\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_ndim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m                 \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 is incompatible with layer conv_lst_m2d_4: expected ndim=5, found ndim=3"
     ]
    }
   ],
   "source": [
    "clstm_model = build_convlstm_model((X_train_lstm.shape[1], X_train_lstm.shape[2]), nb_classes=y_train.shape[2])\n",
    "clstm_model.compile(loss=mdn.get_mixture_loss_func(4,1), optimizer='adam')\n",
    "clstm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_rnn_mdn_model(input_shape=2048, nb_classes=4):    \n",
    "    inputs = Input(shape=input_shape, name='input')\n",
    "    x = LSTM(32, return_sequences=True)(inputs)\n",
    "    x = LSTM(32, return_sequences=True)(x)\n",
    "    x = TimeDistributed(mdn.MDN(4, 1))(x)\n",
    "    model = Model(inputs, x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 28, 2048)          0         \n",
      "_________________________________________________________________\n",
      "lstm_27 (LSTM)               (None, 28, 32)            266368    \n",
      "_________________________________________________________________\n",
      "lstm_28 (LSTM)               (None, 28, 32)            8320      \n",
      "_________________________________________________________________\n",
      "time_distributed_9 (TimeDist (None, 28, 9)             297       \n",
      "=================================================================\n",
      "Total params: 274,985\n",
      "Trainable params: 274,985\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ngwena-ian/miniconda3/envs/models/lib/python3.6/site-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n",
      "/home/ngwena-ian/miniconda3/envs/models/lib/python3.6/site-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n",
      "/home/ngwena-ian/miniconda3/envs/models/lib/python3.6/site-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n",
      "/home/ngwena-ian/miniconda3/envs/models/lib/python3.6/site-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n",
      "/home/ngwena-ian/miniconda3/envs/models/lib/python3.6/site-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n",
      "/home/ngwena-ian/miniconda3/envs/models/lib/python3.6/site-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n",
      "/home/ngwena-ian/miniconda3/envs/models/lib/python3.6/site-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n",
      "/home/ngwena-ian/miniconda3/envs/models/lib/python3.6/site-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n",
      "/home/ngwena-ian/miniconda3/envs/models/lib/python3.6/site-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n",
      "/home/ngwena-ian/miniconda3/envs/models/lib/python3.6/site-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n",
      "/home/ngwena-ian/miniconda3/envs/models/lib/python3.6/site-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n",
      "/home/ngwena-ian/miniconda3/envs/models/lib/python3.6/site-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n",
      "/home/ngwena-ian/miniconda3/envs/models/lib/python3.6/site-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n",
      "/home/ngwena-ian/miniconda3/envs/models/lib/python3.6/site-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n",
      "/home/ngwena-ian/miniconda3/envs/models/lib/python3.6/site-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n",
      "/home/ngwena-ian/miniconda3/envs/models/lib/python3.6/site-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n",
      "/home/ngwena-ian/miniconda3/envs/models/lib/python3.6/site-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n",
      "/home/ngwena-ian/miniconda3/envs/models/lib/python3.6/site-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "mdn_model = build_rnn_mdn_model((X_train_lstm.shape[1], X_train_lstm.shape[2]), nb_classes=y_train.shape[2])\n",
    "mdn_model.compile(loss=mdn.get_mixture_loss_func(4,1), optimizer='adam')\n",
    "mdn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2252 samples, validate on 564 samples\n",
      "Epoch 1/500\n",
      "2252/2252 [==============================] - 11s 5ms/step - loss: 2.4835 - val_loss: 2.3057\n",
      "Epoch 2/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2974 - val_loss: 2.2826\n",
      "Epoch 3/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2809 - val_loss: 2.2584\n",
      "Epoch 4/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2705 - val_loss: 2.2763\n",
      "Epoch 5/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2722 - val_loss: 2.2592\n",
      "Epoch 6/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2654 - val_loss: 2.2418\n",
      "Epoch 7/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2594 - val_loss: 2.2315\n",
      "Epoch 8/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2607 - val_loss: 2.2237\n",
      "Epoch 9/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2380 - val_loss: 2.2322\n",
      "Epoch 10/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2422 - val_loss: 2.2266\n",
      "Epoch 11/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2404 - val_loss: 2.2139\n",
      "Epoch 12/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2274 - val_loss: 2.2103\n",
      "Epoch 13/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2245 - val_loss: 2.1998\n",
      "Epoch 14/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2246 - val_loss: 2.1962\n",
      "Epoch 15/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2185 - val_loss: 2.1875\n",
      "Epoch 16/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2130 - val_loss: 2.1811\n",
      "Epoch 17/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2115 - val_loss: 2.1851\n",
      "Epoch 18/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.1996 - val_loss: 2.1495\n",
      "Epoch 19/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.1657 - val_loss: 2.1211\n",
      "Epoch 20/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2232 - val_loss: 2.2171\n",
      "Epoch 21/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.1766 - val_loss: 2.1544\n",
      "Epoch 22/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.1553 - val_loss: 2.1813\n",
      "Epoch 23/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.1591 - val_loss: 2.1080\n",
      "Epoch 24/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2793 - val_loss: 2.9241\n",
      "Epoch 25/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.4979 - val_loss: 2.2306\n",
      "Epoch 26/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2343 - val_loss: 2.2145\n",
      "Epoch 27/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2382 - val_loss: 2.2143\n",
      "Epoch 28/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2295 - val_loss: 2.2168\n",
      "Epoch 29/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2312 - val_loss: 2.2144\n",
      "Epoch 30/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2281 - val_loss: 2.2101\n",
      "Epoch 31/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2325 - val_loss: 2.2185\n",
      "Epoch 32/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2312 - val_loss: 2.2190\n",
      "Epoch 33/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2271 - val_loss: 2.2144\n",
      "Epoch 34/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2256 - val_loss: 2.2080\n",
      "Epoch 35/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2265 - val_loss: 2.2126\n",
      "Epoch 36/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2273 - val_loss: 2.2152\n",
      "Epoch 37/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2283 - val_loss: 2.2107\n",
      "Epoch 38/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2375 - val_loss: 2.2175\n",
      "Epoch 39/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2303 - val_loss: 2.2099\n",
      "Epoch 40/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2249 - val_loss: 2.2061\n",
      "Epoch 41/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2264 - val_loss: 2.2031\n",
      "Epoch 42/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2246 - val_loss: 2.2019\n",
      "Epoch 43/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2195 - val_loss: 2.2001\n",
      "Epoch 44/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2190 - val_loss: 2.2017\n",
      "Epoch 45/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2185 - val_loss: 2.2028\n",
      "Epoch 46/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2167 - val_loss: 2.1977\n",
      "Epoch 47/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2137 - val_loss: 2.1908\n",
      "Epoch 48/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2169 - val_loss: 2.1981\n",
      "Epoch 49/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2051 - val_loss: 2.1896\n",
      "Epoch 50/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2090 - val_loss: 2.1892\n",
      "Epoch 51/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2073 - val_loss: 2.1754\n",
      "Epoch 52/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.1908 - val_loss: 2.1730\n",
      "Epoch 53/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.1958 - val_loss: 2.1754\n",
      "Epoch 54/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.1908 - val_loss: 2.1566\n",
      "Epoch 55/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.1816 - val_loss: 2.1762\n",
      "Epoch 56/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2381 - val_loss: 2.1692\n",
      "Epoch 57/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.1865 - val_loss: 2.1642\n",
      "Epoch 58/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.1685 - val_loss: 2.1447\n",
      "Epoch 59/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.1495 - val_loss: 2.1100\n",
      "Epoch 60/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.1247 - val_loss: 2.5373\n",
      "Epoch 61/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2061 - val_loss: 2.1246\n",
      "Epoch 62/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.1295 - val_loss: 2.0901\n",
      "Epoch 63/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.0949 - val_loss: 2.2155\n",
      "Epoch 64/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.0718 - val_loss: 2.0512\n",
      "Epoch 65/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.0503 - val_loss: 2.0691\n",
      "Epoch 66/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.0605 - val_loss: 2.0857\n",
      "Epoch 67/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.0583 - val_loss: 2.0205\n",
      "Epoch 68/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.0709 - val_loss: 2.0309\n",
      "Epoch 69/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.0165 - val_loss: 2.0731\n",
      "Epoch 70/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 1.9883 - val_loss: 2.0607\n",
      "Epoch 71/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.0260 - val_loss: 2.0974\n",
      "Epoch 72/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 1.9905 - val_loss: 1.9899\n",
      "Epoch 73/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 1.9738 - val_loss: 2.0832\n",
      "Epoch 74/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 1.9624 - val_loss: 2.0530\n",
      "Epoch 75/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 1.9579 - val_loss: 2.2723\n",
      "Epoch 76/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.0061 - val_loss: 1.9758\n",
      "Epoch 77/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 1.9563 - val_loss: 1.9686\n",
      "Epoch 78/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 1.9115 - val_loss: 2.0642\n",
      "Epoch 79/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 1.9248 - val_loss: 2.0193\n",
      "Epoch 80/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 1.9416 - val_loss: 1.9261\n",
      "Epoch 81/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 1.9470 - val_loss: 1.9502\n",
      "Epoch 82/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 1.8870 - val_loss: 2.0993\n",
      "Epoch 83/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 1.9127 - val_loss: 1.9809\n",
      "Epoch 84/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 1.8753 - val_loss: 1.9964\n",
      "Epoch 85/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 1.9243 - val_loss: 2.0094\n",
      "Epoch 86/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 1.9337 - val_loss: 1.9947\n",
      "Epoch 87/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 1.9389 - val_loss: 1.8868\n",
      "Epoch 88/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 1.8267 - val_loss: 2.1209\n",
      "Epoch 89/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 1.9329 - val_loss: 1.8435\n",
      "Epoch 90/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 1.9477 - val_loss: 1.9304\n",
      "Epoch 91/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 1.8405 - val_loss: 1.8495\n",
      "Epoch 92/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 1.8365 - val_loss: 1.8226\n",
      "Epoch 93/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 1.8177 - val_loss: 1.8411\n",
      "Epoch 94/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 1.7402 - val_loss: 2.0151\n",
      "Epoch 95/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 1.8259 - val_loss: 1.7963\n",
      "Epoch 96/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 1.7604 - val_loss: 1.9495\n",
      "Epoch 97/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 1.7177 - val_loss: 1.8413\n",
      "Epoch 98/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 1.7431 - val_loss: 3.3893\n",
      "Epoch 99/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.1078 - val_loss: 1.9428\n",
      "Epoch 100/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 1.7951 - val_loss: 1.7608\n",
      "Epoch 101/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 1.7232 - val_loss: 1.8093\n",
      "Epoch 102/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 1.6921 - val_loss: 1.7138\n",
      "Epoch 103/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 1.7529 - val_loss: 1.8764\n",
      "Epoch 104/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 1.7451 - val_loss: 1.7189\n",
      "Epoch 105/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 1.7245 - val_loss: 2.1839\n",
      "Epoch 106/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 1.7445 - val_loss: 1.7225\n",
      "Epoch 107/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 1.7124 - val_loss: 1.7264\n",
      "Epoch 108/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 1.8047 - val_loss: 1.9345\n",
      "Epoch 109/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 1.7187 - val_loss: 1.7566\n",
      "Epoch 110/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 1.7787 - val_loss: 1.7920\n",
      "Epoch 111/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 1.7870 - val_loss: 1.6314\n",
      "Epoch 112/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 1.5712 - val_loss: 2.0288\n",
      "Epoch 113/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 1.6414 - val_loss: 1.6643\n",
      "Epoch 114/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 1.5399 - val_loss: 1.6328\n",
      "Epoch 115/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 1.6128 - val_loss: 1.6198\n",
      "Epoch 116/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 1.5674 - val_loss: 1.5117\n",
      "Epoch 117/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 1.6388 - val_loss: 1.5932\n",
      "Epoch 118/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 1.9627 - val_loss: 2.1735\n",
      "Epoch 119/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.0697 - val_loss: 1.9444\n",
      "Epoch 120/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 1.7757 - val_loss: 1.6911\n",
      "Epoch 121/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 1.6164 - val_loss: 1.5876\n",
      "Epoch 122/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 1.9121 - val_loss: 1.7063\n",
      "Epoch 123/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 1.9814 - val_loss: 3.2701\n",
      "Epoch 124/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.5219 - val_loss: 2.2551\n",
      "Epoch 125/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2383 - val_loss: 2.2234\n",
      "Epoch 126/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2327 - val_loss: 2.2130\n",
      "Epoch 127/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2288 - val_loss: 2.2119\n",
      "Epoch 128/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2274 - val_loss: 2.2144\n",
      "Epoch 129/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2275 - val_loss: 2.2128\n",
      "Epoch 130/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2271 - val_loss: 2.2119\n",
      "Epoch 131/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2285 - val_loss: 2.2115\n",
      "Epoch 132/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2288 - val_loss: 2.2082\n",
      "Epoch 133/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2253 - val_loss: 2.2066\n",
      "Epoch 134/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2255 - val_loss: 2.2115\n",
      "Epoch 135/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2246 - val_loss: 2.2083\n",
      "Epoch 136/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2241 - val_loss: 2.2083\n",
      "Epoch 137/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2259 - val_loss: 2.2056\n",
      "Epoch 138/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2245 - val_loss: 2.2062\n",
      "Epoch 139/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2273 - val_loss: 2.2091\n",
      "Epoch 140/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2256 - val_loss: 2.2052\n",
      "Epoch 141/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2246 - val_loss: 2.2073\n",
      "Epoch 142/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2239 - val_loss: 2.2056\n",
      "Epoch 143/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2274 - val_loss: 2.2140\n",
      "Epoch 144/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2274 - val_loss: 2.2051\n",
      "Epoch 145/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2224 - val_loss: 2.2038\n",
      "Epoch 146/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2215 - val_loss: 2.2053\n",
      "Epoch 147/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2235 - val_loss: 2.2073\n",
      "Epoch 148/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2281 - val_loss: 2.2051\n",
      "Epoch 149/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2240 - val_loss: 2.2040\n",
      "Epoch 150/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2252 - val_loss: 2.2068\n",
      "Epoch 151/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2221 - val_loss: 2.2030\n",
      "Epoch 152/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2235 - val_loss: 2.2083\n",
      "Epoch 153/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2248 - val_loss: 2.2047\n",
      "Epoch 154/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2222 - val_loss: 2.2052\n",
      "Epoch 155/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2226 - val_loss: 2.2039\n",
      "Epoch 156/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2245 - val_loss: 2.2036\n",
      "Epoch 157/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2230 - val_loss: 2.2040\n",
      "Epoch 158/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2234 - val_loss: 2.2041\n",
      "Epoch 159/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2242 - val_loss: 2.2078\n",
      "Epoch 160/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2235 - val_loss: 2.2036\n",
      "Epoch 161/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2246 - val_loss: 2.2056\n",
      "Epoch 162/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2254 - val_loss: 2.2037\n",
      "Epoch 163/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2251 - val_loss: 2.2152\n",
      "Epoch 164/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2282 - val_loss: 2.2040\n",
      "Epoch 165/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2223 - val_loss: 2.2053\n",
      "Epoch 166/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2233 - val_loss: 2.2072\n",
      "Epoch 167/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2259 - val_loss: 2.2053\n",
      "Epoch 168/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2269 - val_loss: 2.2041\n",
      "Epoch 169/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2238 - val_loss: 2.2038\n",
      "Epoch 170/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2243 - val_loss: 2.2042\n",
      "Epoch 171/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2228 - val_loss: 2.2045\n",
      "Epoch 172/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2258 - val_loss: 2.2038\n",
      "Epoch 173/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2223 - val_loss: 2.2045\n",
      "Epoch 174/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2252 - val_loss: 2.2043\n",
      "Epoch 175/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2233 - val_loss: 2.2024\n",
      "Epoch 176/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2222 - val_loss: 2.2067\n",
      "Epoch 177/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2259 - val_loss: 2.2050\n",
      "Epoch 178/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2233 - val_loss: 2.2019\n",
      "Epoch 179/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2237 - val_loss: 2.2108\n",
      "Epoch 180/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2252 - val_loss: 2.2044\n",
      "Epoch 181/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2238 - val_loss: 2.2034\n",
      "Epoch 182/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2238 - val_loss: 2.2040\n",
      "Epoch 183/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2262 - val_loss: 2.2019\n",
      "Epoch 184/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2221 - val_loss: 2.2023\n",
      "Epoch 185/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2214 - val_loss: 2.2032\n",
      "Epoch 186/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2213 - val_loss: 2.2041\n",
      "Epoch 187/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2228 - val_loss: 2.2061\n",
      "Epoch 188/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2228 - val_loss: 2.2056\n",
      "Epoch 189/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2256 - val_loss: 2.2052\n",
      "Epoch 190/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2251 - val_loss: 2.2025\n",
      "Epoch 191/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2212 - val_loss: 2.2031\n",
      "Epoch 192/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2243 - val_loss: 2.2035\n",
      "Epoch 193/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2264 - val_loss: 2.2021\n",
      "Epoch 194/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2230 - val_loss: 2.2058\n",
      "Epoch 195/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2283 - val_loss: 2.2124\n",
      "Epoch 196/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2238 - val_loss: 2.2035\n",
      "Epoch 197/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2202 - val_loss: 2.2021\n",
      "Epoch 198/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2215 - val_loss: 2.2038\n",
      "Epoch 199/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2252 - val_loss: 2.2076\n",
      "Epoch 200/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2268 - val_loss: 2.2151\n",
      "Epoch 201/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2282 - val_loss: 2.2019\n",
      "Epoch 202/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2255 - val_loss: 2.2027\n",
      "Epoch 203/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2231 - val_loss: 2.2101\n",
      "Epoch 204/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2263 - val_loss: 2.2040\n",
      "Epoch 205/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2232 - val_loss: 2.2034\n",
      "Epoch 206/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2234 - val_loss: 2.2022\n",
      "Epoch 207/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2248 - val_loss: 2.2017\n",
      "Epoch 208/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2261 - val_loss: 2.2027\n",
      "Epoch 209/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2233 - val_loss: 2.2039\n",
      "Epoch 210/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2225 - val_loss: 2.2048\n",
      "Epoch 211/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2260 - val_loss: 2.2072\n",
      "Epoch 212/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2212 - val_loss: 2.2040\n",
      "Epoch 213/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2207 - val_loss: 2.2024\n",
      "Epoch 214/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2224 - val_loss: 2.2044\n",
      "Epoch 215/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2229 - val_loss: 2.2016\n",
      "Epoch 216/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2226 - val_loss: 2.2039\n",
      "Epoch 217/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2235 - val_loss: 2.2136\n",
      "Epoch 218/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2260 - val_loss: 2.2060\n",
      "Epoch 219/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2230 - val_loss: 2.2041\n",
      "Epoch 220/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2246 - val_loss: 2.2040\n",
      "Epoch 221/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2213 - val_loss: 2.2129\n",
      "Epoch 222/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.8981 - val_loss: 2.2336\n",
      "Epoch 223/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2384 - val_loss: 2.2269\n",
      "Epoch 224/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2353 - val_loss: 2.2200\n",
      "Epoch 225/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2364 - val_loss: 2.2191\n",
      "Epoch 226/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2312 - val_loss: 2.2159\n",
      "Epoch 227/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2282 - val_loss: 2.2162\n",
      "Epoch 228/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2268 - val_loss: 2.2092\n",
      "Epoch 229/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2231 - val_loss: 2.2126\n",
      "Epoch 230/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2240 - val_loss: 2.2091\n",
      "Epoch 231/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2226 - val_loss: 2.2079\n",
      "Epoch 232/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2240 - val_loss: 2.2074\n",
      "Epoch 233/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2244 - val_loss: 2.2063\n",
      "Epoch 234/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2273 - val_loss: 2.2069\n",
      "Epoch 235/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2219 - val_loss: 2.2040\n",
      "Epoch 236/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2239 - val_loss: 2.2065\n",
      "Epoch 237/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2234 - val_loss: 2.2041\n",
      "Epoch 238/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2218 - val_loss: 2.2037\n",
      "Epoch 239/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2208 - val_loss: 2.2045\n",
      "Epoch 240/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2208 - val_loss: 2.2081\n",
      "Epoch 241/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2231 - val_loss: 2.2044\n",
      "Epoch 242/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2227 - val_loss: 2.2026\n",
      "Epoch 243/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2206 - val_loss: 2.2033\n",
      "Epoch 244/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2218 - val_loss: 2.2027\n",
      "Epoch 245/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2205 - val_loss: 2.2130\n",
      "Epoch 246/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2236 - val_loss: 2.2034\n",
      "Epoch 247/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2223 - val_loss: 2.2057\n",
      "Epoch 248/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2255 - val_loss: 2.2051\n",
      "Epoch 249/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2248 - val_loss: 2.2123\n",
      "Epoch 250/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2246 - val_loss: 2.2047\n",
      "Epoch 251/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2227 - val_loss: 2.2047\n",
      "Epoch 252/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2234 - val_loss: 2.2029\n",
      "Epoch 253/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2214 - val_loss: 2.2035\n",
      "Epoch 254/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2236 - val_loss: 2.2051\n",
      "Epoch 255/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2214 - val_loss: 2.2019\n",
      "Epoch 256/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2232 - val_loss: 2.2069\n",
      "Epoch 257/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2248 - val_loss: 2.2038\n",
      "Epoch 258/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2206 - val_loss: 2.2026\n",
      "Epoch 259/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2209 - val_loss: 2.2012\n",
      "Epoch 260/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2206 - val_loss: 2.2015\n",
      "Epoch 261/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2247 - val_loss: 2.2057\n",
      "Epoch 262/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2259 - val_loss: 2.2011\n",
      "Epoch 263/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2202 - val_loss: 2.2022\n",
      "Epoch 264/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2217 - val_loss: 2.2016\n",
      "Epoch 265/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2208 - val_loss: 2.2016\n",
      "Epoch 266/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2223 - val_loss: 2.2045\n",
      "Epoch 267/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2220 - val_loss: 2.2012\n",
      "Epoch 268/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2218 - val_loss: 2.2027\n",
      "Epoch 269/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2206 - val_loss: 2.2024\n",
      "Epoch 270/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2225 - val_loss: 2.2040\n",
      "Epoch 271/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2212 - val_loss: 2.2012\n",
      "Epoch 272/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2190 - val_loss: 2.2028\n",
      "Epoch 273/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2224 - val_loss: 2.2006\n",
      "Epoch 274/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2212 - val_loss: 2.2037\n",
      "Epoch 275/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2236 - val_loss: 2.2023\n",
      "Epoch 276/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2208 - val_loss: 2.2026\n",
      "Epoch 277/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2216 - val_loss: 2.2002\n",
      "Epoch 278/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2234 - val_loss: 2.2039\n",
      "Epoch 279/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2210 - val_loss: 2.2006\n",
      "Epoch 280/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2221 - val_loss: 2.2017\n",
      "Epoch 281/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2226 - val_loss: 2.2048\n",
      "Epoch 282/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2231 - val_loss: 2.2029\n",
      "Epoch 283/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2268 - val_loss: 2.2023\n",
      "Epoch 284/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2229 - val_loss: 2.1996\n",
      "Epoch 285/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2201 - val_loss: 2.2093\n",
      "Epoch 286/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2246 - val_loss: 2.1991\n",
      "Epoch 287/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2183 - val_loss: 2.2018\n",
      "Epoch 288/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2191 - val_loss: 2.1987\n",
      "Epoch 289/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2255 - val_loss: 2.2078\n",
      "Epoch 290/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2201 - val_loss: 2.2017\n",
      "Epoch 291/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2209 - val_loss: 2.1983\n",
      "Epoch 292/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2229 - val_loss: 2.1998\n",
      "Epoch 293/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2250 - val_loss: 2.2026\n",
      "Epoch 294/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2198 - val_loss: 2.2001\n",
      "Epoch 295/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2184 - val_loss: 2.2140\n",
      "Epoch 296/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2202 - val_loss: 2.1984\n",
      "Epoch 297/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2193 - val_loss: 2.1984\n",
      "Epoch 298/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2174 - val_loss: 2.2009\n",
      "Epoch 299/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2258 - val_loss: 2.1992\n",
      "Epoch 300/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2221 - val_loss: 2.1983\n",
      "Epoch 301/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2192 - val_loss: 2.1999\n",
      "Epoch 302/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2208 - val_loss: 2.2055\n",
      "Epoch 303/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2179 - val_loss: 2.1997\n",
      "Epoch 304/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2156 - val_loss: 2.1975\n",
      "Epoch 305/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2198 - val_loss: 2.1956\n",
      "Epoch 306/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2213 - val_loss: 2.2011\n",
      "Epoch 307/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2154 - val_loss: 2.1955\n",
      "Epoch 308/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2157 - val_loss: 2.1926\n",
      "Epoch 309/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2147 - val_loss: 2.1979\n",
      "Epoch 310/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2134 - val_loss: 2.1948\n",
      "Epoch 311/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2148 - val_loss: 2.1906\n",
      "Epoch 312/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2125 - val_loss: 2.1886\n",
      "Epoch 313/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2092 - val_loss: 2.2005\n",
      "Epoch 314/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2144 - val_loss: 2.1881\n",
      "Epoch 315/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2095 - val_loss: 2.1889\n",
      "Epoch 316/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2104 - val_loss: 2.1884\n",
      "Epoch 317/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2090 - val_loss: 2.1939\n",
      "Epoch 318/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2165 - val_loss: 2.1899\n",
      "Epoch 319/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2121 - val_loss: 2.1979\n",
      "Epoch 320/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2110 - val_loss: 2.1872\n",
      "Epoch 321/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2112 - val_loss: 2.1854\n",
      "Epoch 322/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2089 - val_loss: 2.1926\n",
      "Epoch 323/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2107 - val_loss: 2.1885\n",
      "Epoch 324/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2063 - val_loss: 2.2033\n",
      "Epoch 325/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2173 - val_loss: 2.1893\n",
      "Epoch 326/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2120 - val_loss: 2.1886\n",
      "Epoch 327/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2074 - val_loss: 2.1852\n",
      "Epoch 328/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2100 - val_loss: 2.1869\n",
      "Epoch 329/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2105 - val_loss: 2.1905\n",
      "Epoch 330/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2113 - val_loss: 2.1852\n",
      "Epoch 331/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2320 - val_loss: 2.1944\n",
      "Epoch 332/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2158 - val_loss: 2.1851\n",
      "Epoch 333/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2075 - val_loss: 2.1852\n",
      "Epoch 334/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2054 - val_loss: 2.1870\n",
      "Epoch 335/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2056 - val_loss: 2.1938\n",
      "Epoch 336/500\n",
      "2252/2252 [==============================] - 5s 2ms/step - loss: 2.2166 - val_loss: 2.1871\n",
      "Epoch 337/500\n",
      " 576/2252 [======>.......................] - ETA: 3s - loss: 2.2437"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-84-fa2cc98c7dc9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m             )\n",
      "\u001b[0;32m~/miniconda3/envs/models/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/miniconda3/envs/models/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/models/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/models/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/models/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mdn_model.fit(\n",
    "    X_train_lstm,\n",
    "    y_train,\n",
    "    validation_split=validation_split,\n",
    "    batch_size=batch_size,\n",
    "    epochs=n_epochs,\n",
    "    shuffle=True,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = mdn_model.predict(features[1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.83390598e-04, 4.78741458e-05, 1.35706235e-02, 9.85598147e-01]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_model.predict(np.array([X_train[1000]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 1.])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtractor(Layer):\n",
    "    def __init__(self, shape, **kwargs):\n",
    "        super(FeatureExtractor, self).__init__(**kwargs)\n",
    "        self.shape = shape\n",
    "        self.layers = layers\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.base_model = InceptionV3(\n",
    "             weights='imagenet',\n",
    "             include_top=False,\n",
    "             input_shape=self.shape,\n",
    "         )\n",
    "            \n",
    "        self.base_model.trainable = False\n",
    "\n",
    "        for layer in self.base_model.layers:\n",
    "            layer.trainable = False\n",
    "\n",
    "        self.outputs = BatchNormalization()(self.base_model.get_layer('avg_pool').output)\n",
    "        \n",
    "        self.model = Model(\n",
    "            self.base_model.inputs,\n",
    "            self.outputs,\n",
    "            )\n",
    "        super(FeatureExtractor, self).build(input_shape)\n",
    "\n",
    "    def call(self, layer_inputs, **kwargs):\n",
    "        return self.model(layer_inputs)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'input_shape': self.input_shape,\n",
    "            'layers': self.layers,\n",
    "        }\n",
    "        base_config = \\\n",
    "            super(FeatureExtractor, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "\n",
    "get_custom_objects().update({'FeatureExtractor':\n",
    "                             FeatureExtractor})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def collect_data(annotations_file, image_folder='data/occelatus/', starting_frame=315):\n",
    "#     df = pd.read_csv(annotations_file)\n",
    "#     df['FRAME_IDX'] = df['FRAME_IDX'] + starting_frame\n",
    "#     FRAMES = []\n",
    "#     LABELS = df['LABEL']\n",
    "#     for BID in np.unique(df['LABEL']):\n",
    "#         frames = [image_folder+str(df.at[int(idx),'FRAME_IDX']).zfill(5)+'.jpg' for idx in np.argwhere(df['LABEL']==BID)]\n",
    "#         FRAMES.extend(frames)\n",
    "                 \n",
    "#     return FRAMES, LABELS\n",
    "\n",
    "# def get_model(weights='imagenet', num_classes=6):\n",
    "#     # create the base pre-trained model\n",
    "#     base_model = InceptionV3(weights=weights, include_top=False)\n",
    "\n",
    "#     # add a global spatial average pooling layer\n",
    "#     base_model.layers.pop()  # two pops to get to pool layer\n",
    "#     x = base_model.output\n",
    "#     x = GlobalAveragePooling2D()(x)\n",
    "#     # let's add a fully-connected layer\n",
    "#     x = Dense(1024, activation='relu')(x)\n",
    "#     # and a logistic layer\n",
    "#     predictions = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "#     # this is the model we will train\n",
    "#     model = Model(inputs=base_model.input, outputs=predictions)\n",
    "#     return model\n",
    "\n",
    "# def extract(model, path):\n",
    "#     features = []\n",
    "#     img = image.load_img(path)\n",
    "#     x = image.img_to_array(img)\n",
    "#     features = model.predict(np.array([x]))\n",
    "#     return features\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
