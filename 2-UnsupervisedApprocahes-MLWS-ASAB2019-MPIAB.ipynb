{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numba\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import cupy as cp\n",
    "from skcuda.fft import fft, ifft, Plan\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import mixture\n",
    "from mne.time_frequency import tfr_array_morlet as morlet\n",
    "\n",
    "from ethotype import config\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def median_filter(df, \n",
    "                  window=config.median_filter_window):\n",
    "    '''\n",
    "    TODO: add doc-string\n",
    "    '''\n",
    "    return df.rolling(center=True,window=window).mean()\n",
    "\n",
    "def reject_cross_frame_noise(df, \n",
    "                             n_stds=config.n_stds):\n",
    "    '''\n",
    "    TODO: add doc-string\n",
    "    '''\n",
    "    #we need to investigate if this has any affect on down stream intuitions\n",
    "    global_mask = []\n",
    "    df2 = df.copy()\n",
    "    for column in df2:\n",
    "        feature = df2[column]\n",
    "        df2[column+'_shift1'] = feature.shift(1)\n",
    "        stdx = np.std(df2[column])*n_stds\n",
    "        abs(df2[column]-df2[column+'_shift1'])<abs(stdx)\n",
    "        mask = df2[abs(df2[column]-df2[column+'_shift1'])>abs(stdx)].index.values.tolist()\n",
    "        for frame in mask:\n",
    "            if frame not in global_mask:\n",
    "                global_mask.append(frame)\n",
    "    included_frames = df[~df.index.isin(global_mask)].index.tolist()\n",
    "    df= df[~df.index.isin(global_mask)]\n",
    "    return df, np.asarray(included_frames)\n",
    "\n",
    "def get_low_var_cutoff(fv, \n",
    "                       frame_index):\n",
    "    '''\n",
    "    TODO: add doc-string\n",
    "    '''\n",
    "    frame_index= np.asarray(frame_index)\n",
    "    fv = np.vstack(fv)\n",
    "    fv_var = np.var(fv, axis=0)\n",
    "    #gmm = mixture.GaussianMixture(n_components=2,  covariance_type='tied', random_state=42)\n",
    "    #labels = gmm.fit(fv_var.reshape(-1,1)).predict(fv_var.reshape(-1,1))\n",
    "    kmeans = KMeans(2, random_state=0)\n",
    "    labels = kmeans.fit(fv_var.reshape(-1,1)).predict(fv_var.reshape(-1,1))\n",
    "    if np.mean(fv_var[np.where(labels==1)]) > np.mean(fv_var[np.where(labels==0)]):\n",
    "        pass\n",
    "    else:\n",
    "        labels = np.where(labels==0,1,0)\n",
    "    fv = np.vstack(fv[:,np.where(labels==1)])\n",
    "    frames = frame_index[np.where(labels==1)]\n",
    "    return fv, labels, frames\n",
    "\n",
    "def get_wavelet_features(data, \n",
    "                         sampling_rate = config.sampling_rate, \n",
    "                         n_octaves=config.n_octaves, \n",
    "                         range_cycles = config.range_cycles):\n",
    "    '''\n",
    "    TODO: add doc-string\n",
    "    '''\n",
    "    \n",
    "    #metadata\n",
    "    channels = [column for column in data] \n",
    "    \n",
    "    #wavelet parameters\n",
    "    range_frex = [1, sampling_rate/2] #nyquist limit is half of srate\n",
    "    frex = np.geomspace(range_frex[0],\n",
    "                                  range_frex[1],\n",
    "                                  num=n_octaves)\n",
    "    \n",
    "    cycles = np.geomspace(range_cycles[0],\n",
    "                                    range_cycles[1],\n",
    "                                    num=n_octaves)\n",
    "\n",
    "    time = np.linspace(-2,2,sampling_rate)\n",
    "    half_wave = int((len(time))/2)\n",
    "    \n",
    "    #FFT parameters\n",
    "    nkern = len(time)\n",
    "    nconv = nkern+len(data)\n",
    "    \n",
    "    #init output\n",
    "    tf = []\n",
    "    for _, chan in enumerate(channels):\n",
    "        cf = []\n",
    "        dataX = np.fft.fft(np.asarray(data[chan]), nconv)\n",
    "        for o, (f, c) in enumerate(zip(frex, cycles)):\n",
    "            #create wavelet\n",
    "            sine_wave = np.exp(1j*2*np.pi*f*time) \n",
    "            s = c / (2*np.pi*f) \n",
    "            gaus_win  = np.exp((-time**2)/(2*s**2)) \n",
    "            cmw  = sine_wave * gaus_win\n",
    "            cmwX = np.fft.fft(cmw,nconv)\n",
    "            cmwX = cmwX/np.max(cmwX)\n",
    "\n",
    "            #convolve and trim\n",
    "            m = np.fft.ifft(dataX * cmwX) \n",
    "            m2 = m[half_wave:-half_wave]\n",
    "\n",
    "            cf.append(abs(m2)**2)\n",
    "        tf.append(cf)\n",
    "    return tf\n",
    "\n",
    "\n",
    "def get_window_features(data, \n",
    "                        win_scales=config.win_scales):\n",
    "    '''\n",
    "    TODO: add doc-string\n",
    "    '''\n",
    "    channels = [column for column in data]\n",
    "    TF = []\n",
    "    for _, chan in enumerate(channels):\n",
    "        cf = []\n",
    "        for win_scale in win_scales:\n",
    "            val = data[chan].rolling(center=True,window=win_scale).mean()\n",
    "            cf.append(val)\n",
    "        TF.append(cf)\n",
    "    return(tf)\n",
    "\n",
    "def sum_norm(fv):\n",
    "    '''\n",
    "    TODO: add doc-string\n",
    "    '''\n",
    "    return fv/fv.sum(axis=1)[:,None]\n",
    "\n",
    "@numba.njit(fastmath=True)\n",
    "def morletConjFT(w, \n",
    "                 omega0):\n",
    "    '''\n",
    "    TODO: add doc-string\n",
    "    '''\n",
    "    return np.pi**(-1/4)*np.exp(-.5*(w-omega0)**2) #eq. C2\n",
    "\n",
    "\n",
    "def berman2014_wavelet(x, \n",
    "                       f, \n",
    "                       omega0, \n",
    "                       dt):\n",
    "    '''\n",
    "    TODO: add doc-string\n",
    "    '''\n",
    "    N = len(x)\n",
    "    L = len(f)\n",
    "            \n",
    "    amp = np.zeros((L,N)) #make amplitude container\n",
    "    if N % 2 == 1: #make the signal divisible by 2\n",
    "\n",
    "        x = np.append(x, 0)\n",
    "        N += 1\n",
    "        test = True\n",
    "    else:\n",
    "        test = False\n",
    "        \n",
    "    s = x.shape\n",
    "\n",
    "    if s[0]!=1:\n",
    "        x = x.T\n",
    "    x = np.concatenate([np.zeros(int(N/2)), x, np.zeros(int(N/2))]) #pad the signal for convolution\n",
    "    M = N \n",
    "    N = len(x)\n",
    "    scales = np.divide([omega0 + np.sqrt(2+omega0**2)],4*np.pi*f) #eq. C3\n",
    "    Omegavals = np.divide([2*np.pi*np.arange(-N/2,N/2,1,dtype='int64')],N*dt)\n",
    "    \n",
    "    with tf.Graph().as_default():\n",
    "        sess = tf.Session() #tf\n",
    "        x_tensor = tf.cast(x, dtype='complex64') #tf\n",
    "        xHat = tf.fft(x_tensor) #tf\n",
    "\n",
    "        #x_gpu = cp.array(x)#cupy\n",
    "        #print(x_gpu)\n",
    "        #xHat = cp.fft.fft(x_gpu) #cupy\n",
    "        #xHat = np.fft.fft(x) #numpy\n",
    "\n",
    "\n",
    "        if test == True:\n",
    "            idx = np.arange((M-1)/2+1, M/2+M-1, 1, dtype='uint64')\n",
    "        else:\n",
    "            idx = np.arange((M-1)/2+1, M/2+M, 1, dtype='uint64')\n",
    "\n",
    "\n",
    "        for i in range(0,L): \n",
    "            m = morletConjFT(-Omegavals*scales[i], omega0)\n",
    "\n",
    "            #\n",
    "            m_tensor = tf.cast(m, dtype='complex64') #tf\n",
    "            sig_tensor = tf.multiply(m_tensor,xHat) #tf\n",
    "            q = tf.ifft(sig_tensor) #tf\n",
    "            q = sess.run(q) #tf\n",
    "\n",
    "\n",
    "            #m_gpu = cp.array(m*xHat) #cupy\n",
    "            #q = cp.fft.ifft(cp.array(m_gpu))*cp.sqrt(scales[i]) #cupy\n",
    "            #q = np.fft.ifft(m*xHat)*np.sqrt(scales[i]) #numpy\n",
    "\n",
    "            q = q[:,idx]\n",
    "            amp[i,:] = np.abs(q)*((np.pi**-.25)*np.exp(.25*(omega0-np.sqrt(omega0**2+2)**2)))/np.sqrt(2*scales[i]) #eq. C5 \n",
    "\n",
    "        sess.close() #tf\n",
    "    return amp\n",
    "\n",
    "def compute(df, rej_cross_frame_noise=config.rej_cross_frame_noise, \n",
    "            low_var_cutoff=config.low_var_cutoff, \n",
    "            features=config.feature_type,window=config.median_filter_window):\n",
    "    '''\n",
    "    TODO: add doc-string\n",
    "    '''\n",
    "    frames = np.asarray(df.index.tolist())\n",
    "    \n",
    "    #standard preprocessing\n",
    "    df = df.rolling(center=True,window=window).mean()\n",
    "    df = df.bfill()\n",
    "    df = df.ffill()\n",
    "    print('done with preporcessing')\n",
    "    #optional preprocessing\n",
    "    if rej_cross_frame_noise==True:\n",
    "        print('rejecting crossframe noise')\n",
    "        df, p_frames = reject_cross_frame_noise(df)\n",
    "    else:\n",
    "        p_frames = frames\n",
    "    #wavelet computation\n",
    "    if features=='sliding_window':\n",
    "        print('calculating sliding_window')\n",
    "        fv = get_window_features(df)\n",
    "    elif features=='morlet_custom':\n",
    "        fv = get_wavelet_features(df)\n",
    "        print('calculating custom morlet wavelet')\n",
    "    elif features=='morlet_standard':\n",
    "        fv = get_wavelet_features_mne(df)\n",
    "        print('calculating default morlet wavelet')\n",
    "    elif features == 'berman2014_wavelet':\n",
    "        print('calculating berman2014 wavelet')\n",
    "        channels = [column for column in df]\n",
    "        f = np.linspace(config.min_freq,config.sampling_rate/2,num=config.n_octaves)\n",
    "        amps = []\n",
    "        \n",
    "        for chan in channels:\n",
    "            print(chan)\n",
    "            x = df[chan].as_matrix(columns=None)\n",
    "            amp = berman2014_wavelet(x, f, omega0=5, dt=1/config.sampling_rate)\n",
    "            amps.append(amp)\n",
    "            \n",
    "        fv = np.vstack(amps)\n",
    "    else:\n",
    "        print('unkown feature \\'{}\\''.format(features))\n",
    "    #optional postprocessing\n",
    "    if low_var_cutoff == True:\n",
    "        fv, hv_labels, hv_frames = get_low_var_cutoff(fv, p_frames)\n",
    "    else:\n",
    "        fv = np.vstack(fv)\n",
    "        hv_frames = p_frames\n",
    "        hv_labels = np.zeros(len(fv[1]))\n",
    "    #standard postprocessing\n",
    "    fv = sum_norm(fv)\n",
    "    return frames, p_frames, hv_frames, hv_labels, fv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "#general\n",
    "home = os.getcwd()\n",
    "proj='fromNadja' ###################################################################################### IMPORTANT\n",
    "input_dir = ''.join([home, '/data/', proj, '/'])\n",
    "input_ext = '.npz' ##################################################################################### IMPORTANT\n",
    "output_dir = ''.join([home,'/tmp/',proj,'/'])\n",
    "output_ext = '.npz'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "fv_str = '_feature_vector_' #feature vector of processed frames\n",
    "lb_str = '_labels_' #frame labels of processed frames\n",
    "fr_str = '_frames_' #all frames\n",
    "ix_str = '_idx_' #processed frames\n",
    "ix2_str = '_sub_idx_' #frames which survive pre-processing (low noise) but not post-processing (low variance)[if used]\n",
    "\n",
    "\n",
    "#wavelet transformation\n",
    "feature_type = 'berman2014_wavelet' #['berman2014_wavelet', 'morlet_standard','morelt_custom', 'sliding_window'] # suggested: berman2014_wavelet\n",
    "input_file_list = ''.join([input_dir, '*', input_ext])\n",
    "posture_channels = ['bone1', 'bone2',\n",
    "       'bone3', 'bone4', 'bone5', 'bone6', 'bone7', 'bone8', 'bone9', 'bone10', 'bone11']\n",
    "movement_channels = ['']\n",
    "\n",
    "min_freq = 1. #Hz we set the minimum frequency to 1/s you can investigate if a longer time span is needed with a fourier transform \n",
    "sampling_rate = 140 #Hz ~2 * max. freq (max. freq == Nyquist limit)\n",
    "n_octaves=25\n",
    "n_features = len(posture_channels)*n_octaves\n",
    "range_cycles = [3, 15]\n",
    "n_stds = 5\n",
    "rej_cross_frame_noise=False\n",
    "low_var_cutoff=False\n",
    "median_filter_window = 3\n",
    "#rolling window\n",
    "win_scales = [1,11,31,61,101,151,211,281,361,451,551]\n",
    "\n",
    "#state-space embedding\n",
    "n_jobs = -1 #all available threads = -1\n",
    "tsne_alg = 'parametric_tsne' #['bh_tsne', 'fit_sne', 'parametric_tsne']\n",
    "overwrite_model=False\n",
    "cosine_dist_batch_size = 50\n",
    "resample_size = 3000\n",
    "perplexity = 200 \n",
    "tsne_dims = 2\n",
    "tsne_batch_size = 30\n",
    "tsne_training_epochs = 100\n",
    "model_name = ''.join([output_dir,proj,'_',str(perplexity),'_',feature_type,'_',tsne_alg,'_model.h5'])\n",
    "feature_vectors_file_list = ''.join([output_dir, '*', fv_str, feature_type, output_ext])\n",
    "\n",
    "\n",
    "#segmentation\n",
    "max_k=40\n",
    "ws_thresh=0.0005\n",
    "ws_bins=100 \n",
    "ws_sigma=2.0 \n",
    "ws_kernel=13 \n",
    "ws_min_dist=0\n",
    "if low_var_cutoff == True:\n",
    "    label_base = 1\n",
    "else:\n",
    "    label_base = 0\n",
    "labels_file_list = ''.join([output_dir, '*', lb_str, feature_type, output_ext])\n",
    "frames_file_list = ''.join([output_dir, '*', fr_str, feature_type, output_ext])\n",
    "index_file_list = ''.join([output_dir, '*', ix_str, feature_type, output_ext])\n",
    "sub_index_file_list = ''.join([output_dir, '*', ix2_str, feature_type, output_ext])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
